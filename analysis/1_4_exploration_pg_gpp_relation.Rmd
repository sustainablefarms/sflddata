---
title: "More Exploration of GPP and precipitation"
author: "Kassel Hingee"
date: "13/01/2020"
output: html_document
---

The following exploration occurs after fitting an additive linear model, and log-linear model for GPP. It uses learnings summarised in `1_3_3_model_fitting_pg_gpp.Rmd`.

+ correlation analysis, a variety of transforms and derivative precipitation infomration, would be useful for choosing predictors
+ using pre-built decomposition methods within R to explore break down too
+ exploring stationarity of GPP


```{r setup}
knitr::opts_chunk$set(echo = TRUE)
out <- lapply(c("sf", "tsibble", 'lubridate', "viridis",
                'ggplot2', 'tidyr', 'grid', 'gridExtra', 
                'feasts', 'dplyr', 'gtable', 'fable'),
       library, character.only = TRUE)
out <- lapply(paste0("../functions/", list.files("../functions/")), source)
```

```{r preparedata}
#load data and convert to tsibbles
load("../private/data/remote_sensed/pg_daily.Rdata")
pg_daily$times <- as_date(pg_daily$times)
pg <- pg_daily %>%
  pivot_longer(-times, names_to = "site", values_to = "pg") %>%
  as_tsibble(key = site, index = times)
load("../private/data/remote_sensed/gpp_8d.Rdata")
gpp <- gpp_8d %>%
  pivot_longer(-times, names_to = "site", values_to = "gpp") %>%
  as_tsibble(key = site, index = times)
pggpp <- as_tsibble(dplyr::full_join(pg, gpp, by = c("times", "site")), key = site, index = times)

#interpolate gpp
pggpp <- pggpp %>%
  mutate(yday = yday(times)) %>%
  group_by_key() %>% #key is site
  mutate(lininterp_gpp = zoo::na.approx(gpp, rule = 2, na.rm = FALSE)) %>% #rule 2 means edges are assigned last value
  ungroup()

#make sure sites are ordered alphabetically
pggpp <- pggpp %>%
  arrange(site) %>%
  mutate(site = factor(site, ordered = TRUE))

#extract alpha part of code
pggpp <- pggpp %>%
  mutate(farm = substr(site, 1, 4),
         sitenum = as.integer(substr(site, 5, 5)))
```


## Automatic Time Series Decompositions
Using interpolated values for all decompositions - so that it will not error.

In below:
+ the season window specifies how fast the seasonal component of the decomposition can vary
+ the trend window specifies how fast the trend can vary

```{r stl_decomposition_additive}
decomposition <- pggpp %>%
  filter(site %in% c("ARCH1", "BELL1")) %>%
  STL(lininterp_gpp ~ trend(5*8, degree = 1) + season("3 year", degree = 0))
decomposition %>% 
  autoplot()
```

Remainders are quite autocorrelated even with a trend term. Multiplicate might do better.


Multiplicative decompisition with STL
```{r stl_decomposition_additive}
decomposition <- pggpp %>%
  filter(site %in% c("ARCH1", "BELL1")) %>%
  STL(log(lininterp_gpp + 1) ~ trend(6*8, degree = 1) + season("1 year", degree = 1))
decomposition %>% 
  autoplot()
```
The remainders are about a 3rd of the season variation.

Something in between multiplicative and additive:
```{r stl_decomposition_additive}
decomposition <- pggpp %>%
  filter(site %in% levels(site)[c(1, 5, 9)]) %>%
  STL(box_cox(lininterp_gpp + 1, lambda = 0.5) ~ trend(5*8, degree = 1) + season("1 year", degree = 0))
decomposition %>% 
  autoplot()
```

Multiplicative decompisition with STL with outliers capped (really it would be better to delete but the code doesn't allow that)
```{r stl_decomposition_additive}
edges <- quantile(pggpp$gpp, probs = c(0.01, 0.99), na.rm = TRUE, names = TRUE)
decomposition <- pggpp %>%
  filter(site %in% c("ARCH1", "BELL1")) %>%
  mutate(lininterp_gpp = case_when(lininterp_gpp < edges[[1]] ~ edges[[1]],
                                   lininterp_gpp > edges[[2]] ~ edges[[2]],
                                   TRUE ~ lininterp_gpp)) %>%
  STL(log(lininterp_gpp +1) ~ trend(6*8, degree = 1) + season("1 year", degree = 1))
decomposition %>% 
  autoplot()
```

It is difficult to interpret much from this figure, nothing appears different to when outliers are not capped.

### Classical decomposition
Uses moving averages
```{r classicaldecomp}
pggpp %>%
  filter(sitenum == 1) %>% #keep only first site at each farm
  filter(farm %in% unique(farm)[1:10]) %>%
  classical_decomposition(lininterp_gpp ~ season("1 year"), type = "multiplicative") %>%
  autoplot()
```

The seasonal variation and the trend variation are both smaller than the remainder! 
Furthermore the remainders appear to be autocorellated - suggestions decomposition is missing systematic parts.
Interesting that the trend says roughly constant for a year over spring, for many of the years.

##  Correlation Between Precipitation Derivatives
It seems like precipitation has a maximum impact *once a place is very wet, more rain isn't going to make it grow faster*. This means that the effect of precipitation in the last month depends on the precipitation over the last 6 months (i.e. there is interaction). The effect will also interact with the GPP of that site of that particular day in past years.

 + Use cumulative-monthly precipitation (backwards in time?)
 + Use monthly precipitation with interactions between months?
 + Use seasonal residuals of precipitation?
 + Use interactions between cumulative precipitation and season, and past GPP?
 
*The goal:* detect differences in how a farms GPP responds to  rainfall. Most likely the observed GPP will spike and then as farmers add more animals it will return to normal levels. We expect over-grazing will lead to smaller/non-existent spikes.

*Proposal:* high rate of change in GPP will correspond to spikes. For gpp sufficiently high, grazing is increased to maximise profits and the GPP increase is slower. This suggests a model for the rate of GPP change as a function of current/previous GPP, day of the year, and recent rainfall, with interactions between all of these.

+ high GPP ==> low rate of GPP increase regardless of other covariates
+ high rainfall and low GPP ==> high rate of GPP increase
+ moderate rainfall, spring and low GPP ==> moderate rate of GPP increase


### Correlation within rainfall time-series.
#### Cumulative rainfall.
```{r calcumulativerainfall}
pggpp_cumsum <- pggpp %>% 
  group_by_key() %>%
  mutate(pg_cumsum = cumsum(pg)) %>%
  mutate(pg_1to8 = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 8), # 1 to 8 days behind
         pg_1to16 = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 16), # 1 to 16 days behind
         pg_1to1m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 31),
         pg_1to2m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 2*31),
         pg_1to3m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 3*31),
         pg_1to4m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 4*31),
         pg_1to5m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 5*31),
         pg_1to6m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 6*31),
         pg_1to7m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 7*31),
         pg_1to8m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 8*31),
         )

pggpp_cumsum %>%
  filter(site == "BELL1") %>%
  filter_index("2010") %>%
  pivot_longer(cols = c("pg_1to1m",
                        "pg_1to2m",
                        "pg_1to3m",
                        "pg_1to4m",
                        "pg_1to5m",
                        "pg_1to6m",
                        "pg_1to7m",
                        "pg_1to8m")) %>%
  ggplot() +
  geom_line(aes(x = times, y = value, col = name))
```

In these cumulative amounts you can see that large increases in PG are included in all cumulative amounts (as they all start at 1 day), and that this is not the case for a lack of precipitation.

Should I be looking for linear relationships? Or monotonic relationships? (which correlations to test for?) For a linear model Pearson's Correlation is appropriate I think, but for GAM modelling I think Kendall or Spearman would do better (since they indicate monotonic relationships).
```{r cumulativecorrelations}
cormat <- pggpp_cumsum %>%
  as_tibble() %>%
  #group_by(site) %>%
  select(c("pg", grep("pg_1", names(pggpp_cumsum), value = TRUE))) %>%
  group_map(.f = ~ cor(.x, use = "pairwise.complete.obs"))
reshape2::melt(cormat[[1]], value.name = "Pearson Correlation") %>%
  ggplot() +
  geom_tile(aes(x = Var1, y = Var2, fill = `Pearson Correlation`)) +
  geom_text(aes(x = Var1, y = Var2, label = format(`Pearson Correlation`, digits = 1))) +
  scale_fill_viridis_c() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  ggtitle("Pearson Correlation between cumulative precipitation averaged across all sites")
```

The correlations between first 8, 16, 1 month, 2 month and 3 month are not prohibitively high (up to 0.88) I think. But correlatations between longer cumulative rainfalls (3m, 4m. 5m, ...) is getting really high. 
Suppose we wanted to fit only using predictors with correlation less than 0.9. Could choose:
pg, 8, 16, 1m, 2m, 3m, 5m, 8m.

Is this overall correlation matched within groups?
```{r cumulativecorrelations_grouped}
cors <- pggpp_cumsum %>%
  as_tibble() %>%
  group_by(site) %>%
  select(c("pg", grep("pg_1", names(pggpp_cumsum), value = TRUE))) %>%
  group_map(.f = ~ cor(.x, use = "pairwise.complete.obs"))
cors <- c(cors, cormat)
names(cors) <- c(as.character(group_keys(pggpp_cumsum)$site), "all")
corsmelt <- lapply(cors, function(x) reshape2::melt(x - cormat[[1]], value.name = "Diff Pearson Correlation"))
corstbl <- bind_rows(corsmelt, .id = "site")

corstbl %>%
    mutate(farm = substr(site, 1, 4),
         sitenum = as.integer(substr(site, 5, 5))) %>%
  filter(site %in% c(paste0(unique(farm), "1"), "all")) %>%
  ggplot() +
  facet_wrap(~ site) +
  geom_tile(aes(x = Var1, y = Var2, fill = `Diff Pearson Correlation`)) +
  scale_fill_viridis_c(limits = extendrange(r = range(corstbl$`Diff Pearson Correlation`), 0.1)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  coord_fixed() +
  theme(strip.text.x = element_text(size = 8)) +
  ggtitle("Pearson Correlation between cumulative precipitation for each farm")
```
 
 The range of difference in correlation computer per-site or across sites is `r range(corstbl$`Diff Pearson Correlation`)`. It is small enough that I think the correlation assessment of all sites together is enough, and that the suggested less-correlated variables of pg, 8, 16, 1m, 2m, 3m, 5m, 8m could work well.

#### Spearman Rank Correlation for Investigating Monotonic Function Relationships
```{r cumulativecorrelations_spearman}
cormat <- pggpp_cumsum %>%
  as_tibble() %>%
  #group_by(site) %>%
  select(c("pg", grep("pg_1", names(pggpp_cumsum), value = TRUE))) %>%
  group_map(.f = ~ cor(.x, use = "pairwise.complete.obs", method = "spearman"))
reshape2::melt(cormat[[1]], value.name = "Spearman Correlation") %>%
  ggplot() +
  geom_tile(aes(x = Var1, y = Var2, fill = `Spearman Correlation`)) +
  geom_text(aes(x = Var1, y = Var2, label = format(`Spearman Correlation`, digits = 1))) +
  scale_fill_viridis_c() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  ggtitle("Spearman Correlation between cumulative precipitation averaged across all sites")
```

The above Spearman correlation has a similar message to the Pearson's correlation earlier. Thus choosing pg, 8, 16, 1m, 2m, 3m, 5m, 8m continues to be a good option.

```{r cumulativecorrelations_grouped_spearman}
cors <- pggpp_cumsum %>%
  as_tibble() %>%
  group_by(site) %>%
  select(c("pg", grep("pg_1", names(pggpp_cumsum), value = TRUE))) %>%
  group_map(.f = ~ cor(.x, use = "pairwise.complete.obs", method = "spearman"))
cors <- c(cors, cormat)
names(cors) <- c(as.character(group_keys(pggpp_cumsum)$site), "all")
corsmelt <- lapply(cors, function(x) reshape2::melt(x - cormat[[1]], value.name = "Diff Spearman Correlation"))
corstbl <- bind_rows(corsmelt, .id = "site")

corstbl %>%
    mutate(farm = substr(site, 1, 4),
         sitenum = as.integer(substr(site, 5, 5))) %>%
  filter(site %in% c(paste0(unique(farm), "1"), "all")) %>%
  ggplot() +
  facet_wrap(~ site) +
  geom_tile(aes(x = Var1, y = Var2, fill = `Diff Spearman Correlation`)) +
  scale_fill_viridis_c(limits = extendrange(r = range(corstbl$`Diff Spearman Correlation`), 0.1)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  coord_fixed() +
  theme(strip.text.x = element_text(size = 8)) +
  ggtitle("Spearman Correlation between cumulative precipitation for each farm")
```

Again the difference between the Spearman correlation of each site, and the Spearman correlation ignoring sites is small, with a range of `r range(corstbl$`Diff Spearman Correlation`)`. Thus interpretation of the all-in Spearman correlations is sufficient.
 
### Add seasonal precipitation residuals
First attempt is to use STL decomposition (which is smoothing), which can't actually *predict* seasonal precipitation so could be bad use!
```{r seasonalprecipitation}
decomposepg <- pggpp %>%
  group_by_key() %>%
  STL(pg ~ season(period = "1 year", window = "periodic"), iterations = 3)
decomposepg <- decomposepg %>%
  inner_join(pggpp, by = NULL)
decomposepg %>%
  filter(sitenum == 1) %>% #keep only first site at each farm
  filter(farm %in% unique(farm)[c(1, 5, 10)]) %>%
  filter_index("2011") %>%
  ggplot() +
  facet_wrap(~ site) +
  geom_line(aes(x = times, y = trend + `season_1 year`), col = "blue") +
  geom_point(aes(x = times, y = pg), size = 0.1) 
```

Lets try an actual model! Zero-inflated distribution: Tweedie with 1 < p < 2.
First lets get experience looking at the histograms of the pg data and tweedie distributions.
```{r tweedieeg}
library(tweedie)
invisible(tweedie.plot(seq(0, 30, by = 0.1), mu = 0.2, phi = 0.5, power = 1.2))
```
```{r tweedieforpg}
prop0 <- mean(pggpp$pg == 0)
pggpp %>% 
  ggplot() +
  geom_histogram(aes(x = pg, y = stat(density) * (1 - prop0)), data = function(x) x %>% filter(pg > 0), bins = 30, col = "grey") +
  geom_density(aes(x = pg, y = stat(density) * (1 - prop0)), data = function(x) x %>% filter(pg > 0)) +
  geom_point(aes(x = 0, y = prop0)) +
  xlim(0, 40)
```


```{r fitgamwithtweedie_BELL1}
library(mgcv)
pgmodel <- gam(pg ~ s(yday, bs = "cc", k = 20), family = tw(),
             data = pggpp %>% filter(site == "BELL1"),
             knots = list(yday = c(0, 10)))
plot(pgmodel)
gam.check(pgmodel)
acf(pgmodel$residuals)
```

The QQ plot suggests that the distribution of observed residuals matches the assumption of a Tweedie distribution (with fitted p).
The ACF plot suggests some autocorrelation of level 1.

Given that the distribution of residuals is a non-symmetric distribution (Tweedie == gamma-poisson compound), then I wonder if using them makes sense for predicting gpp.

Trying using autocorrelation and the `p` found above.
```{r fitgamwithtweedie_BELL1}
library(mgcv)
pgmodel_AR1 <- gamm(pg ~ s(yday, bs = "cc", k = 20), family = Tweedie(p = 1.781, link = "log"),
             data = pggpp %>% filter(site == "BELL1"),
             correlation = corAR1(form = ~1),
             knots = list(yday = c(0, 10)))
plot(pgmodel_AR1$gam)
plot(pgmodel_AR1$lme)
acf(pgmodel_AR1$lme$residuals[, 1])
gam.check(pgmodel_AR1$gam)
acf(pgmodel_AR1$gam$residuals)
```

Fitting took a LONG time, and this just for a single site.
I expected the correlations of the residuals to drop, but they didn't.
Also I do not know what the piecewise-linear nature of the QQ plot means.

I've concluded that the seasonal-residual daily precipitation will not be very useful as the distribution around the seasonal precipitation is highly unsymmetric. The mean daily precipitation as fitted in the above models might be useful though.
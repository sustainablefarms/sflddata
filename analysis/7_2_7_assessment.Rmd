---
title: "Assessment of Two Species Models (experiment 7_2_7)"
author: "Kassel Hingee"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document: 
    collapsed: no
    number_sections: yes
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_root(rprojroot::has_file("DESCRIPTION")))
devtools::load_all(rprojroot::find_root(rprojroot::has_file("DESCRIPTION")))
knitr::opts_chunk$set(echo = TRUE)
library(tibble)
library(dplyr)
library(MCMCpack)
library(mclust)
library(corrplot)
library(coda)
library(runjags)
library(ggplot2)
library(patchwork)
```

```{r varname2type}
varname2type <- function(varnames){
  types <- case_when(
    grepl("lv.coef", varnames) ~ "LV Load",
    grepl("LV", varnames) ~ "LV",
    grepl("^(mu|tau)", varnames) ~ "Comm Param", #parameters of community distributions
    grepl("^u.b", varnames) ~ "Occu Coef",
    grepl("^v.b", varnames) ~ "Detn Coef",
    TRUE ~ "other"
    )
  return(types)
}
```

## Data Import

```{r importdata, echo = FALSE, include = FALSE}
inputdata <- readRDS("./private/data/clean/7_2_4_input_data.rds")
# the following whittle out the covariates that we are interested in the residual diagnostics
detcovar <- model.matrix(~ ModelSiteID + MeanWind +  MeanTime + MeanClouds + MeanTemp + ObserverId - 1,
             data = inputdata$insampledata$yXobs) %>%
  as_tibble() %>% rename(ModelSite = ModelSiteID)
occcovar <- model.matrix(~ ModelSiteID + os + ms * NMdetected + gc - 1,
             data = inputdata$insampledata$Xocc) %>%
  as_tibble() %>% rename(ModelSite = ModelSiteID)
```
```{r importmodelfits}
modelspecs <- list(
  interceptsonly = list(OccFmla = "~ 1",
                        ObsFmla = "~ 1"),
  ms =  list(OccFmla = "~ 1 + ms",
             ObsFmla = "~ 1"),
  os_ms =  list(OccFmla = "~ 1 + os + ms",
                ObsFmla = "~ 1"),
  os_ms_nm       = list(OccFmla = "~ 1 + os + ms + NMdetected",
                        ObsFmla = "~ 1 "),
  os_ms_nm_gc    = list(OccFmla = "~ 1 + os + ms + NMdetected + gc",
                        ObsFmla = "~ 1 "),
  os_msnm_gc     = list(OccFmla = "~ 1 + os + ms * NMdetected + gc",
                        ObsFmla = "~ 1 "),
  msnm_time      = list(OccFmla = "~ 1 + ms * NMdetected ",
                        ObsFmla = "~ 1 + MeanTime"),
  msnm_time_temp = list(OccFmla = "~ 1 + ms * NMdetected",
                        ObsFmla = "~ 1 + MeanTime + MeanTemp"),
  msnm_timetemp  = list(OccFmla = "~ 1 + ms * NMdetected",
                        ObsFmla = "~ 1 + MeanTime * MeanTemp"))

modelspecs <- sapply(names(modelspecs), function(x) {
  modspec <- modelspecs[[x]]
  modspec$filename <- paste0("./tmpdata/twospecies_", x,".rds")
  return(modspec)},
  USE.NAMES = TRUE,
  simplify = FALSE)

filenames <- lapply(modelspecs, function(x) x$filename)

# test loading models
a <- vapply(filenames, file.exists, FUN.VALUE = FALSE)
stopifnot(all(a))

# load and remove crosscorrelation
fittedmods <- lapply(filenames, function(x) {
  fit <- readRDS(x)
  return(fit)})
```

```{r import_lpd}
lpds_l <- readRDS("./tmpdata/7_2_7_lpds.rds")
waics_l <- readRDS("./tmpdata/7_2_7_waics.rds")
```

```{r mcmctime}
cat("MCMC time:\n")
lapply(fittedmods, function(x) {
  if (!is.null(x$timetaken)) {return(runjags::timestring(as.numeric(x$timetaken, units="secs")))}
  else return(NULL)})
```

The two species models were incredibly quick to fit.

## MCMC Assessment
### Autocorrelation 
```{r autocorr_fromsummary}
mergedsummaries <- bind_rows(lapply(fittedmods, function(x) as_tibble(x$summaries, rownames = "varname")),
                             .id = "Model") %>%
  mutate(AC_10 = case_when(
    is.finite(AC.400) ~ AC.400,
    TRUE ~ as.numeric(NA)))
mergedsummaries %>%
  mutate(type = varname2type(varname)) %>%
  ggplot() +
  facet_grid(rows = vars(type), cols = vars(Model), scales = "free_y") +
  geom_histogram(aes(x = AC_10), bins = 30) +
  geom_vline(aes(xintercept = 0.1), col = "red") +
  scale_y_continuous(name = "Number of Parameters")
```

Autocorrelation across 10 samples was very low for all models.

### Convegence (Geweke)
See http://www.ugrad.stat.ubc.ca/R/library/coda/html/geweke.diag.html for a very quick description of this.
The Geweke values are Z-scores (technically t-distributed in this situation?).
95% of (independent) Geweke values should be within 2 standard deviations (i.e. just 2 for Z-scores) of the mean.
The below assumes the Geweke value for parameter is also *independent*, even in the situation of converged MCMC.

```{r gewekesumm}
gwk <- bind_rows(lapply(fittedmods, 
       function(x) enframe(geweke.diag(x, frac1=0.1, frac2=0.5)$z, name = "varname")),
       .id = "Model")
gwk %>%
  mutate(type = varname2type(varname)) %>%
  ggplot() +
  facet_grid(rows = vars(type), cols = vars(Model)) +
  geom_abline(slope = 1, intercept = 0, lty = "dashed") +
  geom_qq(aes(sample = value), shape = "+", size = 2) +
  coord_cartesian(ylim = c(-5, 5)) +
  ggtitle("QQ Plots of Geweke Statistics for Each Model Parameter")
```


```{r swstatistics, rows.print = 14}
gwk %>%
  mutate(type = varname2type(varname)) %>%
  group_by(Model, type) %>%
  filter(Model != "interceptsonly") %>%
  filter(Model != "ms", type != "Detn Coef") %>%
  summarise(swp = shapiro.test(value)$p.value) %>%
  ggplot() +
  facet_wrap(~type) +
  geom_vline(aes(xintercept = 0.01)) +
  geom_point(aes(y = Model, x = swp, col = Model)) + 
  scale_x_continuous(name = "Shapiro-Wilk p-value",
                     trans = "identity") +
  ggtitle("Geweke Convergence Statistics Normality Tests",
          subtitle = "0.01 threshold shown")
```

Convergence is ok for all models. However, the qq plot of os_msnm_gc has me worried.

### Multi Chain Gelman-Rubin Statistic (aka "Rhat" or psrf)
Values less than 1.1 are desired.

```{r gelmanrubin}
psrfs <- lapply(fittedmods, function(x) as_tibble(x$summaries[, "psrf"], rownames = "varname"))
psrfs_df <- bind_rows(psrfs, .id = "Model")

psrfs_df %>%
  mutate(type = varname2type(varname)) %>%
  ggplot() +
  facet_grid(rows = vars(type), cols = vars(Model), scales = "free_y") +
  geom_point(aes(y = varname, x = value) ) +
  geom_vline(xintercept = 1.1, col = "blue", lty = "dashed") +
  scale_y_discrete(name = "Variable Name") +
  scale_x_continuous(name = "Gelman-Rubin Statistic")
```

The MCMC chains converged very well according to all parameters and the Gelman-Rubin statistic.

### Conclusions
All MCMC chains are usuable.

## Compare Covariate Loadings
```{r occupancycovariateloadings}
u.b_median <- function(fit) {
  fit$data <- as_list_format(fit$data)
  theta <- get_theta(fit, type = "median")
  u.b <- bugsvar2matrix(theta, "u.b", 1:fit$data$n, 1:fit$data$Vocc)
  colnames(u.b) <- names(fit$XoccProcess$center)
  rownames(u.b) <- fit$species
  u.b <- as_tibble(u.b, rownames = "Species")
  return(u.b)
}
u.b_l <- lapply(fittedmods, u.b_median)
u.b_longer <- lapply(u.b_l,
                     function(x) pivot_longer(x, -Species, names_to = "Covariate", values_to = "CovariateValue"))
df <- bind_rows(u.b_longer, .id = "Model")

df %>%
  ggplot() +
  facet_wrap(vars(Covariate), nrow = 1) +
  geom_point(aes(y = Species, x = CovariateValue,
                 col = Model,
                 shape = Model),
             position = position_jitter(height = 0.1)) +
  scale_color_viridis_d() +
  scale_shape_manual(values = rep(0:5, 3)) +
  ggtitle("Occupancy Covariate Loadings per Species and Model")
```

Occupancy covariate loadings are very similar between models. Models os_ms_nm_gc, os_ms_nm, os_ms, ms appear to have a slighlty different loading for midstorey than the models msnm_time, msnm_time_temp, msnm_timetemp, os_msnm_gc, which all have an interaction term between midstorey and noisy minor.
A similar situation for NMdetected for models with or without interaction with midstorey.

```{r detectioncovariateloadings}
v.b_median <- function(fit) {
  fit$data <- as_list_format(fit$data)
  theta <- get_theta(fit, type = "median")
  v.b <- bugsvar2matrix(theta, "v.b", 1:fit$data$n, 1:fit$data$Vobs)
  colnames(v.b) <- names(fit$XobsProcess$center)
  rownames(v.b) <- fit$species
  v.b <- as_tibble(v.b, rownames = "Species")
  return(v.b)
}
v.b_l <- lapply(fittedmods, v.b_median)
v.b_longer <- lapply(v.b_l,
                     function(x) pivot_longer(x, -Species, names_to = "Covariate", values_to = "CovariateValue"))
df <- bind_rows(v.b_longer, .id = "Model")

df %>%
  ggplot() +
  facet_wrap(vars(Covariate), nrow = 1) +
  geom_point(aes(y = Species, x = CovariateValue,
                 col = Model,
                 shape = Model),
             position = position_jitter(height = 0.1)) +
  scale_color_viridis_d() +
  scale_shape_manual(values = rep(0:5, 3)) +
  ggtitle("Detection Covariate Loadings per Species and Model")
```

Interaction between MeanTime and MeanTemp had a large impact on the MeanTemp loading.

## Model Comparisons
### Log Posterior Density
```{r holdoutlpd}
lpds_df <- as_tibble(do.call(cbind, lapply(lpds_l, function(x) x$lpds)))
melpd <- data.frame(Estimate = apply(lpds_df, 2, mean),
                    SE = apply(lpds_df, 2, sd) / sqrt(nrow(lpds_df)))

mean_2se <- function(x, mult = 2){
  n <- length(x)
  xbar <- sum(x)/n
  sd <- sqrt(sum((x - xbar)^2)/(n - 1))
  return(c(ymin = xbar - mult * sd / sqrt(n),
           y = xbar,
           ymax = xbar + mult * sd / sqrt(n)))
}

lpds_df %>%
  as_tibble() %>%
  rowid_to_column(var = "HoldOutModelSite") %>%
  tidyr::pivot_longer(-HoldOutModelSite, names_to = "model", values_to = "Site_lpd") %>%
  ggplot() +
  facet_grid(rows = vars(model), scales = "free_y") +
  geom_violin(aes(x = Site_lpd, y = model)) +
  stat_summary(aes(x = Site_lpd, y = model),
               fun.data=mean_2se, fun.args = list(mult=2), geom="crossbar", width=0.2 ) +
  stat_summary(aes(x = Site_lpd, y = model),
               fun = median, geom = "point", shape = 23, size = 2) +
  ggtitle("Log-Posterior Density of Holdout ModelSites")
```

Mean lpd for holdout data is not very discriminatory, yet the distributions of lpd are obviously very different. 
Median lpd is a little more discriminatory.

Below is the lpd computed for each ModelSite for both the InSample and out of sample data.

```{r distributioninsampleoutsamplelpd}
insamplelpds_df <- do.call(cbind, lapply(waics_l, function(x) x$waic$pointwise[, "elpd_waic"])) %>%
  as_tibble() %>% mutate(InSample = TRUE)

df <- lpds_df %>% as_tibble() %>% mutate(InSample = FALSE)

df <- bind_rows(insamplelpds_df, df)


df %>%
  as_tibble() %>%
  tidyr::pivot_longer(-InSample, names_to = "model", values_to = "site_lpd") %>%
  ggplot() +
  facet_grid(rows = vars(model), scales = "free_y", switch = "y") +
  geom_violin(aes(x = site_lpd, y = InSample, col = InSample), position = position_dodge(1)) +
  stat_summary(aes(x = site_lpd, y = InSample, group = InSample),
               fun.data=mean_2se, fun.args = list(mult=2), geom="crossbar", width=0.2 ) +
  theme(strip.text.y.left = element_text(angle = 0)) +
  ggtitle("Log Posterior Density of ModelSites")
```

There are clear losers in some of these models (msnm_timetemp), but on the whole they are all very similar. Note that WAIC values are different because they adjust for the insample bias.

```{r waics}
waics_average_elpd_per_point <- lapply(waics_l, function(x) x$waic$estimates["elpd_waic", ]/nrow(x$waic$pointwise))
waics_average_elpd_per_point <- simplify2array(waics_average_elpd_per_point)
waics_average_elpd_per_point <- t(waics_average_elpd_per_point) %>% as_tibble(rownames = "Model")
waics_average_elpd_per_point$type = "WAIC"

loo_average_elpd_per_point <- lapply(waics_l, function(x) x$loo$estimates["elpd_loo", ]/nrow(x$waic$pointwise))
loo_average_elpd_per_point <- simplify2array(loo_average_elpd_per_point)
loo_average_elpd_per_point <- t(loo_average_elpd_per_point) %>% as_tibble(rownames = "Model")
loo_average_elpd_per_point$type = "LOO-PSIS"

melpd$type <- "Holdout"
melpd <- as_tibble(melpd, rownames = "Model")

df <- bind_rows(waics_average_elpd_per_point, loo_average_elpd_per_point, melpd)

df %>%
  ggplot() +
  geom_errorbar(aes(x = Model, ymax = Estimate +  2*SE, ymin = Estimate - 2*SE, col = type, lty = type)) +
  geom_point(aes(x = Model, y = Estimate, col = type), position = position_jitter(width = 0.1)) +
  coord_flip() +
  ggtitle("Estimates of Log Posterior Density for a new ModelSite",
          subtitle = "Holdout estimate is the mean lpd of holdout sites")
```

Many of the models are only as good as the intercept-only model according to the WAIC.
Curiously the mean holdout lpd increases slightly for the models with the worst WAIC.
This is *not* due to the WAIC bias adjustment.
**How is this possible?**

### Expected Number of Detections for Each Species
```{r numdetections}
obsdetections <- colSums(fittedmods[[1]]$data$y)

Edetections <- lapply(fittedmods,
                      function(x) colSums(Endetect_modelsite(x,
                                            conditionalLV = (!is.null(x$data$nlv) && (x$data$nlv > 0) ))
                                          )
                      )
Edetections <- simplify2array(Edetections)
# Edetections[names(obsdetections), "Observed"] <- obsdetections



Edetections %>% 
  as_tibble(Edetections, rownames = "Species") %>%
  tidyr::pivot_longer(cols = -Species, names_to = "Model", values_to = "E_Ndetections") %>%
  ggplot() +
  geom_point(aes(x = E_Ndetections, y = Species, col = Model, shape = Model)) +
  scale_color_viridis_d() +
  scale_shape_manual(values = rep(0:5, 3)) +
  geom_point(aes(x = Detections, y = Species), data = obsdetections %>% enframe(name = "Species", value = "Detections"),
             shape = "|",
             size = 10,
             inherit.aes = FALSE) +
  ggtitle("Expected Number of Detections vs Observed")
```


### Quick check of residual distribution for all models
Note that there are too many data points to apply the shapiro-Wilks normality test directly, however the Anderson-Darling test can be applied. I do not know enough about this test yet to know if it can be fully trusted.

```{r all_resid_occ_normality}
resid_occ_l <- lapply(fittedmods, ds_occupancy_residuals.fit, type = "median", seed = 321, conditionalLV = FALSE)
# vapply(resid_occ_l, function(x) shapiro.test(sample(unlist(x[, -1]), 5000))$p.value, FUN.VALUE = 3.3)
vapply(resid_occ_l, function(x) goftest::ad.test(unlist(x[, -1]))$p.value, FUN.VALUE = 3.3)
as_tibble(lapply(resid_occ_l, function(x) unlist(x[, -1]))) %>%
  pivot_longer(everything(), names_to = "Model", values_to = "Residual") %>%
  ggplot() +
  geom_qq(aes(sample = Residual)) +
  geom_abline(slope = 1, intercept = 0, lty = "dashed") +
  facet_grid(cols = vars(Model)) +
  ggtitle("Occupancy Residual Disribution: qq plots")
```


```{r all_resid_det_normality}
resid_det_l <- lapply(fittedmods, ds_detection_residuals.fit, type = "median", seed = 321)
vapply(resid_det_l, function(x) {
  vals <- unlist(x[, -1])
  vals <- vals[!is.na(vals)]
  goftest::ad.test(vals)$p.value},
  FUN.VALUE = 3.3)
as_tibble(lapply(resid_det_l, function(x) unlist(x[, -1]))) %>%
  pivot_longer(everything(), names_to = "Model", values_to = "Residual") %>%
  ggplot() +
  geom_qq(aes(sample = Residual)) +
  geom_abline(slope = 1, intercept = 0, lty = "dashed") +
  facet_grid(cols = vars(Model)) +
  ggtitle("Detection Residual Distribution: qq plots")
```



### Occupancy Residuals
```{r residocc_plots_manymodels}
seeds = c(321, 120, 6545, 65498, 63)
df_l <- lapply(seeds, function(x) {
  resid_occ_l <- lapply(fittedmods, ds_occupancy_residuals.fit, type = "median", seed = x, conditionalLV = FALSE)
  resid_occ_df <- bind_rows(resid_occ_l, .id = "Model")
  df <- resid_occ_df %>%
    pivot_longer(-c(ModelSite, Model),
                   names_to = "Species",
                   values_to = "Residual",
                   values_drop_na = TRUE) %>%
    left_join(occcovar %>% 
                pivot_longer(-ModelSite,
                   names_to = "Covariate",
                   values_to = "CovariateValue"),
              by = "ModelSite")
  return(df)
})
names(df_l) <- seeds
df <- bind_rows(df_l, .id = "seed")

plt <- df %>%
  ggplot() +
  ggplot2::geom_point(aes(x = CovariateValue, y = Residual), data = function(x) x[x$seed == seeds[[1]], ])
  
plt <- plt + ggplot2::geom_smooth(aes(x = CovariateValue, y = Residual, col = seed), method = "gam", level = 0.95, formula = y ~ s(x, bs = "cs"))

plt <- plt +
  ggplot2::facet_grid(rows = vars(Model), cols = vars(Covariate), as.table = TRUE, scales = "free_x") +
  ggplot2::geom_hline(yintercept = 0, col = "blue", lty = "dashed") +
  ggplot2::scale_x_continuous(name = "Covariate Value") +
  scale_y_continuous(name = "Occupancy Residual")
plt + coord_cartesian(ylim = c(-0.1, 0.1)) + ggtitle("Occupancy Residuals vs Covariates") +
  theme(strip.text.y.right = element_text(angle = 0))
```


### Detection Residuals
```{r residdet_plots_manymodels}
seeds = c(321, 120, 6545, 65498, 63)
df_l <- lapply(seeds, function(x) {
  resid_det_l <- lapply(fittedmods, ds_detection_residuals.fit, type = "median", seed = x)
  resid_det_df <- bind_rows(resid_det_l, .id = "Model")
  df <- resid_det_df %>%
    pivot_longer(-c(ModelSite, Model),
                   names_to = "Species",
                   values_to = "Residual",
                   values_drop_na = TRUE) %>%
    left_join(detcovar %>% 
                pivot_longer(-ModelSite,
                   names_to = "Covariate",
                   values_to = "CovariateValue"),
              by = "ModelSite")
  return(df)
})
names(df_l) <- seeds
df_det <- bind_rows(df_l, .id = "seed")

plt <- df_det %>%
  ggplot() +
  ggplot2::geom_point(aes(x = CovariateValue, y = Residual), data = function(x) x[x$seed == seeds[[1]], ])
  
plt <- plt + ggplot2::geom_smooth(aes(x = CovariateValue, y = Residual, col = seed), method = "gam", level = 0.95, formula = y ~ s(x, bs = "cs"))

plt <- plt +
  ggplot2::facet_grid(rows = vars(Model), cols = vars(Covariate), as.table = TRUE, scales = "free_x") +
  ggplot2::geom_hline(yintercept = 0, col = "blue", lty = "dashed") +
  ggplot2::scale_x_continuous(name = "Covariate Value") +
  scale_y_continuous(name = "Detection Residual")
plt + coord_cartesian(ylim = c(-0.1, 0.1)) + ggtitle("Detection Residuals vs Covariates")  +
  theme(strip.text.y.right = element_text(angle = 0))
```


## Conclusions
Log posterior density and WAIC behaved very strangely for these models.


### Next Steps

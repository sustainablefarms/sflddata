---
title: "LIND1 GPP vs PG fit"
author: "Kassel Hingee"
date: "03/04/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
out <- lapply(c("sf", "tsibble", 'lubridate', "viridis",
                'ggplot2', 'tidyr', 'grid', 'gridExtra', 
                'feasts', 'dplyr', 'gtable', 'fable',
                'mgcv'),
       library, character.only = TRUE)
out <- lapply(paste0("../functions/", list.files("../functions/")), source)
```

```{r preparedata}
#load data and convert to tsibbles
load("../private/data/remote_sensed/pg_daily.Rdata")
pg_daily$times <- as_date(pg_daily$times)
pg <- pg_daily %>%
  pivot_longer(-times, names_to = "site", values_to = "pg") %>%
  as_tsibble(key = site, index = times)
load("../private/data/remote_sensed/gpp_8d.Rdata")
gpp <- gpp_8d %>%
  pivot_longer(-times, names_to = "site", values_to = "gpp") %>%
  as_tsibble(key = site, index = times)
pggpp <- as_tsibble(dplyr::full_join(pg, gpp, by = c("times", "site")), key = site, index = times)

# add times breakdowns
pggpp <- pggpp %>%
  mutate(yday = yday(times),
         year = year(times))
  

#interpolate gpp
pggpp <- pggpp %>%
  group_by_key() %>% #key is site
  mutate(lininterp_gpp = zoo::na.approx(gpp, rule = 2, na.rm = FALSE)) %>% #rule 2 means edges are assigned last value
  ungroup()

#make sure sites are ordered alphabetically
pggpp <- pggpp %>%
  arrange(site) %>%
  mutate(site = factor(site, ordered = TRUE))

#separate alpha part of site code
pggpp <- pggpp %>%
  mutate(farm = factor(substr(site, 1, 4)),
         sitenum = factor(as.integer(substr(site, 5, 5))))


# Add cumulative rainfalls
pggpp <- pggpp %>% 
  group_by_key() %>%
  mutate(pg_cumsum = cumsum(pg)) %>%
  mutate(pg_1to7 = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 8), # 1 up to 8 days behind (excluding 8th day)
         pg_1to15 = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 16), # 1 to 16 days behind
         pg_1to1m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 31),
         pg_1to2m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 2*31),
         pg_1to3m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 3*31),
         pg_1to4m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 4*31),
         pg_1to5m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 5*31),
         pg_1to6m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 6*31),
         pg_1to7m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 7*31),
         pg_1to8m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 8*31),
         pg_1to10m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 10*31),
         pg_1to12m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 12*31),
         pg_1to14m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 14*31),
         ) %>%
  mutate(pg_8d = (pg_cumsum - lag(pg_cumsum, n = 8))/8.0,
         #0 to day 7 (8 days) cumulative rainfall to correspond with gaps in GPP
         pg_24d = (pg_cumsum - lag(pg_cumsum, n = 3*8)) / 24) %>% 
         # every 24 days (3*8) of GPP should be less correlated (given average GPP), this pg_24d corresponds to the rain through that period
  ungroup()
```

```{r seasonalreferences}
# simple median of values
ydaymedian <- pggpp %>%
  filter(yday %in% seq(1, 366, by = 8)) %>%
  group_by(site) %>%
  index_by(yday) %>%
  summarise(gpp.ydaymed = median(gpp),
            pg_8d.ydaymed = median(pg_8d),
            pg_24d.ydaymed = median(pg_24d),
            pg_1to5m.ydaymed = median(pg_1to5m, na.rm = TRUE))
pggpp <- left_join(pggpp, ydaymedian, by = c("site", "yday"))
```

```{r preparetraintest}
train <- pggpp %>%
  filter(yday %in% seq(1, 366, by = 8)) %>%
  filter(sitenum == 1) %>% #so not doubling up at farms
  filter_index(. ~ "2016-12-31") %>%
  dplyr::select(-pg_cumsum, -lininterp_gpp) %>%
  mutate(gpp = if_else(gpp < 0.1, as.double(NA), gpp)) #remove outlying GPP values that are super low

test <- pggpp %>%
  filter_index("2017-01-01" ~ .) %>%
  filter(sitenum == 1) %>% #so not doubling up at farms
  filter(yday %in% seq(1, 366, by = 8)) %>%
  dplyr::select(-pg_cumsum)
```


In the above very small GPP values have been removed. There was `r sum(is.na(train$gpp))` of them, which corresponds to `r sum(is.na(train$gpp)) / length(train$gpp)` of the data.

## Site LIND1
```{r select_pggpp_for_lind1}
train <- train %>%
  filter(site == "LIND1")
```

```{r view_lind1}
train %>%
  mutate(st_gpp = gpp / gpp.ydaymed) %>%
  pivot_longer(cols = c("st_gpp", "pg_8d", "pg_24d")) %>%
  ggplot() +
  geom_line(aes(x = yday, y = value, col = name)) +
  facet_wrap(vars(year)) +
  ylim(c(0, 10))
```


### Attempt a garch model
`garch()` from `tseries` package does not appear to allow external predictors.
Similarly the `fGarch` package does not have any ability for external regressors.
However the `rugarch` package does.

```{r garch_m1}
library(rugarch)

filtertrain5 <- function(x){
  x <- x %>% filter(!is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 1 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}

Xproto <- model.frame(~ pg_1to5m * I(1 / pg_1to5m.ydaymed) * pg_24d,
             data = train %>% filtertrain5())
Xproto <- scale(Xproto)
Xscales <- attributes(Xproto)

X <- model.matrix(~ 
              pg_1to5m * I.1.pg_1to5m.ydaymed. * pg_24d,
             data = data.frame(Xproto))[, -1]  #doesn't fit when intercept is included!

Y <- train %>%
  filtertrain5() %>%
  mutate(y = box_cox(gpp / gpp.ydaymed, lambda = 0.1414141)) %>%
  as_tibble() %>%
  select(y) %>%
  as.matrix() %>%
  as.vector()

acfs <- acf(Y)
pacfs <- pacf(Y)

garch_m1_spec <- ugarchspec(variance.model = list(
  model = "sGARCH", garchOrder = c(1, 1)),
  mean.model = list(armaOrder = c(1, 1),
                    external.regressors = X),
  start.pars = list(mu = median(Y),
                    ar1 = pacfs$acf[1, 1, 1],
                    ma1 = acfs$acf[1, 1, 1],
                    alpha1 = 0.8,
                    beta1 = 0.8) )
 

garch_m1 <- ugarchfit(garch_m1_spec, Y,
                      # out.sample = 500,
                      solver = "hybrid",
                      solver.control = list(parallel = TRUE),
                      fit.control = list(stationarity = TRUE, scale = 1))

# print(garch_m1)
plot(garch_m1, which = "all")
infocriteria(garch_m1)
```

```{r fit_withoutstartparameters}
garch_m1_spec <- ugarchspec(variance.model = list(
  model = "sGARCH", garchOrder = c(1, 1)),
  mean.model = list(armaOrder = c(1, 1),
                    external.regressors = X))
 

garch_m1_autostart <- ugarchfit(garch_m1_spec, Y,
                      # out.sample = 500,
                      solver = "hybrid",
                      solver.control = list(parallel = TRUE),
                      fit.control = list(stationarity = TRUE, scale = 1))

# print(garch_m1_autostart)
plot(garch_m1_autostart, which = "all")
tibble(times = zoo::index(fitted(garch_m1_autostart)), fit = as.numeric(fitted(garch_m1_autostart)), actual = Y) %>%
  pivot_longer(cols = c("fit", "actual")) %>%
  ggplot() +
  geom_line(aes(x = times, y = value, col = name, lty = name))
infocriteria(garch_m1_autostart)
show(garch_m1_autostart)
```

The fitted model using automatically determined initial search values satisfies assumptions better, particularly the normal distribution of the residuals. It also has much better information criteria values. I will investigate its predictions in the following.

```{r garch_m1_autostart_prediction}
# fcst_10ahead_uncertainty <- ugarchboot(garch_m1_autostart,
#                            method = "partial", #uncertainy is only in model's randmoness, uncertainty of fitted parameters not included.
#                            n.ahead = 10)

Xtestproto <- model.frame(~ pg_1to5m * I(1 / pg_1to5m.ydaymed) * pg_24d,
             data = test %>% filtertrain5())
Xtestproto <- scale(Xtestproto,
                    center = attr(Xproto, "scaled:center"),
                    scale = attr(Xproto, "scaled:scale"))
Xtest <- model.matrix(~ 
              pg_1to5m * I.1.pg_1to5m.ydaymed. * pg_24d,
             data = data.frame(Xtestproto))[, -1]
Ytest <- test %>%
  filtertrain5() %>%
  mutate(actual = box_cox(gpp / gpp.ydaymed, lambda = 0.1414141)) %>%
  as_tibble() %>%
  select(times, actual)


fcst_test <- ugarchforecast(garch_m1_autostart,
                           external.forecasts = list(mregfor = Xtest),
                           n.ahead = 100)#nrow(Xtest))

fcst_test_df <- tibble(mean = fitted(fcst_test)[, 1], sigma = sigma(fcst_test)[, 1]) %>%
  mutate(upper = mean + sigma, lower = mean - sigma)

fcst_test_df <- cbind(fcst_test_df, Ytest[1:nrow(fcst_test_df), ])

fcst_test_df %>%
  pivot_longer(cols = c("mean","actual")) %>%
  ggplot() +
  geom_ribbon(aes(x = times, ymin = lower, ymax = upper)) +
  geom_line(aes(x = times, y = value, col = name, lty = name))

plot(fcst_test, which = 1)
# plot(fcst_test, which = 3)
# plot(fcst_10ahead, which = 4)
```



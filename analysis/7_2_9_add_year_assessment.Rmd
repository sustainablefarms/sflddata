---
title: "7_2_9 Add Year Experimental Analysis"
author: "Kassel Hingee"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document: 
    collapsed: no
    number_sections: yes
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_root(rprojroot::has_file("DESCRIPTION")))
devtools::load_all(rprojroot::find_root(rprojroot::has_file("DESCRIPTION")))
knitr::opts_chunk$set(echo = FALSE)
library(tibble)
library(dplyr)
library(MCMCpack)
library(mclust)
library(corrplot)
library(coda)
library(runjags)
library(ggplot2)
library(patchwork)
```

```{r varname2type}
varname2type <- function(varnames){
  types <- case_when(
    grepl("lv.coef", varnames) ~ "LV Load",
    grepl("LV", varnames) ~ "LV",
    grepl("^(mu|tau)", varnames) ~ "Comm Param", #parameters of community distributions
    grepl("^u.b", varnames) ~ "Occu Coef",
    grepl("^v.b", varnames) ~ "Detn Coef",
    TRUE ~ "other"
    )
  return(types)
}
```

## Data Import

```{r importdata, echo = FALSE, include = FALSE}
inputdata <- readRDS("./private/data/clean/7_2_8_input_data.rds")
# the following whittle out the covariates that we are interested in the residual diagnostics
detcovar <- model.matrix(~ ModelSiteID + MeanWind +  MeanTime + MeanClouds + MeanTemp + ObserverId - 1,
             data = inputdata$insampledata$yXobs) %>%
  as_tibble() %>% rename(ModelSite = ModelSiteID)
occcovar <- model.matrix(~ SurveyYear + StudyId + ModelSiteID + os + ms * NMdetected + gc - 1,
             data = inputdata$insampledata$Xocc) %>%
  as_tibble() %>% rename(ModelSite = ModelSiteID)
```
```{r importmodelfits}
modelspecs <- readRDS("./tmpdata/7_2_9_modelspecs.rds")
filenames <- lapply(modelspecs, function(x) x$filename)

# test loading models
a <- vapply(filenames, file.exists, FUN.VALUE = FALSE)
stopifnot(all(a))

# load and remove crosscorrelation
fittedmods <- lapply(filenames, function(x) {
  fit <- readRDS(x)
  return(fit)})
```

```{r import_lpd}
lpds_l <- readRDS("./tmpdata/7_2_9_lpds.rds")
waics_l <- readRDS("./tmpdata/7_2_9_waics.rds")
```

```{r cleanersummaries}
cleanersummary <- function(fit) {
  vals <- fit$summaries %>%
    as_tibble(rownames = "bugsvarname") %>%
    mutate(AC_10 = case_when(
      is.finite(AC.400) ~ AC.400,
      TRUE ~ as.numeric(NA))) %>%
    mutate(varname = gsub("\\[.*\\]", "", bugsvarname)) %>%
    mutate(type = varname2type(bugsvarname))
  suppressWarnings(vals <- vals %>%
    mutate(SpeciesIdx = as.integer(gsub("(.*\\[|,.*\\])", "", bugsvarname))) %>%
    mutate(CovarIdx = as.integer(gsub("(.*\\[.*,|\\])", "", bugsvarname))) )
  vals <- vals %>%
    mutate(Species = fit$species[SpeciesIdx]) %>%
    mutate(Covariate = case_when(
      varname == "u.b" ~ colnames(fit$data$Xocc)[CovarIdx],
      varname == "v.b" ~ colnames(fit$data$Xobs)[CovarIdx],
      varname == "LV" ~ as.character(CovarIdx),
      TRUE ~ as.character(NA)
    )) %>% 
    dplyr::select(-SpeciesIdx, -CovarIdx)
  return(vals)
}
cleanersummary_l <- lapply(fittedmods, cleanersummary)
cleanersummaries <- bind_rows(cleanersummary_l, .id = "Model")
```


```{r mcmctime}
cat("MCMC time:\n")
lapply(fittedmods, function(x) {
  if (!is.null(x$timetaken)) {return(runjags::timestring(as.numeric(x$timetaken, units="secs")))}
  else return(NULL)})
```

*Comment on time taken for the MCMC of each model:*

## MCMC Assessment
### Autocorrelation 
```{r autocorr_fromsummary}
cleanersummaries %>%
  ggplot() +
  facet_grid(rows = vars(type), cols = vars(Model), scales = "free_y") +
  geom_histogram(aes(x = AC_10), bins = 30) +
  geom_vline(aes(xintercept = 0.1), col = "red") +
  theme(strip.text.x.top = element_text(angle = 90)) +
  scale_y_continuous(name = "Number of Parameters")
```

The two models with latent variabales have overly high autocorrelation in the latent variables and some community parameter.

### Convegence (Geweke)
See http://www.ugrad.stat.ubc.ca/R/library/coda/html/geweke.diag.html for a very quick description of this.
The Geweke values are Z-scores (technically t-distributed in this situation?).
95% of (independent) Geweke values should be within 2 standard deviations (i.e. just 2 for Z-scores) of the mean.
The below assumes the Geweke value for parameter is also *independent*, even in the situation of converged MCMC.

```{r gewekesumm}
gwk <- bind_rows(lapply(fittedmods, 
       function(x) enframe(geweke.diag(x, frac1=0.1, frac2=0.5)$z, name = "varname")),
       .id = "Model")
gwk %>%
  mutate(type = varname2type(varname)) %>%
  ggplot() +
  facet_grid(rows = vars(type), cols = vars(Model)) +
  geom_abline(slope = 1, intercept = 0, lty = "dashed") +
  geom_qq(aes(sample = value), shape = "+", size = 2) +
  coord_cartesian(ylim = c(-5, 5)) +
  theme(strip.text.x.top = element_text(angle = 90)) +
  ggtitle("QQ Plots of Geweke Statistics for Each Parameter")
```


```{r swstatistics, rows.print = 14}
gwk %>%
  mutate(type = varname2type(varname)) %>%
  group_by(Model, type) %>%
  summarise(swp = shapiro.test(value)$p.value) %>%
  ggplot() +
  facet_wrap(~type) +
  geom_vline(aes(xintercept = 0.01)) +
  geom_point(aes(y = Model, x = swp, col = Model)) + 
  scale_x_continuous(name = "Shapiro-Wilk p-value",
                     trans = "log") +
  ggtitle("Geweke Convergence Statistics Normality Tests",
          subtitle = "0.01 threshold shown")
```

LV values have not converged well. It appears msnm_year did not converge either, but mostly in the community parameters and detection coefficients, which is strange.
I would use the results for models with LV and msnm_year with caution.

### Multi Chain Gelman-Rubin Statistic (aka "Rhat" or psrf)
Values less than 1.1 are desired.

```{r gelmanrubin}
psrfs <- lapply(fittedmods, function(x) as_tibble(x$summaries[, "psrf"], rownames = "varname"))
psrfs_df <- bind_rows(psrfs, .id = "Model")

psrfs_df %>%
  mutate(type = varname2type(varname)) %>%
  ggplot() +
  facet_grid(rows = vars(type), cols = vars(Model), scales = "free_y") +
  geom_point(aes(y = varname, x = value) ) +
  geom_vline(xintercept = 1.1, col = "blue", lty = "dashed") +
  scale_y_discrete(name = "Variable Name") +
  scale_x_continuous(name = "Gelman-Rubin Statistic")
```

Despite the Geweke values, the multichain tests suggest msnm_year has converged well.

### Conclusions
Assessment of models without LVs can be performed safely.
For models with LVs:

+ LV loadings may be ok to use, but great care should be taken for anything that uses more than the mean of the distribution as there is high autocorrelation. *The expected likelihood calculations, which uses a mean across the full distribution of LV loadings, can be trusted, but the standard error is probably an __under estimate__.*
+ LV values did not appear to converge so the first moment of the LV values cannot be trusted. This, for example, means the occupancy residuals cannot be trusted to be indicative of the model specifications.

## Compare Covariate Loadings
```{r occupancycovariateloadings}
cleanersummaries %>%
  dplyr::filter(varname == "u.b") %>%
  ggplot() +
  facet_wrap(vars(Covariate), nrow = 1) +
  geom_hline(yintercept = 0) +
  geom_pointrange(aes(x = Species,
                 ymin = Lower95,
                 ymax = Upper95,
                 y = Median,
                 col = Model,
                 group = Model),
             shape = "|",
             size = 1,
             position = position_dodge(width = 1)) +
  coord_flip() +
  scale_color_viridis_d() +
  theme(strip.text.x.top = element_text(angle = 90)) +
  ggtitle("Occupancy Covariate Loadings per Species and Model")
```
  
Again, very little difference in loadings between models. It appears ms:NMdetected and TWI:woody500m loadings may as well be zero for nearly all species and models.

```{r detectioncovariateloadings}
cleanersummaries %>%
  dplyr::filter(varname == "v.b") %>%
  ggplot() +
  facet_wrap(vars(Covariate), nrow = 1) +
  geom_hline(yintercept = 0) +
  geom_pointrange(aes(x = Species,
                 ymin = Lower95,
                 ymax = Upper95,
                 y = Median,
                 col = Model,
                 group = Model),
             shape = "|",
             size = 1,
             position = position_dodge(width = 1)) +
  coord_flip() +
  scale_color_viridis_d() +
  theme(strip.text.x.top = element_text(angle = 90)) +
  ggtitle("Detection Covariate Loadings per Species and Model")
```

MeanTime is significantly non-zero for many species.
The credible interval for the intercept in detection is quite large for the Australian Pipit and a few other birds.
*Suggests that the models do not model detectability of a species well*

## Log Posterior Density
```{r holdoutlpd}
lpds_df <- as_tibble(do.call(cbind, lapply(lpds_l, function(x) x$lpds)))
melpd <- data.frame(Estimate = apply(lpds_df, 2, mean),
                    SE = apply(lpds_df, 2, sd) / sqrt(nrow(lpds_df)))

mean_2se <- function(x, mult = 2){
  n <- length(x)
  xbar <- sum(x)/n
  sd <- sqrt(sum((x - xbar)^2)/(n - 1))
  return(c(ymin = xbar - mult * sd / sqrt(n),
           y = xbar,
           ymax = xbar + mult * sd / sqrt(n)))
}

lpds_df %>%
  as_tibble() %>%
  rowid_to_column(var = "HoldOutModelSite") %>%
  tidyr::pivot_longer(-HoldOutModelSite, names_to = "model", values_to = "Site_lpd") %>%
  ggplot() +
  # facet_grid(rows = vars(model), scales = "free_y") +
  geom_violin(aes(x = Site_lpd, y = model), adjust = 0.2) +
  stat_summary(aes(x = Site_lpd, y = model),
               fun.data=mean_2se, fun.args = list(mult=2), geom="crossbar", width=0.2 ) +
  stat_summary(aes(x = Site_lpd, y = model),
               fun = median, geom = "point", shape = 23, size = 2) +
  ggtitle("Log-Posterior Density of Holdout ModelSites")
```

It looks like msnm performed the best, with the highest median lpd values for the holdout data. Strangely the median lpds for msnm_year and msnm_year_time are slightly lower. This seems to have been caused by a slightly thicker left tail.
LVs increased the mean lpds of the holdout data a bit (still within statistical uncertainty though). Given the convergence diagnostics the mean lpd for these models can be trusted.

Below is the lpd computed for each ModelSite for both the InSample and out of sample data.


```{r distributioninsampleoutsamplelpd}
insamplelpds_df <- do.call(cbind, lapply(waics_l, function(x) x$waic$pointwise[, "elpd_waic"])) %>%
  as_tibble() %>% mutate(InSample = TRUE)

df <- lpds_df %>% as_tibble() %>% mutate(InSample = FALSE)

df <- bind_rows(insamplelpds_df, df)


df %>%
  as_tibble() %>%
  tidyr::pivot_longer(-InSample, names_to = "model", values_to = "site_lpd") %>%
  ggplot() +
  facet_grid(rows = vars(model), scales = "free_y", switch = "y") +
  geom_violin(aes(x = site_lpd, y = InSample, col = InSample), adjust = 0.2, position = position_dodge(1)) +
  stat_summary(aes(x = site_lpd, y = InSample, group = InSample),
               fun.data=mean_2se, fun.args = list(mult=2), geom="crossbar", width=0.2 ) +
  stat_summary(aes(x = site_lpd, y = InSample, group = InSample),
               fun = median, geom = "point", shape = 23, size = 2) +
  theme(strip.text.y.left = element_text(angle = 0)) +
  ggtitle("Log Posterior Density of ModelSites")
```


```{r waics}
waics_average_elpd_per_point <- lapply(waics_l, function(x) x$waic$estimates["elpd_waic", ]/nrow(x$waic$pointwise))
waics_average_elpd_per_point <- simplify2array(waics_average_elpd_per_point)
waics_average_elpd_per_point <- t(waics_average_elpd_per_point) %>% as_tibble(rownames = "Model")
waics_average_elpd_per_point$type = "WAIC"

loo_average_elpd_per_point <- lapply(waics_l, function(x) x$loo$estimates["elpd_loo", ]/nrow(x$waic$pointwise))
loo_average_elpd_per_point <- simplify2array(loo_average_elpd_per_point)
loo_average_elpd_per_point <- t(loo_average_elpd_per_point) %>% as_tibble(rownames = "Model")
loo_average_elpd_per_point$type = "LOO-PSIS"

melpd$type <- "Holdout"
melpd <- as_tibble(melpd, rownames = "Model")

df <- bind_rows(waics_average_elpd_per_point, loo_average_elpd_per_point, melpd)

df %>%
  ggplot() +
  geom_errorbar(aes(x = Model, ymax = Estimate +  2*SE, ymin = Estimate - 2*SE, col = type, lty = type)) +
  geom_point(aes(x = Model, y = Estimate, col = type), position = position_jitter(width = 0.1)) +
  coord_flip() +
  ggtitle("Estimates of Log Posterior Density for a new ModelSite")
```

After bias correction (WAIC), the expected lpd (elpd) of a new model site is much higher for the two models with LVs with slightly better for msnm_year_time_2lv. The next highest is msnm_year_time.

From both msnm and twiwoody500m:

+ adding year in increases elpd_waic and elpd_holdout
+ adding time increases elpd_waic and elpd_holdout again.


## Expected Number of Detections for Each Species
```{r numdetections}
obsdetections <- colSums(fittedmods[[1]]$data$y)

Edetections <- lapply(fittedmods,
                      function(x) colSums(Endetect_modelsite(x,
                                            conditionalLV = (!is.null(x$data$nlv) && (x$data$nlv > 0) ))
                                          )
                      )
Edetections <- simplify2array(Edetections)
# Edetections[names(obsdetections), "Observed"] <- obsdetections

Edetections %>% 
  as_tibble(Edetections, rownames = "Species") %>%
  tidyr::pivot_longer(cols = -Species, names_to = "Model", values_to = "E_Ndetections") %>%
  ggplot() +
  geom_col(aes(x = Detections, y = Species), data = obsdetections %>% enframe(name = "Species", value = "Detections"),
             alpha = 0.2,
             inherit.aes = FALSE) +
  geom_point(aes(x = E_Ndetections, y = Species, col = Model, shape = Model), inherit.aes = FALSE) +
  scale_color_viridis_d() +
  scale_shape_manual(values = rep(0:5, 3)) +
  theme(legend.position="bottom") +
  scale_x_continuous(name = "Expected Detections") +
  ggtitle("Expected Number of Detections vs Observed")
```

## Quick check of residual distribution for all models
Note that there are too many data points to apply the shapiro-Wilks normality test directly, however the Anderson-Darling test can be applied. I do not know enough about this test yet to know if it can be fully trusted.

```{r all_resid_occ_normality}
resid_occ_l <- lapply(fittedmods, ds_occupancy_residuals.fit, type = "median", seed = 321, conditionalLV = FALSE)
# vapply(resid_occ_l, function(x) shapiro.test(sample(unlist(x[, -1]), 5000))$p.value, FUN.VALUE = 3.3)
vapply(resid_occ_l, function(x) goftest::ad.test(unlist(x[, -1]))$p.value, FUN.VALUE = 3.3)
as_tibble(lapply(resid_occ_l, function(x) unlist(x[, -1]))) %>%
  tidyr::pivot_longer(everything(), names_to = "Model", values_to = "Residual") %>%
  ggplot() +
  geom_qq(aes(sample = Residual)) +
  geom_abline(slope = 1, intercept = 0, lty = "dashed") +
  facet_grid(cols = vars(Model)) +
  ggtitle("Occupancy Residual Distribution: qq plots")
```


```{r all_resid_det_normality}
resid_det_l <- lapply(fittedmods, ds_detection_residuals.fit, type = "median", seed = 321)
vapply(resid_det_l, function(x) {
  vals <- unlist(x[, -1])
  vals <- vals[!is.na(vals)]
  goftest::ad.test(vals)$p.value},
  FUN.VALUE = 3.3)
as_tibble(lapply(resid_det_l, function(x) unlist(x[, -1]))) %>%
  tidyr::pivot_longer(everything(), names_to = "Model", values_to = "Residual") %>%
  ggplot() +
  geom_qq(aes(sample = Residual)) +
  geom_abline(slope = 1, intercept = 0, lty = "dashed") +
  facet_grid(cols = vars(Model)) +
  ggtitle("Detection Residual Distribution: qq plots")
```



## Occupancy Residuals
```{r residocc_plots_manymodels}
seeds = c(321, 120, 6545, 65498, 63)
df_l <- lapply(seeds, function(x) {
  resid_occ_l <- lapply(fittedmods, ds_occupancy_residuals.fit, type = "median", seed = x, conditionalLV = FALSE)
  resid_occ_df <- bind_rows(resid_occ_l, .id = "Model")
  df <- resid_occ_df %>%
    tidyr::pivot_longer(-c(ModelSite, Model),
                   names_to = "Species",
                   values_to = "Residual",
                   values_drop_na = TRUE) %>%
    left_join(occcovar %>% 
                tidyr::pivot_longer(-ModelSite,
                   names_to = "Covariate",
                   values_to = "CovariateValue"),
              by = "ModelSite")
  return(df)
})
names(df_l) <- seeds
df <- bind_rows(df_l, .id = "seed")

treatfactor <- df %>%
  group_by(Covariate) %>%
  summarise(nvals = n_distinct(CovariateValue), .groups = "drop_last") %>%
  filter(nvals <= 10) %>%
  dplyr::select(Covariate) %>%
  unlist()

plt <- df %>%
  ggplot() +
  ggplot2::geom_point(aes(x = CovariateValue, y = Residual), data = function(x) x[x$seed == seeds[[1]], ])

# gam smooths for continuous variables
plt <- plt + ggplot2::geom_smooth(aes(x = CovariateValue, y = Residual, col = seed),
                                  data = function(x) x %>% dplyr::filter(!(Covariate %in% treatfactor)),
                                  method = "gam", level = 0.95, formula = y ~ s(x, bs = "cs"))

# mean + 2SE summaries for discrete variables
plt <- plt + ggplot2::stat_summary(aes(x = CovariateValue, y = Residual, col = seed),
                                  data = function(x) x %>% dplyr::filter(Covariate %in% treatfactor),
                                  geom = "pointrange",
                                  fun.data = mean_se,
                                  fun.args = list(mult = 2),
                                  position = position_dodge(width = 0.1, preserve = "total"),
                                  alpha = 0.8,
                                  lwd = 2,
                                  fatten = 1,
                                  show.legend = FALSE)

plt <- plt +
  ggplot2::facet_grid(rows = vars(Model), cols = vars(Covariate), as.table = TRUE, scales = "free_x") +
  ggplot2::geom_hline(yintercept = 0, col = "blue", lty = "dashed") +
  ggplot2::scale_x_continuous(name = "Covariate Value") +
  scale_y_continuous(name = "Occupancy Residual")
plt + coord_cartesian(ylim = c(-0.1, 0.1)) + ggtitle("Occupancy Residuals vs Covariates") +
  theme(strip.text.y.right = element_text(angle = 0))
```


## Detection Residuals
```{r residdet_plots_manymodels}
seeds = c(321, 120, 6545, 65498, 63)
df_l <- lapply(seeds, function(x) {
  resid_det_l <- lapply(fittedmods, ds_detection_residuals.fit, type = "median", seed = x)
  resid_det_df <- bind_rows(resid_det_l, .id = "Model")
  df <- resid_det_df %>%
    tidyr::pivot_longer(-c(ModelSite, Model),
                   names_to = "Species",
                   values_to = "Residual",
                   values_drop_na = TRUE) %>%
    left_join(detcovar %>% 
                tidyr::pivot_longer(-ModelSite,
                   names_to = "Covariate",
                   values_to = "CovariateValue"),
              by = "ModelSite")
  return(df)
})
names(df_l) <- seeds
df_det <- bind_rows(df_l, .id = "seed")

treatfactor <- df_det %>%
  group_by(Covariate) %>%
  summarise(nvals = n_distinct(CovariateValue), .groups = "drop_last") %>%
  filter(nvals <= 10) %>%
  dplyr::select(Covariate) %>%
  unlist()

plt <- df_det %>%
  ggplot() +
  ggplot2::geom_point(aes(x = CovariateValue, y = Residual), data = function(x) x[x$seed == seeds[[1]], ])

# gam smooths for continuous variables
plt <- plt + ggplot2::geom_smooth(aes(x = CovariateValue, y = Residual, col = seed),
                                  data = function(x) x %>% dplyr::filter(!(Covariate %in% treatfactor)),
                                  method = "gam", level = 0.95, formula = y ~ s(x, bs = "cs"))

# mean + 2SE summaries for discrete variables
plt <- plt + ggplot2::stat_summary(aes(x = CovariateValue, y = Residual, col = seed),
                                  data = function(x) x %>% dplyr::filter(Covariate %in% treatfactor),
                                  geom = "pointrange",
                                  fun.data = mean_se,
                                  fun.args = list(mult = 2),
                                  position = position_dodge(width = 0.1, preserve = "total"),
                                  alpha = 0.8,
                                  lwd = 2,
                                  fatten = 1,
                                  show.legend = FALSE)

  
plt <- plt +
  ggplot2::facet_grid(rows = vars(Model), cols = vars(Covariate), as.table = TRUE, scales = "free_x") +
  ggplot2::geom_hline(yintercept = 0, col = "blue", lty = "dashed") +
  ggplot2::scale_x_continuous(name = "Covariate Value") +
  scale_y_continuous(name = "Detection Residual")
plt + coord_cartesian(ylim = c(-0.1, 0.1)) + ggtitle("Detection Residuals vs Covariates") +
  theme(strip.text.y.right = element_text(angle = 0))
```


## Conclusions

### Next Steps

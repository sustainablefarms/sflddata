---
title: "Very Simple Models for GPP"
author: "Kassel Hingee"
date: "24/01/2020"
output: html_document
---

## Preparation
```{r setup, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
out <- lapply(c("sf", "tsibble", 'lubridate', "viridis",
                'ggplot2', 'tidyr', 'grid', 'gridExtra', 
                'feasts', 'dplyr', 'gtable', 'fable',
                'mgcv'),
       library, character.only = TRUE)
out <- lapply(paste0("../functions/", list.files("../functions/")), source)
```

```{r preparedata}
#load data and convert to tsibbles
load("../private/data/remote_sensed/pg_daily.Rdata")
pg_daily$times <- as_date(pg_daily$times)
pg <- pg_daily %>%
  pivot_longer(-times, names_to = "site", values_to = "pg") %>%
  as_tsibble(key = site, index = times)
load("../private/data/remote_sensed/gpp_8d.Rdata")
gpp <- gpp_8d %>%
  pivot_longer(-times, names_to = "site", values_to = "gpp") %>%
  as_tsibble(key = site, index = times)
pggpp <- as_tsibble(dplyr::full_join(pg, gpp, by = c("times", "site")), key = site, index = times)

# add times breakdowns
pggpp <- pggpp %>%
  mutate(yday = yday(times),
         year = year(times))
  

#interpolate gpp
pggpp <- pggpp %>%
  group_by_key() %>% #key is site
  mutate(lininterp_gpp = zoo::na.approx(gpp, rule = 2, na.rm = FALSE)) %>% #rule 2 means edges are assigned last value
  ungroup()

#make sure sites are ordered alphabetically
pggpp <- pggpp %>%
  arrange(site) %>%
  mutate(site = factor(site, ordered = TRUE))

#separate alpha part of site code
pggpp <- pggpp %>%
  mutate(farm = factor(substr(site, 1, 4)),
         sitenum = factor(as.integer(substr(site, 5, 5))))


# Add cumulative rainfalls
pggpp <- pggpp %>% 
  group_by_key() %>%
  mutate(pg_cumsum = cumsum(pg)) %>%
  mutate(pg_1to7 = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 8), # 1 up to 8 days behind (excluding 8th day)
         pg_1to15 = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 16), # 1 to 16 days behind
         pg_1to1m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 31),
         pg_1to2m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 2*31),
         pg_1to3m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 3*31),
         pg_1to4m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 4*31),
         pg_1to5m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 5*31),
         pg_1to6m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 6*31),
         pg_1to7m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 7*31),
         pg_1to8m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 8*31),
         pg_1to10m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 10*31),
         pg_1to12m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 12*31),
         pg_1to14m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 14*31),
         ) %>%
  mutate(pg_8d = pg_cumsum - lag(pg_cumsum, n = 8),
         #0 to day 7 (8 days) cumulative rainfall to correspond with gaps in GPP
         pg_24d = pg_cumsum - lag(pg_cumsum, n = 3*8)) %>% 
         # every 24 days (3*8) of GPP should be less correlated (given average GPP), this pg_24d corresponds to the rain through that period
  ungroup()
```

```{r seasonalreferences}
# simple median of values
ydaymedian <- pggpp %>%
  filter(yday %in% seq(1, 366, by = 8)) %>%
  group_by(site) %>%
  index_by(yday) %>%
  summarise(gpp.ydaymed = median(gpp),
            pg_8d.ydaymed = median(pg_8d),
            pg_24d.ydaymed = median(pg_24d),
            pg_1to5m.ydaymed = median(pg_1to5m, na.rm = TRUE))
pggpp <- left_join(pggpp, ydaymedian, by = c("site", "yday"))
```

```{r preparetraintest}
train <- pggpp %>%
  filter(yday %in% seq(1, 366, by = 8)) %>%
  filter(sitenum == 1) %>% #so not doubling up at farms
  filter_index(. ~ "2016-12-31") %>%
  select(-pg_cumsum, -lininterp_gpp) %>%
  mutate(gpp = if_else(gpp < 0.1, as.double(NA), gpp)) #remove outlying GPP values that are super low

test <- pggpp %>%
  filter_index("2017-01-01" ~ .) %>%
  filter(sitenum == 1) %>% #so not doubling up at farms
  filter(yday %in% seq(1, 366, by = 8)) %>%
  select(-pg_cumsum)
```


In the above very small GPP values have been removed. There was `r sum(is.na(train$gpp))` of them, which corresponds to `r sum(is.na(train$gpp)) / length(train$gpp)` of the data.

## Generalised Linear Model of GPP
### Single order with interaction
```{r m1}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}

m1 <- lm(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              pg_1to5m * I(1 /  pg_1to5m.ydaymed) * pg_24d,
              data = train %>% filtertrain() )

plot(m1)
summary(m1)

pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(as_tibble(x = data.frame(predict(m1, type = "response", se.fit = TRUE)[1:2]), rownames = "rowname"),
            by = "rowname") %>% 
  mutate(pred_m1 = inv_box_cox(fit, lambda = 0.2626) * gpp.ydaymed) %>%
  mutate(pred_m1_upper = inv_box_cox(fit + 2 * se.fit, lambda = 0.2626) * gpp.ydaymed) %>%
  mutate(pred_m1_lower = inv_box_cox(fit - 2 * se.fit, lambda = 0.2626) * gpp.ydaymed) 
pred %>%
  filter(farm == "WILS") %>%
  ggplot() +
  geom_ribbon(aes(x = times, ymin = pred_m1_lower, ymax = pred_m1_upper)) +
  geom_line(aes(x = times, y = pred_m1)) +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "grey", linetype = "dashed", size = 0.5) +
  geom_line(aes(x = times, y = gpp), col = "blue") +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m1")
```

Minus a few outlying residuals, the distribution looks roughly constant in variance! The residuals are a long way off Gaussian at the larger end.
The adjusted R2 value of 0.417 is better than that of m11 in 1_5...Rmd.

But it lacks some physical sense: large pg_1to5m will have a negative (cancelling) effect.

I'm surprised that a linear model works so well. The stats are similar to the gams!

The confidence intervals are waaay too small. Suggesting a lot more correlation in the data than the computer knows about.

#### Investigation of residuals
```{r m1_residuals}
meanresid <- pred %>%
  mutate(resid = pred_m1 - gpp) %>%
  as_tibble() %>%
  group_by(site) %>%
  summarise(avresid = mean(resid, na.rm = TRUE))
pred %>%
  mutate(resid = pred_m1 - gpp) %>% 
  inner_join(meanresid, by = "site") %>%
  ggplot() +
  facet_wrap(~farm) +
  geom_line(aes(x = times, y = resid, col = avresid)) +
  scale_color_viridis_c() +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m1 residuals") +
  scale_y_continuous(name = "predicted gpp - observed gpp")
```

##### Spatial Distribution of Average of Site Residuals
```{r m1_spatialdistribution_avresiduals}
library(ggrepel)
sws_sites <- sws_sites_2_sf(readRDS("./private/data/clean/sws_sites.rds")) %>%
  mutate(latitude =  sf::st_coordinates(geometry)[, "Y"],
         longitude = sf::st_coordinates(geometry)[, "X"]) 

meanresid %>%
  left_join(sws_sites, by = c(site = "SiteCode")) %>%
  ggplot() +
  geom_point(aes(x = longitude, y = latitude, col = avresid, size = avresid)) +
  scale_color_viridis_c() +
  geom_text_repel(aes(x = longitude, y = latitude, label = site)) +
  guides(
    fill = guide_legend("Average\nResidual"),
    size = guide_legend("Average\nResidual")
  ) +
  coord_fixed() +
  ggtitle("Average Residual of m1 for each site")
```

### Full 2nd Order Polynomial Model
```{r m2}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}

m2 <- lm(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              polym(pg_1to5m, I(1/pg_1to5m.ydaymed), pg_24d, degree = 2),
              data = train %>% filtertrain() )

plot(m2)
summary(m2)

pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(tibble::enframe(predict(m2, type = "response"), name = "rowname", value = "linpred_m2"),
            by = "rowname") %>% 
  mutate(pred_m2 = inv_box_cox(linpred_m2, lambda = 0.2626) * gpp.ydaymed) 
pred %>%
  filter(farm == "WILS") %>%
  pivot_longer(c(pred_m2, gpp)) %>%
  ggplot() +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "black", size = 0.5) +
  geom_line(aes(x = times, y = value, col = name, lty = name)) +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m2")
```

This model with higher orders has very similar R-squared value to m1, residuals etc, and all standard diagnostic plots look very similar.

### Full 5th Order Polynomial
```{r m3}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}

m3 <- lm(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              polym(pg_1to5m, I(1/pg_1to5m.ydaymed), pg_24d, degree = 5),
              data = train %>% filtertrain() )

plot(m3)
summary(m3)

pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(tibble::enframe(predict(m3, type = "response"), name = "rowname", value = "linpred_m3"),
            by = "rowname") %>% 
  mutate(pred_m3 = inv_box_cox(linpred_m3, lambda = 0.2626) * gpp.ydaymed) 
pred %>%
  filter(farm == "WILS") %>%
  pivot_longer(c(pred_m3, gpp)) %>%
  ggplot() +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "black", size = 0.5) +
  geom_line(aes(x = times, y = value, col = name, lty = name)) +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m3")
```



### Single-order polynomial with interaction and site-specific effects
```{r m4}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}

m4 <- lm(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              pg_1to5m * I(1 /  pg_1to5m.ydaymed) * pg_24d * farm,
              data = train %>% filtertrain() )

plot(m4)
summary(m4)

pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(tibble::enframe(predict(m4, type = "response"), name = "rowname", value = "linpred_m4"),
            by = "rowname") %>% 
  mutate(pred_m4 = inv_box_cox(linpred_m4, lambda = 0.2626) * gpp.ydaymed) 
pred %>%
  filter(farm == "WILS") %>%
  pivot_longer(c(pred_m4, gpp)) %>%
  ggplot() +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "black", size = 0.5) +
  geom_line(aes(x = times, y = value, col = name, lty = name)) +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m4")
```


Interesting that this model appears to do as well as the single order with interactions and no site effects model (model m1). 
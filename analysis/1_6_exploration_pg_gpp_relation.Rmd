---
title: "Very Simple Models for GPP"
author: "Kassel Hingee"
date: "24/01/2020"
output: html_document
---

## Preparation
```{r setup, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
out <- lapply(c("sf", "tsibble", 'lubridate', "viridis",
                'ggplot2', 'tidyr', 'grid', 'gridExtra', 
                'feasts', 'dplyr', 'gtable', 'fable',
                'mgcv'),
       library, character.only = TRUE)
out <- lapply(paste0("../functions/", list.files("../functions/")), source)
```

```{r preparedata}
#load data and convert to tsibbles
load("../private/data/remote_sensed/pg_daily.Rdata")
pg_daily$times <- as_date(pg_daily$times)
pg <- pg_daily %>%
  pivot_longer(-times, names_to = "site", values_to = "pg") %>%
  as_tsibble(key = site, index = times)
load("../private/data/remote_sensed/gpp_8d.Rdata")
gpp <- gpp_8d %>%
  pivot_longer(-times, names_to = "site", values_to = "gpp") %>%
  as_tsibble(key = site, index = times)
pggpp <- as_tsibble(dplyr::full_join(pg, gpp, by = c("times", "site")), key = site, index = times)

# add times breakdowns
pggpp <- pggpp %>%
  mutate(yday = yday(times),
         year = year(times))
  

#interpolate gpp
pggpp <- pggpp %>%
  group_by_key() %>% #key is site
  mutate(lininterp_gpp = zoo::na.approx(gpp, rule = 2, na.rm = FALSE)) %>% #rule 2 means edges are assigned last value
  ungroup()

#make sure sites are ordered alphabetically
pggpp <- pggpp %>%
  arrange(site) %>%
  mutate(site = factor(site, ordered = TRUE))

#separate alpha part of site code
pggpp <- pggpp %>%
  mutate(farm = factor(substr(site, 1, 4)),
         sitenum = factor(as.integer(substr(site, 5, 5))))


# Add cumulative rainfalls
pggpp <- pggpp %>% 
  group_by_key() %>%
  mutate(pg_cumsum = cumsum(pg)) %>%
  mutate(pg_1to7 = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 8), # 1 up to 8 days behind (excluding 8th day)
         pg_1to15 = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 16), # 1 to 16 days behind
         pg_1to1m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 31),
         pg_1to2m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 2*31),
         pg_1to3m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 3*31),
         pg_1to4m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 4*31),
         pg_1to5m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 5*31),
         pg_1to6m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 6*31),
         pg_1to7m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 7*31),
         pg_1to8m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 8*31),
         pg_1to10m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 10*31),
         pg_1to12m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 12*31),
         pg_1to14m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 14*31),
         ) %>%
  mutate(pg_8d = pg_cumsum - lag(pg_cumsum, n = 8),
         #0 to day 7 (8 days) cumulative rainfall to correspond with gaps in GPP
         pg_24d = pg_cumsum - lag(pg_cumsum, n = 3*8)) %>% 
         # every 24 days (3*8) of GPP should be less correlated (given average GPP), this pg_24d corresponds to the rain through that period
  ungroup()
```

```{r seasonalreferences}
# simple median of values
ydaymedian <- pggpp %>%
  filter(yday %in% seq(1, 366, by = 8)) %>%
  group_by(site) %>%
  index_by(yday) %>%
  summarise(gpp.ydaymed = median(gpp),
            pg_8d.ydaymed = median(pg_8d),
            pg_24d.ydaymed = median(pg_24d),
            pg_1to5m.ydaymed = median(pg_1to5m, na.rm = TRUE))
pggpp <- left_join(pggpp, ydaymedian, by = c("site", "yday"))
```

```{r preparetraintest}
train <- pggpp %>%
  filter(yday %in% seq(1, 366, by = 8)) %>%
  filter(sitenum == 1) %>% #so not doubling up at farms
  filter_index(. ~ "2016-12-31") %>%
  select(-pg_cumsum, -lininterp_gpp) %>%
  mutate(gpp = if_else(gpp < 0.1, as.double(NA), gpp)) #remove outlying GPP values that are super low

test <- pggpp %>%
  filter_index("2017-01-01" ~ .) %>%
  filter(sitenum == 1) %>% #so not doubling up at farms
  filter(yday %in% seq(1, 366, by = 8)) %>%
  select(-pg_cumsum)
```


In the above very small GPP values have been removed. There was `r sum(is.na(train$gpp))` of them, which corresponds to `r sum(is.na(train$gpp)) / length(train$gpp)` of the data.

## Linear Model of GPP
### Single order with interaction
Recipricoal of pg_1to5m.ydaymed included.
```{r m1}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp)) # %>%
  #   mutate(recippg_1to5m.ydaymed = 1/pg_1to5m.ydaymed)
  # x$recippg_1to5m.ydaymed <- scale(x$recippg_1to5m.ydaymed)
  return(x)
}

m1 <- lm(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              pg_1to5m * I(1 / pg_1to5m.ydaymed) * pg_24d,
              data = train %>% filtertrain() )

plot(m1)
summary(m1)

pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(as_tibble(x = data.frame(predict(m1, type = "response", se.fit = TRUE)[1:2]), rownames = "rowname"),
            by = "rowname") %>% 
  mutate(pred_m1 = inv_box_cox(fit, lambda = 0.2626) * gpp.ydaymed) %>%
  mutate(pred_m1_upper = inv_box_cox(fit + 2 * se.fit, lambda = 0.2626) * gpp.ydaymed) %>%
  mutate(pred_m1_lower = inv_box_cox(fit - 2 * se.fit, lambda = 0.2626) * gpp.ydaymed) 
pred %>%
  filter(farm %in% c("WILS", "GEDD", "MATH", "SMAR")) %>%
  ggplot() +
  facet_wrap(~farm) +
  geom_ribbon(aes(x = times, ymin = pred_m1_lower, ymax = pred_m1_upper)) +
  geom_line(aes(x = times, y = pred_m1)) +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "grey", linetype = "dashed", size = 0.5) +
  geom_line(aes(x = times, y = gpp), col = "blue") +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m1")
```

Minus a few outlying residuals, the distribution looks roughly constant in variance! The residuals are a long way off Gaussian at the larger end.
The adjusted R2 value of 0.417 is better than that of m11 in 1_5...Rmd.

But it lacks some physical sense: large pg_1to5m will have a negative (cancelling) effect.

I'm surprised that a linear model works so well. The stats are similar to the gams!

The confidence intervals are waaay too small. Suggesting a lot more correlation in the data than the computer knows about.

#### Investigation of residuals
```{r m1_residuals}
meanresid <- pred %>%
  mutate(resid = pred_m1 - gpp) %>%
  as_tibble() %>%
  group_by(site) %>%
  summarise(avresid = mean(resid, na.rm = TRUE))
pred %>%
  mutate(resid = pred_m1 - gpp) %>% 
  inner_join(meanresid, by = "site") %>%
  ggplot() +
  facet_wrap(~farm) +
  geom_line(aes(x = times, y = resid, col = avresid)) +
  scale_color_viridis_c() +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m1 residuals") +
  scale_y_continuous(name = "predicted gpp - observed gpp")
```

In the above, positive values mean the gpp prediction was higher than the observed gpp.
That GEDD has a high, positive, average residual means that on average observed GPP was lower than what was predicted. *Even though GEDD usually has a high GPP, the prediction of GEDD's GPP is even higher!*

##### Spatial Distribution of Average of Site Residuals
```{r m1_spatialdistribution_avresiduals}
library(ggrepel)
sws_sites <- sws_sites_2_sf(readRDS("../private/data/clean/sws_sites.rds")) %>%
  mutate(latitude =  sf::st_coordinates(geometry)[, "Y"],
         longitude = sf::st_coordinates(geometry)[, "X"]) 

meanresid %>%
  left_join(sws_sites, by = c(site = "SiteCode")) %>%
  ggplot() +
  geom_point(aes(x = longitude, y = latitude, col = avresid, size = avresid)) +
  scale_color_viridis_c() +
  geom_text_repel(aes(x = longitude, y = latitude, label = site)) +
  guides(
    color = guide_colourbar("Average\nResidual Color"),
    size = guide_legend("Average\nResidual Size")
  ) +
  coord_fixed() +
  ggtitle("Average Residual of m1 for each site")
```

#### Does the inclusion of the reciprical median rainfal improve the model?
If the distributional assumptions could be trusted then the $p$ values from an anova test could be used to decide this. Looking at relative size of the $p$ values it seems the reciprical by itself is not very useful, but interacting with pg_1to5m is quite useful. Testing with a scaled centred reciprical gave the same results.

In liu of the mathematically sound method, lets try investigating a model without the reciprical.
```{r m1_b}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}

m1_b <- lm(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              pg_1to5m * pg_24d,
              data = train %>% filtertrain() )

plot(m1_b)
summary(m1_b)

pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(as_tibble(x = data.frame(predict(m1_b, type = "response", se.fit = TRUE)[1:2]), rownames = "rowname"),
            by = "rowname") %>% 
  mutate(pred_m1_b = inv_box_cox(fit, lambda = 0.2626) * gpp.ydaymed) %>%
  mutate(pred_m1_b_upper = inv_box_cox(fit + 2 * se.fit, lambda = 0.2626) * gpp.ydaymed) %>%
  mutate(pred_m1_b_lower = inv_box_cox(fit - 2 * se.fit, lambda = 0.2626) * gpp.ydaymed) 
pred %>%
  filter(farm %in% c("WILS", "GEDD", "MATH", "SMAR")) %>%
  ggplot() +
  facet_wrap(~farm) +
  geom_ribbon(aes(x = times, ymin = pred_m1_b_lower, ymax = pred_m1_b_upper)) +
  geom_line(aes(x = times, y = pred_m1_b)) +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "grey", linetype = "dashed", size = 0.5) +
  geom_line(aes(x = times, y = gpp), col = "blue") +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m1 without recipricol of median precipitation")
```

The R2 value of this model is nearly identical to that of m1.
The predictions themselves also look ver similar.

### Full 2nd Order Polynomial Model
```{r m2}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp)) 
  return(x)
}

m2 <- lm(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              polym(pg_1to5m, I(1/pg_1to5m.ydaymed), pg_24d, degree = 2),
              data = train %>% filtertrain() )

plot(m2)
summary(m2)

pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(tibble::enframe(predict(m2, type = "response"), name = "rowname", value = "linpred_m2"),
            by = "rowname") %>% 
  mutate(pred_m2 = inv_box_cox(linpred_m2, lambda = 0.2626) * gpp.ydaymed) 
pred %>%
  filter(farm == "WILS") %>%
  pivot_longer(c(pred_m2, gpp)) %>%
  ggplot() +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "black", size = 0.5) +
  geom_line(aes(x = times, y = value, col = name, lty = name)) +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m2")
```

This model with higher orders has very similar R-squared value to m1, residuals etc, and all standard diagnostic plots look very similar.

### Full 5th Order Polynomial
```{r m3}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}

m3 <- lm(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              polym(pg_1to5m, I(1/pg_1to5m.ydaymed), pg_24d, degree = 5),
              data = train %>% filtertrain() )

plot(m3)
summary(m3)

pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(tibble::enframe(predict(m3, type = "response"), name = "rowname", value = "linpred_m3"),
            by = "rowname") %>% 
  mutate(pred_m3 = inv_box_cox(linpred_m3, lambda = 0.2626) * gpp.ydaymed) 
pred %>%
  filter(farm == "WILS") %>%
  pivot_longer(c(pred_m3, gpp)) %>%
  ggplot() +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "black", size = 0.5) +
  geom_line(aes(x = times, y = value, col = name, lty = name)) +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m3")
```



### Single-order polynomial with interaction and site-specific effects
```{r m4}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}

m4 <- lm(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              pg_1to5m * I(1 /  pg_1to5m.ydaymed) * pg_24d * farm,
              data = train %>% filtertrain() )

plot(m4)
summary(m4)

pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(tibble::enframe(predict(m4, type = "response"), name = "rowname", value = "linpred_m4"),
            by = "rowname") %>% 
  mutate(pred_m4 = inv_box_cox(linpred_m4, lambda = 0.2626) * gpp.ydaymed) 
pred %>%
  filter(farm == "WILS") %>%
  pivot_longer(c(pred_m4, gpp)) %>%
  ggplot() +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "black", size = 0.5) +
  geom_line(aes(x = times, y = value, col = name, lty = name)) +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m4")
```


Interesting that this model appears to do as well as the single order with interactions and no site effects model (model m1). 

## GAM of Cumulative precipitations (to double check) with identity link
In other documents I've nearly always fitted gams using log link. Given that transformation isn't required for the above models to perform well, I'm going to try it here without the log link.

```{r m5_gam}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}
  
m5 <- bam(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
            s(pg_24d) +
            s(pg_1to5m) +
            s(pg_1to5m.ydaymed) +
             ti(pg_24d, pg_1to5m) +
             ti(pg_1to5m, pg_1to5m.ydaymed) +
             ti(pg_24d, pg_1to5m.ydaymed) +
             ti(pg_24d, pg_1to5m,  pg_1to5m.ydaymed),
             data = train %>% filtertrain() )

gam.check(m5)
plot(m5)
summary(m5)

pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(as_tibble(x = data.frame(predict(m5, type = "response", se.fit = TRUE)[1:2]), rownames = "rowname"),
            by = "rowname") %>% 
  mutate(pred = inv_box_cox(fit, lambda = 0.2626) * gpp.ydaymed) %>%
  mutate(pred_upper = inv_box_cox(fit + 2 * se.fit, lambda = 0.2626) * gpp.ydaymed) %>%
  mutate(pred_lower = inv_box_cox(fit - 2 * se.fit, lambda = 0.2626) * gpp.ydaymed) 
pred %>%
  filter(farm %in% c("WILS", "GEDD", "MATH", "SMAR")) %>%
  ggplot() +
  facet_wrap(~farm) +
  geom_ribbon(aes(x = times, ymin = pred_lower, ymax = pred_upper)) +
  geom_line(aes(x = times, y = pred)) +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "grey", linetype = "dashed", size = 0.5) +
  geom_line(aes(x = times, y = gpp), col = "blue") +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m5")
```

The map of response and fitted values is much poorer than the linear models: a trend in the fitted values is clear, it is very strange that such a trend is present as it looks like a spline would easily remove such issues.

The predictions from m5 appear so similar to the prediction from m1, but there are small differences. GEDD predictions are substantially higher (perhaps because GEDD is an outlier).
The R2 value of m5 is slightly higher than the R2 value of m1.


## How/why are the prediction intervals so small? ARIMA models?
Let try with an ARIMA model, again!
```{r arimaforerror_explore}
pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(as_tibble(x = data.frame(predict(m1, type = "response", se.fit = TRUE)[1:2]), rownames = "rowname"),
            by = "rowname") %>% 
  left_join(as_tibble(x = data.frame(linresid = residuals(m1, type = "response")), rownames = "rowname"),
            by = "rowname") %>% 
  mutate(pred_m1 = inv_box_cox(fit, lambda = 0.2626) * gpp.ydaymed) 

per <- length(seq(1, 366, by = 3 * 8))

pred %>%
  group_by_key() %>%
  select(linresid) %>%
  filter(site %in% c("BELL1", "WILS1")) %>%
  mutate(sd1 = difference(linresid, lag = 16)) %>%
  mutate(sd2 = difference(linresid, lag = 2 * 16)) %>%
  mutate(sd3 = difference(linresid, lag = 3 * 16)) %>%
  mutate(sd1_2 = difference(linresid, lag = 1 * 16, differences = 2)) %>%
  mutate(sd1_3 = difference(linresid, lag = 1 * 16, differences = 3)) %>%
  mutate(sd1_4 = difference(linresid, lag = 1 * 16, differences = 4)) %>%
  mutate(sd2_3 = difference(linresid, lag = 2 * 16, differences = 3)) %>%
  mutate(sd3_2 = difference(linresid, lag = 3 * 16, differences = 2)) %>%
  mutate(sd3_3 = difference(linresid, lag = 3 * 16, differences = 3)) %>%
  mutate(od1_sd1 = difference(sd1, lag = 1)) %>%
  mutate(od1_sd3 = difference(sd1, lag = 3)) %>%
  mutate(od2_sd1 = difference(sd1, lag = 2)) %>%
  mutate(od1_2_sd1 = difference(sd1, lag = 1, differences = 2)) %>%
  mutate(od1_sd3 = difference(sd3, lag = 1, differences = 1)) %>%
  mutate(od1_sd3_2 = difference(sd3_2, lag = 1, differences = 1)) %>%
  mutate(od1_sd3_3 = difference(sd3_2, lag = 1, differences = 3)) %>%
  mutate(od2_sd3 = difference(sd3, lag = 2, differences = 1)) %>%
  mutate(od1_2_sd3 = difference(sd3, lag = 1, differences = 2)) %>%
  pivot_longer(c(-times, -site)) %>%
  ggplot() +
  facet_grid(cols = vars(site), rows = vars(name), scales = "free_y") +
  geom_hline(yintercept = 0, col = "grey", lty = "dashed") +
  geom_line(aes(x = times, y = value)) +
  scale_y_continuous(name = "log(gpp + 1)") +
  ggtitle("Linear Residual: Seasonal Differences (sd) First")

```

Looks like the stationarity of the linear residuals isn't too bad. But differencing may help regardless.

Lets just try fitting something, maybe it will work this time!?
```{r m6_fitarima}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}
m6_sp <- ARIMA(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              pg_1to5m * I(1 / pg_1to5m.ydaymed) * pg_24d +
              pdq())


m6 <- train %>% filtertrain() %>%
  tibble::rowid_to_column() %>% #reindex by approximate 8 day intervals (discrepancies at the end of every year)
  as_tsibble(key = NULL, index = "rowid") %>%
  ungroup() %>%
  model(m6_sp)

print(m6[[1, 1]])
tidy(m6[[1, 1]])

train %>% filtertrain() %>%
  tibble::rowid_to_column() %>%
  left_join(fitted(m6), by = "rowid") %>%
  filter(farm %in% c("WILS", "GEDD", "MATH", "SMAR")) %>%
  mutate(pred = .fitted * gpp.ydaymed) %>%
  ggplot() +
  facet_wrap(~farm) +
  geom_line(aes(x = times, y = pred)) +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "grey", linetype = "dashed", size = 0.5) +
  geom_line(aes(x = times, y = gpp), col = "blue") +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m6")
```


```{r forecastingwithout_pastgpp}
m6 %>%
  forecast(new_data = train %>% filtertrain() %>%
             #select(-gpp) %>% # I've checked that it doesn't use gpp
             tibble::rowid_to_column() %>%
             #filter(farm %in% c("GEDD")) %>% 
             update_tsibble(key = NULL, index = "rowid") %>%
             fill_gaps()
           ) %>%
  filter(!is.na(times)) %>%
  update_tsibble(key = "site", index = "times") %>%
  filter(farm %in% c("WILS", "GEDD", "MATH", "SMAR")) %>% 
  mutate(interval = hilo(.distribution, 95)) %>%
  ggplot() +
  facet_wrap(~farm) +
  geom_ribbon(aes(x = times, ymin = interval$.lower * gpp.ydaymed, ymax = interval$.upper * gpp.ydaymed), fill = "lightgrey") +
  geom_line(aes(x = times, y = `gpp/gpp.ydaymed` * gpp.ydaymed), col = "black") + 
  geom_line(aes(x = times, y = gpp), col = "blue")
```

Finally fitted a model where the error bars look believable! :). Probably worth checking autocorrelations of residuals though!

Prediction of mean is very close to what m1 was, which makes sense if one assumes there is enough mixing in the time series.

Residuals are still not Gaussian though! See below

```{r m6_resid}
residuals(m6) %>%
  ggplot() +
  geom_point(aes(x = rowid, y = .resid))

residuals(m6) %>%
  ggplot() +
  geom_qq(aes(sample = .resid)) +
  stat_qq_line(aes(sample = .resid))
```
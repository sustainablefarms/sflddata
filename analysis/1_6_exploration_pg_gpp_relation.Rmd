---
title: "Very Simple Models for GPP"
author: "Kassel Hingee"
date: "24/01/2020"
output: 
  html_document: 
    keep_md: yes
    toc: yes
---

## Preparation
```{r setup, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
out <- lapply(c("sf", "tsibble", 'lubridate', "viridis",
                'ggplot2', 'tidyr', 'grid', 'gridExtra', 
                'feasts', 'dplyr', 'gtable', 'fable',
                'mgcv'),
       library, character.only = TRUE)
out <- lapply(paste0("../functions/", list.files("../functions/")), source)
```

```{r preparedata}
#load data and convert to tsibbles
load("../private/data/remote_sensed/pg_daily.Rdata")
pg_daily$times <- as_date(pg_daily$times)
pg <- pg_daily %>%
  pivot_longer(-times, names_to = "site", values_to = "pg") %>%
  as_tsibble(key = site, index = times)
load("../private/data/remote_sensed/gpp_8d.Rdata")
gpp <- gpp_8d %>%
  pivot_longer(-times, names_to = "site", values_to = "gpp") %>%
  as_tsibble(key = site, index = times)
pggpp <- as_tsibble(dplyr::full_join(pg, gpp, by = c("times", "site")), key = site, index = times)

# add times breakdowns
pggpp <- pggpp %>%
  mutate(yday = yday(times),
         year = year(times))
  

#interpolate gpp
pggpp <- pggpp %>%
  group_by_key() %>% #key is site
  mutate(lininterp_gpp = zoo::na.approx(gpp, rule = 2, na.rm = FALSE)) %>% #rule 2 means edges are assigned last value
  ungroup()

#make sure sites are ordered alphabetically
pggpp <- pggpp %>%
  arrange(site) %>%
  mutate(site = factor(site, ordered = TRUE))

#separate alpha part of site code
pggpp <- pggpp %>%
  mutate(farm = factor(substr(site, 1, 4)),
         sitenum = factor(as.integer(substr(site, 5, 5))))


# Add cumulative rainfalls
pggpp <- pggpp %>% 
  group_by_key() %>%
  mutate(pg_cumsum = cumsum(pg)) %>%
  mutate(pg_1to7 = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 8), # 1 up to 8 days behind (excluding 8th day)
         pg_1to15 = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 16), # 1 to 16 days behind
         pg_1to1m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 31),
         pg_1to2m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 2*31),
         pg_1to3m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 3*31),
         pg_1to4m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 4*31),
         pg_1to5m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 5*31),
         pg_1to6m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 6*31),
         pg_1to7m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 7*31),
         pg_1to8m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 8*31),
         pg_1to10m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 10*31),
         pg_1to12m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 12*31),
         pg_1to14m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 14*31),
         ) %>%
  mutate(pg_8d = pg_cumsum - lag(pg_cumsum, n = 8),
         #0 to day 7 (8 days) cumulative rainfall to correspond with gaps in GPP
         pg_24d = pg_cumsum - lag(pg_cumsum, n = 3*8)) %>% 
         # every 24 days (3*8) of GPP should be less correlated (given average GPP), this pg_24d corresponds to the rain through that period
  ungroup()
```

```{r seasonalreferences}
# simple median of values
ydaymedian <- pggpp %>%
  filter(yday %in% seq(1, 366, by = 8)) %>%
  group_by(site) %>%
  index_by(yday) %>%
  summarise(gpp.ydaymed = median(gpp),
            pg_8d.ydaymed = median(pg_8d),
            pg_24d.ydaymed = median(pg_24d),
            pg_1to5m.ydaymed = median(pg_1to5m, na.rm = TRUE))
pggpp <- left_join(pggpp, ydaymedian, by = c("site", "yday"))
```

```{r preparetraintest}
train <- pggpp %>%
  filter(yday %in% seq(1, 366, by = 8)) %>%
  filter(sitenum == 1) %>% #so not doubling up at farms
  filter_index(. ~ "2016-12-31") %>%
  dplyr::select(-pg_cumsum, -lininterp_gpp) %>%
  mutate(gpp = if_else(gpp < 0.1, as.double(NA), gpp)) #remove outlying GPP values that are super low

test <- pggpp %>%
  filter_index("2017-01-01" ~ .) %>%
  filter(sitenum == 1) %>% #so not doubling up at farms
  filter(yday %in% seq(1, 366, by = 8)) %>%
  dplyr::select(-pg_cumsum)
```


In the above very small GPP values have been removed. There was `r sum(is.na(train$gpp))` of them, which corresponds to `r sum(is.na(train$gpp)) / length(train$gpp)` of the data.

## Linear Model of GPP
### m1: Single order with interaction
Recipricoal of pg_1to5m.ydaymed included.
```{r m1}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp)) # %>%
  #   mutate(recippg_1to5m.ydaymed = 1/pg_1to5m.ydaymed)
  # x$recippg_1to5m.ydaymed <- scale(x$recippg_1to5m.ydaymed)
  return(x)
}

m1 <- lm(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              pg_1to5m * I(1 / pg_1to5m.ydaymed) * pg_24d,
              data = train %>% filtertrain() )

plot(m1)
summary(m1)

pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(as_tibble(x = data.frame(predict(m1, type = "response", se.fit = TRUE)[1:2]), rownames = "rowname"),
            by = "rowname") %>% 
  mutate(pred_m1 = inv_box_cox(fit, lambda = 0.2626) * gpp.ydaymed) %>%
  mutate(pred_m1_upper = inv_box_cox(fit + 2 * se.fit, lambda = 0.2626) * gpp.ydaymed) %>%
  mutate(pred_m1_lower = inv_box_cox(fit - 2 * se.fit, lambda = 0.2626) * gpp.ydaymed) 
pred %>%
  filter(farm %in% c("WILS", "GEDD", "MATH", "SMAR")) %>%
  ggplot() +
  facet_wrap(~farm) +
  geom_ribbon(aes(x = times, ymin = pred_m1_lower, ymax = pred_m1_upper)) +
  geom_line(aes(x = times, y = pred_m1)) +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "grey", linetype = "dashed", size = 0.5) +
  geom_line(aes(x = times, y = gpp), col = "blue") +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m1")
```

Minus a few outlying residuals, the distribution looks roughly constant in variance! The residuals are a long way off Gaussian at the larger end.
The adjusted R2 value of 0.417 is better than that of m11 in 1_5...Rmd.

But it lacks some physical sense: large pg_1to5m will have a negative (cancelling) effect.

I'm surprised that a linear model works so well. The stats are similar to the gams!

The confidence intervals are waaay too small. Suggesting a lot more correlation in the data than the computer knows about.

#### Investigation of residuals
```{r m1_residuals}
meanresid <- pred %>%
  mutate(resid = gpp - pred_m1) %>%
  as_tibble() %>%
  group_by(site) %>%
  summarise(avresid = mean(resid, na.rm = TRUE))
pred %>%
  mutate(resid = gpp - pred_m1) %>% 
  inner_join(meanresid, by = "site") %>%
  ggplot() +
  facet_wrap(~farm) +
  geom_line(aes(x = times, y = resid, col = avresid)) +
  scale_color_viridis_c() +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m1 residuals") +
  scale_y_continuous(name = "observed - predicted gpp")
```

In the above, negative values mean the gpp prediction was higher than the observed gpp.
That GEDD has a highly negative average residual means that on average observed GPP was lower than what was predicted. *Even though GEDD usually has a high GPP, the prediction of GEDD's GPP is even higher!*

##### Spatial Distribution of Average of Site Residuals
```{r m1_spatialdistribution_avresiduals}
library(ggrepel)
sws_sites <- sws_sites_2_sf(readRDS("../private/data/clean/sws_sites.rds")) %>%
  mutate(latitude =  sf::st_coordinates(geometry)[, "Y"],
         longitude = sf::st_coordinates(geometry)[, "X"]) 

meanresid %>%
  left_join(sws_sites, by = c(site = "SiteCode")) %>%
  ggplot() +
  geom_point(aes(x = longitude, y = latitude, col = avresid, size = avresid)) +
  scale_color_viridis_c() +
  geom_text_repel(aes(x = longitude, y = latitude, label = site)) +
  guides(
    color = guide_colourbar("Average\nResidual Color"),
    size = guide_legend("Average\nResidual Size")
  ) +
  coord_fixed() +
  ggtitle("Average Residual of m1 for each site")
```

#### Does the inclusion of the reciprical median rainfal improve the model?
If the distributional assumptions could be trusted then the $p$ values from an anova test could be used to decide this. Looking at relative size of the $p$ values it seems the reciprical by itself is not very useful, but interacting with pg_1to5m is quite useful. Testing with a scaled centred reciprical gave the same results.

In liu of the mathematically sound method, lets try investigating a model without the reciprical.
```{r m1_b}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}

m1_b <- lm(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              pg_1to5m * pg_24d,
              data = train %>% filtertrain() )

plot(m1_b)
summary(m1_b)

pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(as_tibble(x = data.frame(predict(m1_b, type = "response", se.fit = TRUE)[1:2]), rownames = "rowname"),
            by = "rowname") %>% 
  mutate(pred_m1_b = inv_box_cox(fit, lambda = 0.2626) * gpp.ydaymed) %>%
  mutate(pred_m1_b_upper = inv_box_cox(fit + 2 * se.fit, lambda = 0.2626) * gpp.ydaymed) %>%
  mutate(pred_m1_b_lower = inv_box_cox(fit - 2 * se.fit, lambda = 0.2626) * gpp.ydaymed) 
pred %>%
  filter(farm %in% c("WILS", "GEDD", "MATH", "SMAR")) %>%
  ggplot() +
  facet_wrap(~farm) +
  geom_ribbon(aes(x = times, ymin = pred_m1_b_lower, ymax = pred_m1_b_upper)) +
  geom_line(aes(x = times, y = pred_m1_b)) +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "grey", linetype = "dashed", size = 0.5) +
  geom_line(aes(x = times, y = gpp), col = "blue") +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m1 without recipricol of median precipitation")
```

The R2 value of this model is nearly identical to that of m1.
The predictions themselves also look ver similar.

### m2: Full 2nd Order Polynomial Model
```{r m2}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp)) 
  return(x)
}

m2 <- lm(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              polym(pg_1to5m, I(1/pg_1to5m.ydaymed), pg_24d, degree = 2),
              data = train %>% filtertrain() )

plot(m2)
summary(m2)

pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(tibble::enframe(predict(m2, type = "response"), name = "rowname", value = "linpred_m2"),
            by = "rowname") %>% 
  mutate(pred_m2 = inv_box_cox(linpred_m2, lambda = 0.2626) * gpp.ydaymed) 
pred %>%
  filter(farm == "WILS") %>%
  pivot_longer(c(pred_m2, gpp)) %>%
  ggplot() +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "black", size = 0.5) +
  geom_line(aes(x = times, y = value, col = name, lty = name)) +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m2")
```

This model with higher orders has very similar R-squared value to m1, residuals etc, and all standard diagnostic plots look very similar.

### m3: Full 5th Order Polynomial
```{r m3}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}

m3 <- lm(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              polym(pg_1to5m, I(1/pg_1to5m.ydaymed), pg_24d, degree = 5),
              data = train %>% filtertrain() )

plot(m3)
summary(m3)

pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(tibble::enframe(predict(m3, type = "response"), name = "rowname", value = "linpred_m3"),
            by = "rowname") %>% 
  mutate(pred_m3 = inv_box_cox(linpred_m3, lambda = 0.2626) * gpp.ydaymed) 
pred %>%
  filter(farm == "WILS") %>%
  pivot_longer(c(pred_m3, gpp)) %>%
  ggplot() +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "black", size = 0.5) +
  geom_line(aes(x = times, y = value, col = name, lty = name)) +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m3")
```



### m4: Single-order polynomial with interaction and site-specific effects
```{r m4}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}

m4 <- lm(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              pg_1to5m * I(1 /  pg_1to5m.ydaymed) * pg_24d * farm,
              data = train %>% filtertrain() )

plot(m4)
summary(m4)

pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(tibble::enframe(predict(m4, type = "response"), name = "rowname", value = "linpred_m4"),
            by = "rowname") %>% 
  mutate(pred_m4 = inv_box_cox(linpred_m4, lambda = 0.2626) * gpp.ydaymed) 
pred %>%
  filter(farm == "WILS") %>%
  pivot_longer(c(pred_m4, gpp)) %>%
  ggplot() +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "black", size = 0.5) +
  geom_line(aes(x = times, y = value, col = name, lty = name)) +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m4")
```


Interesting that this model appears to do as well as the single order with interactions and no site effects model (model m1). 

## m5: GAM of Cumulative precipitations (to double check) with identity link
In other documents I've nearly always fitted gams using log link. Given that transformation isn't required for the above models to perform well, I'm going to try it here without the log link.

```{r m5_gam}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}
  
m5 <- bam(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
            s(pg_24d) +
            s(pg_1to5m) +
            s(pg_1to5m.ydaymed) +
             ti(pg_24d, pg_1to5m) +
             ti(pg_1to5m, pg_1to5m.ydaymed) +
             ti(pg_24d, pg_1to5m.ydaymed) +
             ti(pg_24d, pg_1to5m,  pg_1to5m.ydaymed),
             data = train %>% filtertrain() )

gam.check(m5)
plot(m5)
summary(m5)

pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(as_tibble(x = data.frame(predict(m5, type = "response", se.fit = TRUE)[1:2]), rownames = "rowname"),
            by = "rowname") %>% 
  mutate(pred = inv_box_cox(fit, lambda = 0.2626) * gpp.ydaymed) %>%
  mutate(pred_upper = inv_box_cox(fit + 2 * se.fit, lambda = 0.2626) * gpp.ydaymed) %>%
  mutate(pred_lower = inv_box_cox(fit - 2 * se.fit, lambda = 0.2626) * gpp.ydaymed) 
pred %>%
  filter(farm %in% c("WILS", "GEDD", "MATH", "SMAR")) %>%
  ggplot() +
  facet_wrap(~farm) +
  geom_ribbon(aes(x = times, ymin = pred_lower, ymax = pred_upper)) +
  geom_line(aes(x = times, y = pred)) +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "grey", linetype = "dashed", size = 0.5) +
  geom_line(aes(x = times, y = gpp), col = "blue") +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m5")
```

The map of response and fitted values is much poorer than the linear models: a trend in the fitted values is clear, it is very strange that such a trend is present as it looks like a spline would easily remove such issues.

The predictions from m5 appear so similar to the prediction from m1, but there are small differences. GEDD predictions are substantially higher (perhaps because GEDD is an outlier).
The R2 value of m5 is slightly higher than the R2 value of m1.


## m6: A linear regression with ARIMA errors to get more realistic prediction intervals
```{r arimaforerror_explore}
pred <- train %>%
  filtertrain() %>%
  tibble::rownames_to_column(var = "rowname") %>%
  left_join(as_tibble(x = data.frame(predict(m1, type = "response", se.fit = TRUE)[1:2]), rownames = "rowname"),
            by = "rowname") %>% 
  left_join(as_tibble(x = data.frame(linresid = residuals(m1, type = "response")), rownames = "rowname"),
            by = "rowname") %>% 
  mutate(pred_m1 = inv_box_cox(fit, lambda = 0.2626) * gpp.ydaymed) 

per <- length(seq(1, 366, by = 3 * 8))

pred %>%
  group_by_key() %>%
  dplyr::select(linresid) %>%
  filter(site %in% c("BELL1", "WILS1")) %>%
  mutate(sd1 = difference(linresid, lag = 16)) %>%
  mutate(sd2 = difference(linresid, lag = 2 * 16)) %>%
  mutate(sd3 = difference(linresid, lag = 3 * 16)) %>%
  mutate(sd1_2 = difference(linresid, lag = 1 * 16, differences = 2)) %>%
  mutate(sd1_3 = difference(linresid, lag = 1 * 16, differences = 3)) %>%
  mutate(sd1_4 = difference(linresid, lag = 1 * 16, differences = 4)) %>%
  mutate(sd2_3 = difference(linresid, lag = 2 * 16, differences = 3)) %>%
  mutate(sd3_2 = difference(linresid, lag = 3 * 16, differences = 2)) %>%
  mutate(sd3_3 = difference(linresid, lag = 3 * 16, differences = 3)) %>%
  mutate(od1_sd1 = difference(sd1, lag = 1)) %>%
  mutate(od1_sd3 = difference(sd1, lag = 3)) %>%
  mutate(od2_sd1 = difference(sd1, lag = 2)) %>%
  mutate(od1_2_sd1 = difference(sd1, lag = 1, differences = 2)) %>%
  mutate(od1_sd3 = difference(sd3, lag = 1, differences = 1)) %>%
  mutate(od1_sd3_2 = difference(sd3_2, lag = 1, differences = 1)) %>%
  mutate(od1_sd3_3 = difference(sd3_2, lag = 1, differences = 3)) %>%
  mutate(od2_sd3 = difference(sd3, lag = 2, differences = 1)) %>%
  mutate(od1_2_sd3 = difference(sd3, lag = 1, differences = 2)) %>%
  pivot_longer(c(-times, -site)) %>%
  ggplot() +
  facet_grid(cols = vars(site), rows = vars(name), scales = "free_y") +
  geom_hline(yintercept = 0, col = "grey", lty = "dashed") +
  geom_line(aes(x = times, y = value)) +
  scale_y_continuous(name = "log(gpp + 1)") +
  ggtitle("Linear Residual: Seasonal Differences (sd) First")

```

Looks like the stationarity of the linear residuals isn't too bad. But differencing may help regardless.

Lets just try fitting something, maybe it will work this time!?
```{r m6_fitarima}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}
m6_sp <- ARIMA(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              pg_1to5m * I(1 / pg_1to5m.ydaymed) * pg_24d +
              pdq())


m6 <- train %>% filtertrain() %>%
  tibble::rowid_to_column() %>% #reindex by approximate 8 day intervals (discrepancies at the end of every year)
  as_tsibble(key = NULL, index = "rowid") %>%
  ungroup() %>%
  model(m6_sp)

print(m6[[1, 1]])
tidy(m6[[1, 1]])

train %>% filtertrain() %>%
  tibble::rowid_to_column() %>%
  left_join(fitted(m6), by = "rowid") %>%
  filter(farm %in% c("WILS", "GEDD", "MATH", "SMAR")) %>%
  mutate(pred = .fitted * gpp.ydaymed) %>%
  ggplot() +
  facet_wrap(~farm) +
  geom_line(aes(x = times, y = pred)) +
  geom_line(aes(x = times, y = gpp.ydaymed), col = "grey", linetype = "dashed", size = 0.5) +
  geom_line(aes(x = times, y = gpp), col = "blue") +
  #geom_point(aes(x = times, y = value, col = name, shape = name)) +
  ggtitle("m6")
```


```{r forecastingwithout_pastgpp}
m6 %>%
  forecast(new_data = train %>% filtertrain() %>%
             #select(-gpp) %>% # I've checked that it doesn't use gpp
             tibble::rowid_to_column() %>%
             #filter(farm %in% c("GEDD")) %>% 
             update_tsibble(key = NULL, index = "rowid") %>%
             fill_gaps()
           ) %>%
  filter(!is.na(times)) %>%
  update_tsibble(key = "site", index = "times") %>%
  filter(farm %in% c("WILS", "GEDD", "MATH", "SMAR")) %>% 
  mutate(interval = hilo(.distribution, 95)) %>%
  ggplot() +
  facet_wrap(~farm, scales = "free_y") +
  geom_ribbon(aes(x = times, ymin = interval$.lower * gpp.ydaymed, ymax = interval$.upper * gpp.ydaymed), fill = "lightgrey") +
  geom_line(aes(x = times, y = `gpp/gpp.ydaymed` * gpp.ydaymed), col = "black") + 
  geom_line(aes(x = times, y = gpp), col = "blue") +
  scale_y_continuous(name = "GPP") +
  ggtitle("m6", subtitle = "blue = observed; black = fitted")
```

Finally fitted a model where the error bars look believable! :). Probably worth checking autocorrelations of residuals though!

Prediction of mean is very close to what m1 was, which makes sense if one assumes there is enough mixing in the time series.

### Model Checking (preliminary)

#### Plotting Residuals
```{r m6_res_view}
preds <- m6[[1, 1]] %>%
  forecast(new_data = train %>% filtertrain() %>%
             #select(-gpp) %>% # I've checked that it doesn't use gpp
             tibble::rowid_to_column() %>%
             #filter(farm %in% c("GEDD")) %>% 
             update_tsibble(key = NULL, index = "rowid") %>%
             fill_gaps()
           ) %>%
  as_tsibble() %>% # the result of forecast is a special class called fable (fbl_ts) which requires response and distribution column to be baked in with unchanged names, so removing that extra structure
  rename(
    "gpp/gpp.ydaymed.pred" = `gpp/gpp.ydaymed`,
    "gpp/gpp.ydaymed.pred.dist" = `.distribution`  #The help for forecast in fabletools make it sound like this distribution is related to the backtransformed variable, which I think is impressive!
  ) %>%
  filter(!is.na(times)) %>%
  update_tsibble(key = "site", index = "times") %>%
  mutate(gpp.pred = `gpp/gpp.ydaymed.pred` * gpp.ydaymed) %>%
  mutate(lin.pred = box_cox(`gpp/gpp.ydaymed.pred`, lambda = 0.2626)) %>%
  mutate(lin.resid =  box_cox(gpp / gpp.ydaymed, lambda = 0.2626) - box_cox(`gpp/gpp.ydaymed.pred`, lambda = 0.2626)) %>%
  mutate(`gpp/gpp.ydaymed` =  gpp  / gpp.ydaymed) %>%
  mutate(lin.obs = box_cox( gpp / gpp.ydaymed, lambda = 0.2626))

preds %>%
  #filter(farm == "CAIN") %>%
  ggplot() +
  facet_wrap(~year) +
  geom_line(aes(x = yday, y = lin.resid, col = farm, group = farm)) +
  scale_color_viridis_d()
```



```{r resid_types}
residuals(m6[[1, 1]], type = "regression") %>%
  left_join(residuals(m6[[1, 1]], type = "innovation"), by = "rowid", suffix = c(".regression", ".innovation")) %>%
  left_join(preds, by = "rowid") %>%
  update_tsibble(key = "site", index = "times") %>%
  as_tibble() %>%
  dplyr::select(lin.obs, .resid.regression)

# check what residuals.ARIMA() returns for type = "regression" or "innovation"
residuals(m6[[1, 1]], type = "regression") %>%
  left_join(residuals(m6[[1, 1]], type = "innovation"), by = "rowid", suffix = c(".regression", ".innovation")) %>%
  left_join(preds, by = "rowid") %>%
  update_tsibble(key = "site", index = "times") %>%
  as_tibble() %>%
  dplyr::select(rowid, times, farm, 
         lin.pred,
         lin.obs,
         lin.resid,
         .resid.regression,
         .resid.innovation
         ) %>%
  #mutate(innov.p.linpred = lin.pred + cumsum(.resid.innovation))
  filter(farm %in% c("CAIN")) %>% 
  mutate(lin.pred.innov = lin.pred - lag(lin.pred, 1)) %>%
  mutate(lin.obs.innov = lin.obs - lag(lin.obs, 1)) %>%
  mutate(man.resid.innov = lin.obs.innov - lin.pred.innov) %>%
  pivot_longer(c(
    lin.pred.innov,
    lin.obs.innov,
    man.resid.innov
    )) %>%
  ggplot() +
  #facet_wrap(~farm, scales = "free_y") +
  facet_grid(rows = vars(name)) +
  geom_line(aes(x = times, y = .resid.innovation), col = "black", lty = "dotted") +
  geom_line(aes(x = times, y = value, col = name, lty = name)) 
```

It looks like `.resid.regression` is identical to the transformed observed value!
The '.resid.innovation' is very similar to the residual in the rate of change, but not quite the same.


#### Residual Frequency
Residuals are not Gaussian! The QQ plot has significant non-Gaussian tails, there are also a number of outliers. See below.

```{r m6_resid_frequencies}
residuals(m6) %>%
  ggplot() +
  geom_qq(aes(sample = .resid)) +
  stat_qq_line(aes(sample = .resid))

residuals(m6) %>%
  ggplot() +
  geom_histogram(aes(x = .resid), bins = 30)
```

#### Autocorrelation of Residuals
```{r m6_resid_acf}
feasts::ACF(residuals(m6, "innovation"), .resid) %>%  #innovation type is forecast using all prior information, regression is the mean
  autoplot()
```

The autocorrelation is pretty high in some places, this is not good.

##### Portmantaeau Test of Residual Autocorrelation
```{r m6_res_portmantaeau}
ljung_box(residuals(m6[[1, 1]])$.resid,
          lag = 16, #16 is a year
          dof = nrow(m6[[1, 1]]$fit$par) ) #dof of the fitted model
ljung_box(residuals(m6[[1, 1]])$.resid,
          lag = 16, #16 is a year
          dof = 6  ) #dof of the ARIMA component
ljung_box(residuals(m6[[1, 1]])$.resid,
          lag = 16, #16 is a year
          dof = nrow(residuals(m6[[1, 1]])) - nrow(m6[[1, 1]]$fit$par)  ) #dof of the ARIMA component
```


__WARNING: I need to look into the mathematics of Ljung-Box test as I'm not sure of the meaning of degrees of freedom when linear regression is involved.__

If the above tests are applied correctly then it means the autocorrelations are statistical significant; the residuals are not consistent with white noise.

#### Constant Variance Given Linear Predictor
Looking at this because that is the model assumption.

#### Additional Structure in Residuals
##### Between-Site Correlation
```{r m6_res_corrbetweenfarms}
resid_mat <- train %>% filtertrain() %>% tibble::rowid_to_column() %>%
  right_join(residuals(m6[[1, 1]]), by = "rowid") %>%
  as_tibble() %>% dplyr::select(times, .resid, site) %>%
  pivot_wider(names_from = site, values_from = .resid) %>%
  dplyr::select(c(-times))
cors <- cor(resid_mat, use = "complete.obs")

reorder_cormat <- function(cormat){
# Use correlation between variables as distance
dd <- as.dist((1-cormat)/2)
hc <- hclust(dd)
cormat <- cormat[hc$order, hc$order]
}

cors %>%
  reorder_cormat() %>%
  reshape2::melt(value.name = "Pearson Correlation") %>%
  ggplot() +
  geom_tile(aes(x = Var1, y = Var2, fill = `Pearson Correlation`)) +
  geom_point(aes(x = Var1, y = Var2, shape = `Pearson Correlation` < 0.80)) +
  scale_fill_viridis_c() +
  scale_shape_manual(name = "Correlation < 0.8", values = c(NA, 19)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  ggtitle("Pearson Correlations of Innovation Residuals")

ordfarms <- colnames(cors %>% reorder_cormat())
ordfarm_cols <- viridis(length(ordfarms))
names(ordfarm_cols) <- ordfarms

pggpp %>%
  filter(sitenum == 1) %>%
  filter(yday %in% seq(1, 366, by = 8)) %>%
  ggplot() +
  facet_wrap(~year, scales = "free") +
  geom_line(aes(x = times, y = pg_24d.ydaymed, col = site),
            alpha = 0.3,
            lty = "dashed", size = 0.1) +
  geom_line(aes(x = times, y = pg_24d, col = site)) +
  scale_color_manual(values = ordfarm_cols) +
  guides(lty = guide_legend()) +
  ggtitle("Median pg_24d vs actual pg_24d: colour ordered by correlation")
```

Some correllation of residuals between sites. The geographic cluster of farms near Gundagai is prominent as having lots of correlation between residuals.

##### Spatial Distributions of Innovation Residuals
```{r spatialdist_innovation_resid}
meanresid <- train %>% filtertrain() %>% tibble::rowid_to_column() %>%
  right_join(residuals(m6[[1, 1]], type = "innovation"), by = "rowid") %>%
  as_tibble() %>%
  group_by(site) %>%
  summarise(avresid = mean(.resid, na.rm = TRUE)) %>%
  mutate(farm = factor(substr(site, 1, 4)))

meanresid %>%
  left_join(sws_sites, by = c(site = "SiteCode")) %>%
  ggplot() +
  geom_text_repel(aes(x = longitude, y = latitude, label = site)) +
  geom_point(aes(x = longitude, y = latitude, col = avresid, size = avresid)) +
  scale_color_viridis_c() +
  guides(
    color = guide_colourbar("Average\nI. Residual Color"),
    size = guide_legend("Average\nI. Residual Size")
  ) +
  coord_fixed() +
  ggtitle("Average Residual of m6 for each site")
```

No discernable spatial pattern in average innovation residuals, except the Gundagai cluster should be visible.

##### Innovation Residuals Distribution per Site
```{r m6_residpersite_dist}
train %>% filtertrain() %>% tibble::rowid_to_column() %>%
  right_join(residuals(m6[[1, 1]], type = "innovation"), by = "rowid") %>%
  as_tibble() %>%
  group_by(site) %>%
  ggplot() +
  geom_hline(yintercept = 0, col = "grey") +
  geom_violin(aes(x = site, y = .resid), fill = "grey") +
  coord_flip() +
  ggtitle("Distributions of Innovation Residuals for Each Site")
train %>% filtertrain() %>% tibble::rowid_to_column() %>%
  right_join(residuals(m6[[1, 1]], type = "innovation"), by = "rowid") %>%
  as_tibble() %>%
  group_by(site) %>%
  ggplot() +
  geom_hline(yintercept = 0, col = "grey") +
  geom_boxplot(aes(x = site, y = .resid), fill = "grey") +
  coord_flip() +
  ggtitle("m6: Distributions of Innovation Residuals for Each Site")

```

##### Innvoation Residuals and Land Use
```{r importsiteuseinfo1}
sws_landuse <- read.table("../private/data/raw/LandUses SWS Farms.csv",
                          sep = ",", skip = 1,
                          as.is = TRUE)
colnames(sws_landuse) <- sws_landuse[1, ]
sws_landuse <- sws_landuse[-1, ]

set.seed(184365)
sws_landuse_train <- sample_frac(sws_landuse, 0.75)
```
```{r m6_innresid_landuse}
meanresid %>%
  right_join(sws_landuse_train, by = c(farm = "FarmUnit")) %>%
  pivot_longer(c(FarmType, `FarmRmnnt (ha)`, FarmEdgeIndexRmnnt,
                 `FarmPlntngs (ha)`, `FarmEdgeIndexPlntngs`, `FarmPine (ha)`, 
                 `FarmClearedLand (ha)`, `FarmPaddockTrees/ha`, `DmnntLandUse`,
                 `FarmTopography`, AnyEnviroWork, Pltngs, Grazing, Remnants,
                 AccmltdScore)) %>%
  ggplot() +
  facet_wrap(~name, scales = "free_x") +
  geom_point(aes(x = value, y = avresid))

library(coin)
independence_test(avresid ~ DmnntLandUse,
                  data = meanresid %>%
                        left_join(sws_landuse_train, by = c(farm = "FarmUnit")) %>%
                    mutate(DmnntLandUse = factor(DmnntLandUse)) )

independence_test(avresid ~ FarmType,
                  data = meanresid %>%
                        left_join(sws_landuse_train, by = c(farm = "FarmUnit")) %>%
                    mutate(FarmType = factor(FarmType)) )
```

Very little in the average innovation appears related to the land use data.
The control and treatment groups appear to have most association, but is still not statistically significant.

##### Association with yday
```{r m6_res_constantvar}
train %>% filtertrain() %>% tibble::rowid_to_column() %>%
  right_join(residuals(m6), by = "rowid") %>%
  ggplot() +
  facet_wrap(~year) +
  geom_hline(yintercept = 0) +
  geom_point(aes(x = yday, y = .resid)) +
  ggtitle("m6: innovation residual by yday")
```

There is definitely still structure in the residuals: clear correlation between residuals on each day. `yday` was not a predictor in the model though.

### Relation to model m1
```{r m6_vs_m1}
m1coefs <- as_tibble(summary(m1)$coefficients, rownames = "term") %>%
  rename(estimate = "Estimate",
         std.error = "Std. Error",
         statistic = "t value",
         p.value = "Pr(>|t|)")
m1coefs$term[[1]] <- "intercept"
left_join(tidy(m6[[1, 1]]),
          m1coefs,
          by = "term",
          suffix = c(".m6", ".m1")) %>%
  dplyr::select(term, estimate.m1, estimate.m6)
```


The fitted coeficients are different between m1 and m6, however for the most part they are very similar in scale.

## m7: Linear Regression with ARIMA errors and sites

```{r m7_parsearch}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp)) # %>%
  #   mutate(recippg_1to5m.ydaymed = 1/pg_1to5m.ydaymed)
  # x$recippg_1to5m.ydaymed <- scale(x$recippg_1to5m.ydaymed)
  return(x)
}

glance(m6[[1, 1]])$AIC
bestscale = optimize(f = function(s) (extractAIC(m1, scale = s)[[2]] - glance(m6[[1, 1]])$AIC)^2,
      interval = c(0, 2))

foundmodel <- step(m1,
                   ~ . * site,
                   scale = bestscale$minimum,
                   direction = "both",
                   trace = 0)

formula(foundmodel)
```

Above uses `scale` argument to account for the correlation between observations when calculating AIC. I expect this to only work partially.

AIC optimisation suggests that interactions with site for *all* terms is useful. That is inconvenient when it comes to extracting a site effect. But anyway, let follow it and see if R2 or anything else improves too.

```{r m7_fit}
filtertrain <- function(x){
  x <- x %>% filter(sitenum == 1,
                    #farm %in% c("BELL", "WILS", "GEDD"),
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}
m7_sp <- ARIMA(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              pg_1to5m * I(1 / pg_1to5m.ydaymed) * pg_24d * farm +  
              pdq())

m7 <- train %>% filtertrain() %>%
  tibble::rowid_to_column() %>% #reindex by approximate 8 day intervals (discrepancies at the end of every year)
  as_tsibble(key = NULL, index = "rowid") %>%
  ungroup() %>%
  model(m7_sp)

print(m7[[1, 1]])
tidy(m7[[1, 1]])
glance(m7[[1, 1]])

m7 %>%
  forecast(new_data = train %>% filtertrain() %>%
             #select(-gpp) %>% # I've checked that it doesn't use gpp
             tibble::rowid_to_column() %>%
             #filter(farm %in% c("GEDD")) %>% 
             update_tsibble(key = NULL, index = "rowid") %>%
             fill_gaps()
           ) %>%
  filter(!is.na(times)) %>%
  update_tsibble(key = "site", index = "times") %>%
  filter(farm %in% c("WILS", "MCRA", "MATH", "DIET")) %>% 
  mutate(interval = hilo(.distribution, 95)) %>%
  ggplot() +
  facet_wrap(~farm, scales = "free_y") +
  geom_ribbon(aes(x = times, ymin = interval$.lower * gpp.ydaymed, ymax = interval$.upper * gpp.ydaymed), fill = "lightgrey") +
  scale_y_continuous(name = "GPP") +
  geom_line(aes(x = times, y = `gpp/gpp.ydaymed` * gpp.ydaymed), col = "black") + 
  geom_line(aes(x = times, y = gpp), col = "blue") +
  ggtitle("m7")
```

The above uses all possible interactions with `farm` as this was suggested by `step()` search with of a linear model.
The model takes a long time to fit (it fitted overnight).
From visual inspection the forecasts of `m6` and `m7` look identical.

### Site Coefficients vs Land Use
```{r displaysitecoeffs}
tdy_siteterms_m7 <- tidy(m7) %>%
  filter(grepl("farm", term)) %>%
  mutate(termshort = gsub("farm....", "", term)) %>%
  mutate(farm = substring(term, regexpr("farm", term) + 4, regexpr("farm....", term) +  7))
farmorder <- tdy_siteterms_m7 %>%
  filter(termshort == "") %>%
  (function(x) reorder(x$farm, x$estimate))
tdy_siteterms_m7 %>%
  ggplot() +
  facet_wrap(~termshort) +
  geom_hline(yintercept = 0, lty = "dashed") +
  geom_crossbar(aes(x = farm, y = estimate /  std.error, ymin = estimate / std.error - 2, ymax = estimate / std.error + 2, fill = farm), fatten = 0.5) +
  scale_fill_viridis_d() +
  scale_x_discrete(limits = rev(levels(farmorder))) +
  # theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1)) +
  coord_flip()

tdy_siteterms_m7 %>%
  left_join(sws_sites %>% mutate(farm = substr(SiteCode, 1, 4), by = "farm")) %>%
  ggplot() +
  facet_wrap(~termshort) +
  #geom_text_repel(aes(x = longitude, y = latitude, label = farm)) +
  guides(
    color = guide_colourbar("Estimate"),
    size = guide_legend("Estimate")
  ) +
  geom_point(aes(x = longitude, y = latitude,
                 size  = estimate / std.error,
                 col = estimate / std.error,
                 shape = p.value < 0.05,
                 alpha = p.value < 0.05)) +
  scale_color_viridis_c() +
  scale_size(range = c(0, 4)) +
  scale_shape(solid = TRUE) +
  coord_fixed() +
  ggtitle("m7: site coefficient estimates")
```

These plots are curious. No single plot means 'less gpp than site-free model predicts' because many sites have both positive and negative coefficients. It also lookis like coefficients of each terms are either significantly negative or positive, and not mixed. Perhaps the largest sign is whether the estimates are signficant or not.

+ The intercepts indicate on average how much relative GPP (relative to seasonal GPP) there is.

+ More positive coefficients interaction with `I(1/pg_1to5m.ydaymed)` mean that seasons with small 5-monthly past rainfall correlated to more positive relative GPP.

+ (negative ==> higher grazing pressure) Negative coefficients for interaction with `I(1/pg_1to5m.ydaymed):pg_24d` suggest that for this site high amounts of recent rain during a lower seasonal rain period, result in lower GPP. __suggestive of poorer or slower reaction to rain during *dry* seasons__.

+ (positive ==> lower grazing pressure) Positive coefficient for interaction with `pg_1to5m` suggests more rain over past 5-months leads to more GPP. __Larger values of this coefficient would suggest better reaction to rain.__

+ (negative ==> higher grazing pressure) Negative coefficients for interaction with `pg_1to5m:I(1/pg_1to5m.ydaymed)` suggests that __more rain in the moderate past has a smaller than expected increase on relative GPP during *dry* seasons.__

+ (positive ==> lower grazing pressure) Positive coefficients for interaction with `pg_1to5m:I(1/pg_1to5m.ydaymed):pg_24d` means __rain in short or medium term during dryer seasons correlated with greater relative GPP than other sites.__ 

+ (negative ==> higher grazing pressure) Negative coefficient for interaction with `pg_1to5m:pg_24d:` means __smaller relative GPP than other sites given recent rain on average across all seasons__.

+ (positive ==> lower grazing pressure) Positive coefficients for interaction with `pg_24d` means __more relative GPP than other sites given recent rain.__

For interaction terms with `pg_1to5m` or `pg_24d`:

  1. fitted significant negative coefficients correspond to higher grazing pressure
  2. fitted significant positive coefficients correspond to lower grazing pressure
  3. I find the coefficients for interactions with `I(1/pg_1to5m.ydaymed):pg_24d` most interesting. That corresponds to lower GPP given recent rains during drier seasons. 

```{r importsiteuseinfo2}
sws_landuse <- read.table("../private/data/raw/LandUses SWS Farms.csv",
                          sep = ",", skip = 1,
                          as.is = TRUE)
colnames(sws_landuse) <- sws_landuse[1, ]
sws_landuse <- sws_landuse[-1, ]

set.seed(184365)
sws_landuse_train <- sample_frac(sws_landuse, 0.75)
```


```{r m7sitecoefs_plotted_with_landuse}
tdy_siteterms_m7 %>%
  left_join(sws_landuse_train, by = c(farm = "FarmUnit")) %>%
  ggplot() +
  facet_wrap(~termshort) +
  geom_hline(yintercept = 0, lty = "dashed") +
  geom_crossbar(aes(x = farm, y = estimate /  std.error, ymin = estimate / std.error - 2, ymax = estimate / std.error + 2, fill = DmnntLandUse), fatten = 0.5) +
  scale_fill_viridis_d() +
  scale_x_discrete(limits = rev(levels(farmorder))) +
  # theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1)) +
  coord_flip()

library(coin)
independence_test(estimate ~ DmnntLandUse | termshort,
                  data = tdy_siteterms_m7 %>%
                    left_join(sws_landuse_train, by = c(farm = "FarmUnit")) %>%
                    mutate(DmnntLandUse = factor(DmnntLandUse)) %>%
                    mutate(termshort = factor(termshort)) )

# independence_test(estimate ~ DmnntLandUse,
#                   data = tdy_siteterms_m7 %>%
#                     left_join(sws_landuse_train, by = c(farm = "FarmUnit")) %>%
#                     mutate(DmnntLandUse = factor(DmnntLandUse)) %>%
#                     mutate(termshort = factor(termshort)) %>%
#                     filter(termshort == "pg_1to5m:I(1/pg_1to5m.ydaymed):pg_24d:"))
```

The independence test above tests whether the ordering of estimates is conditionally independent of the dominant land use given termshort. A very large $p$-value means that the test does not detect statistically significant inconsistency with independence between observed land use and the estimated site coefficients.


#### Additional Structure in Residuals
##### Between-Site Correlation
```{r m7_res_corrbetweenfarms}
resid_mat <- train %>% filtertrain() %>% tibble::rowid_to_column() %>%
  right_join(residuals(m7[[1, 1]]), by = "rowid") %>%
  as_tibble() %>% dplyr::select(times, .resid, site) %>%
  pivot_wider(names_from = site, values_from = .resid) %>%
  dplyr::select(c(-times))
cors <- cor(resid_mat, use = "complete.obs")

reorder_cormat <- function(cormat){
# Use correlation between variables as distance
dd <- as.dist((1-cormat)/2)
hc <- hclust(dd)
cormat <- cormat[hc$order, hc$order]
}

cors %>%
  reorder_cormat() %>%
  reshape2::melt(value.name = "Pearson Correlation") %>%
  ggplot() +
  geom_tile(aes(x = Var1, y = Var2, fill = `Pearson Correlation`)) +
  geom_point(aes(x = Var1, y = Var2, shape = `Pearson Correlation` < 0.80)) +
  scale_fill_viridis_c() +
  scale_shape_manual(name = "Correlation < 0.8", values = c(NA, 19)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  ggtitle("m7: Pearson Correlations of Innovoation Residuals")

ordfarms <- colnames(cors %>% reorder_cormat())
ordfarm_cols <- viridis(length(ordfarms))
names(ordfarm_cols) <- ordfarms
```


##### Innovation Residuals per Site (including spatial plot)
```{r m7_spatialdist_innovation_resid}
medresid <- train %>% filtertrain() %>% tibble::rowid_to_column() %>%
  right_join(residuals(m7[[1, 1]], type = "innovation"), by = "rowid") %>%
  as_tibble() %>%
  group_by(site) %>%
  summarise(medresid = median(.resid, na.rm = TRUE)) %>%
  mutate(farm = factor(substr(site, 1, 4)))

medresid %>%
  left_join(sws_sites, by = c(site = "SiteCode")) %>%
  #filter(farm != "ARCH") %>%
  ggplot() +
  geom_point(aes(x = longitude, y = latitude, col = medresid, size = medresid)) +
  scale_color_viridis_c() +
  geom_text_repel(aes(x = longitude, y = latitude, label = site)) +
  guides(
    color = guide_colourbar("Median\nI. Residual Color"),
    size = guide_legend("Median\nI. Residual Size")
  ) +
  coord_fixed() +
  ggtitle("Median Residual of m7 for each site")

train %>% filtertrain() %>% tibble::rowid_to_column() %>%
  right_join(residuals(m7[[1, 1]], type = "innovation"), by = "rowid") %>%
  as_tibble() %>%
  group_by(site) %>%
  mutate(.resid_cum = cumsum(.resid)) %>%
  ggplot() +
  facet_wrap(~site) +
  geom_hline(yintercept = 0, lty = "dashed", col = "grey") +
  geom_line(aes(x = times, y = .resid, col = .resid_cum), lwd = 1) +
  scale_color_viridis_c() +
  ggtitle("m7 innovation residuals by site")

train %>% filtertrain() %>% tibble::rowid_to_column() %>%
  right_join(residuals(m7[[1, 1]], type = "innovation"), by = "rowid") %>%
  as_tibble() %>%
  group_by(site) %>%
  ggplot() +
  geom_hline(yintercept = 0, col = "grey") +
  geom_violin(aes(x = site, y = .resid), fill = "grey") +
  coord_flip() +
  ggtitle("Distributions of Innovation Residuals for Each Site")
train %>% filtertrain() %>% tibble::rowid_to_column() %>%
  right_join(residuals(m7[[1, 1]], type = "innovation"), by = "rowid") %>%
  right_join(residuals(m6[[1, 1]], type = "innovation"), by = "rowid", suffix  = c("", ".m6")) %>%
  pivot_longer(c(.resid, .resid.m6)) %>%
  as_tibble() %>%
  group_by(site) %>%
  ggplot() +
  geom_hline(yintercept = 0) +
  geom_boxplot(aes(x = site, y = value, col = name)) +
  coord_flip() +
  ggtitle("m7: Distributions of Innovation Residuals for Each Site")
```

The ARCH1 farm is a massive outlier in average residual but not median residual aboves. __Why?__ The residuals of ARCh1 totally with reason when plotted.

##### Innvoation Residuals and Land Use
```{r importsiteuseinfo3}
sws_landuse <- read.table("../private/data/raw/LandUses SWS Farms.csv",
                          sep = ",", skip = 1,
                          as.is = TRUE)
colnames(sws_landuse) <- sws_landuse[1, ]
sws_landuse <- sws_landuse[-1, ]

set.seed(184365)
sws_landuse_train <- sample_frac(sws_landuse, 0.75)
```
```{r m7_innresid_landuse}
medresid %>%
  right_join(sws_landuse_train, by = c(farm = "FarmUnit")) %>%
  pivot_longer(c(FarmType, `FarmRmnnt (ha)`, FarmEdgeIndexRmnnt,
                 `FarmPlntngs (ha)`, `FarmEdgeIndexPlntngs`, `FarmPine (ha)`, 
                 `FarmClearedLand (ha)`, `FarmPaddockTrees/ha`, `DmnntLandUse`,
                 `FarmTopography`, AnyEnviroWork, Pltngs, Grazing, Remnants,
                 AccmltdScore)) %>%
  ggplot() +
  facet_wrap(~name, scales = "free_x") +
  geom_label_repel(aes(x = value, y = medresid, label = farm),
                   data = function(x) x %>% filter(medresid < -0.08)) +
  geom_point(aes(x = value, y = medresid))

library(coin)
independence_test(medresid ~ DmnntLandUse,
                  data = medresid %>%
                        left_join(sws_landuse_train, by = c(farm = "FarmUnit")) %>%
                    mutate(DmnntLandUse = factor(DmnntLandUse)) )

independence_test(medresid ~ FarmType,
                  data = medresid %>%
                        left_join(sws_landuse_train, by = c(farm = "FarmUnit")) %>%
                    mutate(FarmType = factor(FarmType)) )
```


##### Association with yday
```{r m7_res_constantvar}
train %>% filtertrain() %>% tibble::rowid_to_column() %>%
  right_join(residuals(m7, type = "innovation"), by = "rowid", suffix = c("", ".m7")) %>%
  right_join(residuals(m6, type = "innovation"), by = "rowid", suffix = c("", ".m6")) %>%
  pivot_longer(c(.resid.m6, .resid)) %>%
  ggplot() +
  facet_wrap(~year) +
  geom_hline(yintercept = 0) +
  geom_point(aes(x = yday + 3 - 6 * (name == ".resid.m6"), y = value, col = name)) +
  scale_x_continuous(name = "yday") +
  ggtitle("m7: innovation residual by yday")
```


## Summary
This document has fit 7 models:
```{r modelforms, echo = FALSE}
cat("m1: ")
formula(m1)
cat("m2: ")
formula(m2)
cat("m3: ")
formula(m3)
cat("m4: ")
formula(m4)
cat("m5: ")
formula(m5)
cat("m6: ")
formula(m6_sp)
cat("m7: ")
formula(m7_sp)
```

All models fit `box_cox(gpp/gpp.ydaymed, lambda = 0.2626)` rather than GPP directly.

+ `gpp.ydaymed` is the median GPP for each day of the year for each *site*. It was included as a quick way to allow site-specific baseline GPP. A ratio was used as it seems a more plausible way to have GPP close to 0.
 + The variance stabilising transformation Box-Cox was used, with the lambda found in exploration in earlier work using the MASS:boxcox() function. I suspect it maximises variance stationarity given an assumption that the response variable mean is constant, but I have not looked into the theory. __This could be improved by using `boxcox()` with `m1`.__
 + `pg_1to5m` is the rainfall that occured in the last 5 months (excluding today). In file `1_5_....Rmd` the `pg_1to5m` variable had smaller p-values than other variables for one of the `gam` models. __This is a rather adhoc approach and could be improved using model selectio techniques.__
 + `pg_1to5m.ydaymed` is the median for the last 5 months rainfall for this day, across the same day every year and at each site. It was chosed to use this as a reciprical value because it is smoother than the rainfall over shorter time spans. __This is a rather adhoc approach and could be improved using model selectio techniques.__
 + `pg_24d` is the rainfall that occurs in the last 24 days. This was chosen because the autocorrelation and partial autocorrelatin of GPP was observed to be highish for 2 lags (corresponding to 8 and 16 days in the past).
 + `farm` is the factor-valued variable indicating the farm that the data came from.
 
Numerical aspects: to reduce computation cost and correlation between observations the models were fitted using only the first site from each farm, and every third GPP observation.

`m1` - `m4` are linear models. m1 is the simplest and first plausible mean model obtained. 
It is the interaction of `pg_1to5m`,  `1/pg_1to5m.ydaymed` and `pg_24d`, and all lower order terms. Models m2 - m4 add higher order terms and a `farm` term to see if a better model could be obtained. None of them had much better R2 values than m1. The distributional assumptions of m1 are totally flawed: estimated variance is too small due to correlated observations, there are also some outliers.

`m5` was a fitted GAM to see if the results of `m1` would be improved. This was not the case. The predictions visually were similar, but the relation between response and fitted values was much poorer than `m1`: a trend in the fitted values was clear, it was very strange that such a trend is present as it looks like a spline would easily remove such issues.

`m6` was a linear regression of form the same as `m1`, with ARIMA error terms. This was to account for the correlation in GPP values. This model was the first to give plausible error intervals.
However, the errors, after the ARIMA model was taken into account, were still autocorrelated. There were also a number of observations with unusually high residual and unusually low residual. The QQ plot of residuals suggests the distribution was not entirely normal.

`m7` was like `m6` but with terms for farms. It took a very long time to fit and its innovation residuals do not appear to be much better tham `m6`. In fact for each site it looks like the innovation residuals are larger for `m7` than for `m6`. However the residuals of TREV, SCHO, FUEU appear to be centred closer to zero for `m7`. The residuals of DIET MCRA are opposite - they appear to be further from zero for `m7`. At this point we can't really intepret the $p$ values safely. We can say that `m7` is likely to be at least as good as `m6`.


### On differences between sites
Comparisons of median innovation residuals for `m6` and `m7` and the land use of each site were made (excluding 0.25 of the sites for later testing if needed). No relation was observed visually or through permutation tests.
The different median innovation residuals of each site were plotted spatially for each of `m6` and `m7`.

The coefficients of the terms that involve `farm` in `m7` were also investigated. There was no association with land Use terms either. They do appear to have spatial trends though.


### Future

 + D: Remove outliers to achieve residuals that are normally distributed (check with Q-Q plot)
 
 + D: Nail down what the innovation residuals are.
 
 + Resolve issue that autocorrelation remains in residuals, perhaps by using 1 in 4 data points (rather than the 1 in 3 currentl)
 
 + Consider using model search methods (stepAIC, or something more generic) to find better sets of predictors to include.
 
 + D: Search for a better scale in the Box-Cox transformation using `m1`.
 
 + Better seasonal rainfall and GPP using cyclic GAMs.
 
 + Other ways to summarise residuals
    + Consider fitting models for the residuals.
    + Use time-sensitive decompositions of the residuals
    
 + Use all the farms in the SWS study OR use pixels rather than farms.
 
 + It may be that the median residuals for each site are meaningful for biodiversity. Consider including them for biodiversity prediction. And asking people familiar with the farms.
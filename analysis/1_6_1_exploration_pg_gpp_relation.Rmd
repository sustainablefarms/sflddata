---
title: 'Very Simple Models for GPP: improvements'
author: "Kassel Hingee"
date: "30/01/2020"
output: 
  html_document: 
    keep_md: yes
    toc: yes
---

## Preparation
```{r setup, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
out <- lapply(c("sf", "tsibble", 'lubridate', "viridis",
                'ggplot2', 'tidyr', 'grid', 'gridExtra', 
                'feasts', 'dplyr', 'gtable', 'fable',
                'mgcv'),
       library, character.only = TRUE)
out <- lapply(paste0("../functions/", list.files("../functions/")), source)
```

```{r preparedata}
#load data and convert to tsibbles
load("../private/data/remote_sensed/pg_daily.Rdata")
pg_daily$times <- as_date(pg_daily$times)
pg <- pg_daily %>%
  pivot_longer(-times, names_to = "site", values_to = "pg") %>%
  as_tsibble(key = site, index = times)
load("../private/data/remote_sensed/gpp_8d.Rdata")
gpp <- gpp_8d %>%
  pivot_longer(-times, names_to = "site", values_to = "gpp") %>%
  as_tsibble(key = site, index = times)
pggpp <- as_tsibble(dplyr::full_join(pg, gpp, by = c("times", "site")), key = site, index = times)

# add times breakdowns
pggpp <- pggpp %>%
  mutate(yday = yday(times),
         year = year(times))
  

#interpolate gpp
pggpp <- pggpp %>%
  group_by_key() %>% #key is site
  mutate(lininterp_gpp = zoo::na.approx(gpp, rule = 2, na.rm = FALSE)) %>% #rule 2 means edges are assigned last value
  ungroup()

#make sure sites are ordered alphabetically
pggpp <- pggpp %>%
  arrange(site) %>%
  mutate(site = factor(site, ordered = TRUE))

#separate alpha part of site code
pggpp <- pggpp %>%
  mutate(farm = factor(substr(site, 1, 4)),
         sitenum = factor(as.integer(substr(site, 5, 5))))


# Add cumulative rainfalls
pggpp <- pggpp %>% 
  group_by_key() %>%
  mutate(pg_cumsum = cumsum(pg)) %>%
  mutate(pg_1to7 = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 8), # 1 up to 8 days behind (excluding 8th day)
         pg_1to15 = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 16), # 1 to 16 days behind
         pg_1to1m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 31),
         pg_1to2m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 2*31),
         pg_1to3m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 3*31),
         pg_1to4m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 4*31),
         pg_1to5m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 5*31),
         pg_1to6m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 6*31),
         pg_1to7m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 7*31),
         pg_1to8m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 8*31),
         pg_1to10m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 10*31),
         pg_1to12m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 12*31),
         pg_1to14m = lag(pg_cumsum, n = 1) - lag(pg_cumsum, n = 14*31),
         ) %>%
  mutate(pg_8d = pg_cumsum - lag(pg_cumsum, n = 8),
         #0 to day 7 (8 days) cumulative rainfall to correspond with gaps in GPP
         pg_24d = pg_cumsum - lag(pg_cumsum, n = 3*8)) %>% 
         # every 24 days (3*8) of GPP should be less correlated (given average GPP), this pg_24d corresponds to the rain through that period
  ungroup()
```

```{r seasonalreferences}
# simple median of values
ydaymedian <- pggpp %>%
  filter(yday %in% seq(1, 366, by = 8)) %>%
  group_by(site) %>%
  index_by(yday) %>%
  summarise(gpp.ydaymed = median(gpp),
            pg_8d.ydaymed = median(pg_8d),
            pg_24d.ydaymed = median(pg_24d),
            pg_1to5m.ydaymed = median(pg_1to5m, na.rm = TRUE))
pggpp <- left_join(pggpp, ydaymedian, by = c("site", "yday"))
```

```{r preparetraintest}
train <- pggpp %>%
  filter(yday %in% seq(1, 366, by = 8)) %>%
  filter(sitenum == 1) %>% #so not doubling up at farms
  filter_index(. ~ "2016-12-31") %>%
  dplyr::select(-pg_cumsum, -lininterp_gpp) %>%
  mutate(gpp = if_else(gpp < 0.1, as.double(NA), gpp)) #remove outlying GPP values that are super low

test <- pggpp %>%
  filter_index("2017-01-01" ~ .) %>%
  filter(sitenum == 1) %>% #so not doubling up at farms
  filter(yday %in% seq(1, 366, by = 8)) %>%
  dplyr::select(-pg_cumsum)
```


In the above very small GPP values have been removed. There was `r sum(is.na(train$gpp))` of them, which corresponds to `r sum(is.na(train$gpp)) / length(train$gpp)` of the data.

## Previous Models
### m1: Single order linear model with interaction
Recipricoal of pg_1to5m.ydaymed included.
```{r m1}
filtertrain1 <- function(x){
  x <- x %>% filter(sitenum == 1,
                    !is.na(pg_1to14m),
                    yday %in% seq(1, 366, by = 3 * 8), #reduce correlation in data fitting and reduce fitting time
                    !is.na(gpp))
  return(x)
}

m1 <- lm(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              pg_1to5m * I(1 / pg_1to5m.ydaymed) * pg_24d,
              data = train %>% filtertrain1() )
```

### m6: linear model with interactions and ARIMA errors
```{r m6_fitarima}
m6_sp <- ARIMA(box_cox(gpp / gpp.ydaymed, lambda = 0.2626) ~ 
              pg_1to5m * I(1 / pg_1to5m.ydaymed) * pg_24d +
              pdq())


m6 <- train %>% filtertrain1() %>%
  tibble::rowid_to_column() %>% #reindex by approximate 8 day intervals (discrepancies at the end of every year)
  as_tsibble(key = NULL, index = "rowid") %>%
  ungroup() %>%
  model(m6_sp)
```

### m7: linear model with interactions, ARIMA errors and site terms
Loaded from previous document
```{r m7load}
m7 <- readRDS("../private/models/m7_v1.rds")
```

## Nail down what the innovation residuals are
According to Cryer and Chan [Section 11.2], there are additive outliers and innovaive outliers.
An additive outliers is a pulse that purturbs the value of the time series for only one time step.
Innovative outliers purturb the error term, and thus their effect last over multiple time points.

According to the `fable` source code, `fable::residuals(type = "innovation")` extracts the `.resid` attribute of the fitted model, which I think come straight from the `stats::arima`residuals method. In `stats::ARIMA` the residuals come from calls to C_ARIMA_Like. `help(arima)` describes the residuals as the 'fitted innovations', I reckon these are observations of the $\epsilon_t$ process if the model parameters and form are assumed to be true. For `m6`, when GPP is given then the observed values of $\epsilon_t$ are given by solving the below equation. These observed values of $\epsilon_t$ *should* be generated by i.i.d. Gaussians.

\[
\begin{align}
\frac{y_t^\lambda - 1}{\text{y.ydaymed(t)}} =
\phi_1 \frac{y_{t-1}^\lambda - 1}{\text{y.ydaymed(t-1)}} + 
\phi_2 \frac{y_{t-2}^\lambda - 1}{\text{y.ydaymed(t-2)}} + \\
\epsilon_t +
\theta_1 \epsilon_{t - 1} +
\theta_2 \epsilon_{t - 2} +
\theta_3 \epsilon_{t - 4} +
\theta_3 \epsilon_{t - 4} +\\
\beta_0 + 
\beta_1 \text{pg_1to5m} +
\beta_2 \frac{1}{\text{pg_1to5m.ydaymed}} +\\
\beta_3 \text{pg_24d} +
\beta_4 \text{pg_1to5m:I(1/pg_1to5m.ydaymed)} +\\
\beta_5 \text{pg_1to5m:pg_24d} +
\beta_6 \text{I(1/pg_1to5m.ydaymed):pg_24d} +\\
\beta_7 _1to5m:I(1/pg_1to5m.ydaymed):pg_24d}
\end{align}
\]

## Remove outliers
### Identify Outliers
```{r m1m6_outliers}
resids <- tibble::enframe(residuals(m1), name = "rowid", value = ".resid") %>%
  mutate(rowid = as.integer(rowid)) %>%
  left_join(residuals(m6), by = "rowid", suffix = c(".m1", ".m6")) %>%
  select(-.model) %>%
  left_join(residuals(m7), by = "rowid", suffic = c("", ".m7")) %>%
  select(-.model) %>%
  rename(.resid.m7 = .resid)

cutoffs <- quantile(resids$.resid.m1, probs = c(0.001, 0.999))
resids <- resids %>%
  mutate(outlier.m1 = if_else( (.resid.m1 < cutoffs[[1]]) | (.resid.m1 > cutoffs[[2]]), "m1", "FALSE"))
cutoffs <- quantile(resids$.resid.m6, probs = c(0.001, 0.999))
resids <- resids %>%
  mutate(outlier.m6 = if_else( (.resid.m6 < cutoffs[[1]]) | (.resid.m6 > cutoffs[[2]]), "m6", "FALSE"))
cutoffs <- quantile(resids$.resid.m7, probs = c(0.001, 0.999))
resids <- resids %>%
  mutate(outlier.m7 = if_else( (.resid.m7 < cutoffs[[1]]) | (.resid.m7 > cutoffs[[2]]), "m7", "FALSE")) %>%
  mutate(outlier = factor(outlier.m1) : factor(outlier.m6) : factor(outlier.m7))
resids <- resids %>%
  left_join(train %>% filtertrain1() %>% tibble::rowid_to_column(), by = "rowid")
farmswoutliers <- resids %>%
  group_by(farm) %>%
  summarise(any.outliers = any(outlier != "FALSE:FALSE:FALSE"))

resids %>%
  pivot_longer(c(.resid.m1, .resid.m6, .resid.m7)) %>%
  ggplot() +
  facet_grid(rows = vars(name)) +
  geom_point(aes(x = rowid, y = value), col = "black",
             alpha = 0.5, size = 0.1) +
  geom_point(aes(x = rowid, y = value,
                 col = outlier,
                 shape = outlier),
             size = 2,
             data = function(x) x %>% filter(outlier != "FALSE:FALSE:FALSE")) +
  scale_color_viridis_d(begin = 0.5) +
  scale_shape_manual(values = c(3, 4, 6, 8, 16:18)) +
  ggtitle("outliers given by m1, m6 and m7")
```

The outliers given by `m6` innovation residuals appear to be points in the tails or shoulders for `m1` and `m7`.

The outliers given by `m7` residuals remove a lot of the points in the tail for 

```{r viewm6outliers}
m6 %>%
  forecast(new_data = train %>% filtertrain1() %>%
             tibble::rowid_to_column() %>%
             left_join(resids %>% select(rowid, .resid.m6, outlier.m6, outlier.m7), by = "rowid") %>%
             update_tsibble(key = NULL, index = "rowid") %>%
             fill_gaps()
           ) %>%
  filter(!is.na(times)) %>%
  update_tsibble(key = "site", index = "times") %>%
  filter(farm %in% (farmswoutliers %>% filter(any.outliers == TRUE))$farm) %>%
  mutate(interval = hilo(.distribution, 95)) %>%
  ggplot() +
  facet_wrap(~farm, scales = "free_y") +
  geom_ribbon(aes(x = times, ymin = interval$.lower * gpp.ydaymed, ymax = interval$.upper * gpp.ydaymed), fill = "lightgrey") +
  geom_line(aes(x = times, y = `gpp/gpp.ydaymed` * gpp.ydaymed), col = "black") + 
  geom_line(aes(x = times, y = gpp), col = "blue") +
  geom_point(aes(x = times, y = gpp), 
             col = "red", shape = 1, size = 2,
             data = function(x) x %>% filter(outlier.m6 == "m6")) +
  geom_rug(aes(x = times, y = gpp), 
             col = "red", sides = "b",
             data = function(x) x %>% filter(outlier.m6 == "m6")) +
  geom_point(aes(x = times, y = gpp), 
             col = "green", shape = 2, size = 2,
             data = function(x) x %>% filter(outlier.m7 == "m7")) +
  geom_rug(aes(x = times, y = gpp), 
             col = "green", sides = "b",
             data = function(x) x %>% filter(outlier.m7 == "m7")) +
  scale_y_continuous(name = "GPP") +
  ggtitle("gpp and m6 forecast with different outliers")
```

These outliers look like legitimate data. Removing them will mean that the model does not apply to them. Autmn in 2014 is marked as outlying by at least two sites (DIET and MCRA). It is a spike not predicted by the model for many of the sites.
Particularly MCRA appears to have high outliers that might indicate very good response to rainfall.

#### 2014 spike
```{r the2014outlyingspike}
pg_by_yearmonth <- pggpp %>%
  group_by_key() %>%
  index_by(ym = yearmonth(times)) %>%
  summarise(monthlypg = sum(pg))
mean_monthly_pg <- pg_by_yearmonth %>% 
  as_tibble() %>%
  group_by(site, m = month(ym)) %>%
  summarise(mean_monthly_pg = mean(monthlypg))

df <- m6 %>%
  forecast(new_data = train %>% filtertrain1() %>%
             tibble::rowid_to_column() %>%
             left_join(resids %>% select(rowid, .resid.m6, outlier.m6, outlier.m7), by = "rowid") %>%
             update_tsibble(key = NULL, index = "rowid") %>%
             fill_gaps()
           ) %>%
  filter(!is.na(times)) %>%
  update_tsibble(key = "site", index = "times") %>%
  mutate(interval = hilo(.distribution, 95))


g1 <- df %>%
  filter(site %in% c("DIET1")) %>%
  filter_index("2013" ~ "2015") %>%
  ggplot() +
  facet_wrap(~farm, scales = "free_y") +
  geom_ribbon(aes(x = times, ymin = interval$.lower * gpp.ydaymed, ymax = interval$.upper * gpp.ydaymed), fill = "lightgrey") +
  geom_line(aes(x = times, y = `gpp/gpp.ydaymed` * gpp.ydaymed), col = "black") + 
  geom_line(aes(x = times, y = gpp), col = "blue") +
  geom_point(aes(x = times, y = gpp), 
             col = "red", shape = 1, size = 2,
             data = function(x) x %>% filter(outlier.m6 == "m6")) +
  geom_rug(aes(x = times, y = gpp), 
             col = "red", sides = "b",
             data = function(x) x %>% filter(outlier.m6 == "m6")) +
  geom_point(aes(x = times, y = gpp), 
             col = "green", shape = 2, size = 2,
             data = function(x) x %>% filter(outlier.m7 == "m7")) +
  geom_rug(aes(x = times, y = gpp), 
             col = "green", sides = "b",
             data = function(x) x %>% filter(outlier.m7 == "m7")) +
  scale_y_continuous(name = "GPP") +
  ggtitle("gpp and m6 forecast with different outliers")
  
g2 <- train %>%
  filter(site %in% c("DIET1")) %>%
  filter_index("2013" ~ "2015") %>%
  as_tibble() %>%
  left_join(as_tibble(df) %>% select(times, `gpp/gpp.ydaymed`, interval, outlier.m6, outlier.m7),
            by = "times") %>%
  mutate(m = month(times)) %>%
  left_join(mean_monthly_pg, by = c("site", "m")) %>%
  ggplot() +
  facet_wrap(~farm, scales = "free_y") +
  #geom_line(aes(x = times, y = mean_monthly_pg), lty = "dotted") +
  geom_line(aes(x = times, y = pg_1to5m.ydaymed), lty = "dotted") +
  geom_line(aes(x = times, y = pg_24d.ydaymed), lty = "dotted") +
  geom_line(aes(x = times, y = pg_1to5m), lty = "solid") +
  geom_line(aes(x = times, y = pg_24d), lty = "solid") +
  geom_vline(aes(xintercept = times), 
             col = "red", 
             data = function(x) x %>% filter(outlier.m6 == "m6")) +
  geom_vline(aes(xintercept = times), 
             col = "green",
             data = function(x) x %>% filter(outlier.m7 == "m7")) +
  scale_y_continuous(name = "Precipitation") +
  ggtitle("Precipitation and m6 forecast with different outliers")

library(patchwork)
g2 / g1
```

At DIET1 the summer autumn 2014 GPP spike is just after lots of rain, at the end of a relatively dry summer. 


__Decision:__ for now may as well remove outliers according to each of the models, to see if results improve.

### Remove Outliers
```{r removeoutliers}
resids <- tibble::enframe(residuals(m1), name = "rowid", value = ".resid") %>%
  mutate(rowid = as.integer(rowid)) %>%
  left_join(residuals(m6), by = "rowid", suffix = c(".m1", ".m6")) %>%
  select(-.model) %>%
  left_join(residuals(m7), by = "rowid", suffic = c("", ".m7")) %>%
  select(-.model) %>%
  rename(.resid.m7 = .resid)

cutoffs <- quantile(resids$.resid.m1, probs = c(0.001, 0.999))
resids <- resids %>%
  mutate(outlier.m1 = if_else( (.resid.m1 < cutoffs[[1]]) | (.resid.m1 > cutoffs[[2]]), "m1", "FALSE"))
cutoffs <- quantile(resids$.resid.m6, probs = c(0.001, 0.999))
resids <- resids %>%
  mutate(outlier.m6 = if_else( (.resid.m6 < cutoffs[[1]]) | (.resid.m6 > cutoffs[[2]]), "m6", "FALSE"))
cutoffs <- quantile(resids$.resid.m7, probs = c(0.001, 0.999))
resids <- resids %>%
  mutate(outlier.m7 = if_else( (.resid.m7 < cutoffs[[1]]) | (.resid.m7 > cutoffs[[2]]), "m7", "FALSE")) %>%
  mutate(outlier = factor(outlier.m1) : factor(outlier.m6) : factor(outlier.m7))

outliers <- resids %>%
  left_join(train %>% filtertrain1() %>% tibble::rowid_to_column() %>% 
              select(rowid, times, farm, site), by = "rowid") %>%
  select(times, site, outlier)
  

filtertrain2 <- function(x) {
  x <- x %>% filtertrain1() %>%
    left_join(outliers, by = c("times", "site")) %>%
    mutate(gpp = if_else(outlier == "FALSE:FALSE:FALSE", gpp, as.double(NA))) %>%
    select(-outlier)
  return(x)
}
```

### Refit m6 to see if new result any better:
```{r quickm6refit}
m6_remout <- train %>% filtertrain2() %>%
  tibble::rowid_to_column() %>% #reindex by approximate 8 day intervals (discrepancies at the end of every year)
  as_tsibble(key = NULL, index = "rowid") %>%
  ungroup() %>%
  model(m6_sp)


residuals(m6_remout) %>%
  ggplot() +
  geom_point(aes(x = rowid, y = .resid), size = 0.5)
```

The residuals appear to have constant variance with rowid now. 

Investigate the distribution more thoroughly using a Q-Q plot:
```{r m6_remout_norm}
resvis <- rnorm(n = nrow(residuals(m6_remout)) * 19) %>%
  matrix(ncol = 19) %>%
  as_tibble(.name_repair = "universal")
resvis$obs <- scale(residuals(m6_remout)$.resid)
set.seed(35465)
neworder <- sample(1 : 20)
resvis <- resvis[, neworder]
names(resvis) <- 1 : 20
resvis$rowid <- residuals(m6_remout)$rowid
  
resvis %>%
  pivot_longer(-rowid) %>%
  ggplot() +
  facet_wrap(~name) +
  geom_qq(aes(sample = value)) +
  geom_abline(slope = 1, intercept = 0)
```

Before looking at the reordering value: the appearance of data set 16 is striking, far larger tails than any other data set.
Checked with `neworder` and 16 corresponds to the observed residuals.

However the discrepancy doesn't look very large, maybe methods will work ok for it?

## Find a better lambda for Box-Cox using m1 model
```{r boxcoxlambda}
bct <- MASS::boxcox(lm(gpp/gpp.ydaymed ~ pg_1to5m * I(1/pg_1to5m.ydaymed) * pg_24d,
             data = train %>% filtertrain1()))
bestlambda <- bct$x[which.max(bct$y)]
```

### m1b: m1 with better lambda
```{r m1b}
m1b <- lm(box_cox(gpp / gpp.ydaymed, lambda = 0.1414141) ~ 
              pg_1to5m * I(1 / pg_1to5m.ydaymed) * pg_24d,
              data = train %>% filtertrain1() )
saveRDS(m1b, file = "../private/models/m1b.rds")
```

```{r m1b_plotsforpres, height = 10}
newdata <- pggpp %>%
  filtertrain1() %>%
  tibble::rownames_to_column(var = "rowname")
pred <- newdata %>%
  left_join(as_tibble(x = data.frame(predict(m1b,
                                             newdata = newdata,
                                             type = "response")), rownames = "rowname"),
            by = "rowname") %>% 
  rename(linpred = "predict.m1b..newdata...newdata..type....response..") %>%
  mutate(pred_m1b = inv_box_cox(linpred, lambda = 0.1414141) * gpp.ydaymed)
pred %>%
  filter(farm %in% c("PAEC")) %>%
  pivot_longer(c(pred_m1b, gpp, gpp.ydaymed), values_to = "GPP", names_to = "Type") %>%
  ggplot() +
  geom_line(aes(x = times, y = GPP, col = Type, lty = Type, size = Type), alpha = 0.8) +
  # scale_color_manual(labels = c("Observed", "Median across years", "Predicted"),
  #                    values = c("purple", "grey", "black")) +
  scale_color_viridis_d(labels = c("Observed", "Median across years", "Predicted"),
                        end = 0.8,
                        name = NULL) +
  scale_size_manual(labels = c("Observed", "Median across years", "Predicted"),
                     values = c(1.2, 0.5, 1),
                        name = NULL) +
  scale_linetype_manual(labels = c("Observed", "Median across years", "Predicted"),
                     values = c("solid", "solid", "solid"),
                        name = NULL) +
  ggtitle("GPP Model from Rainfall", subtitle = "Showing farm PAEC") +
  theme(legend.position="bottom")
```


```{r m1b_residualsummariesforfarms}
library(ggrepel)
sws_sites <- sws_sites_2_sf(readRDS("../private/data/clean/sws_sites.rds")) %>%
  mutate(latitude =  sf::st_coordinates(geometry)[, "Y"],
         longitude = sf::st_coordinates(geometry)[, "X"]) 

medresid <- pred %>%
  mutate(resid = gpp - pred_m1b) %>%
  as_tibble() %>%
  group_by(site) %>%
  summarise(medresid = median(resid, na.rm = TRUE))

medresid %>%
  left_join(sws_sites, by = c(site = "SiteCode")) %>%
  ggplot() +
  geom_point(aes(x = longitude, y = latitude, col = medresid, size = medresid)) +
  scale_color_viridis_c() +
  geom_text_repel(aes(x = longitude, y = latitude, label = site)) +
  guides(
    color = guide_colourbar("Median\nResidual Color"),
    size = guide_legend("Median\nResidual Size")
  ) +
  coord_fixed() +
  theme(legend.position="bottom") +
  ggtitle("Median residual for each site")
```

#### Residual Descriptions
```{r m1bresid1}
m1b <- readRDS("../private/models/m1b.rds")

m1bresids <- train %>% filtertrain1() %>%
  tibble::rowid_to_column() %>%
  mutate(rowid = as.character(rowid)) %>%
  right_join(tibble::enframe(residuals(m1b), name = "rowid", value = ".resid"),
             by = "rowid") %>%
  right_join(tibble::enframe(predict(m1b), name = "rowid", value = ".pred"),
             by = "rowid")

tsummaries <- m1bresids %>%
  as_tibble() %>%
  group_by(farm) %>%
  summarise(mean = mean(.resid, na.rm = TRUE),
            med = median(.resid),
            iqr = IQR(.resid),
            q10 = quantile(.resid, probs = 0.10), #GPP extremely over-predicted
            q90 = quantile(.resid, probs = 0.9) #high GPP (peaks) not predicted
            )
saveRDS(tsummaries, file = "../private/models/m1b_resids_summaries.rds")

m1bresids %>%
  select(times, site, pg, gpp, .pred, .resid, farm) %>%
  filter_index("2001" ~ "2010") %>%
  left_join(tsummaries, by = "farm") %>%
  filter(farm == "BELL") %>%
  pivot_longer(cols = c(.resid, .pred)) %>%
  ggplot() +
  facet_wrap(c(vars(farm))) + 
  geom_line(aes(x = times, y = value, col = q10, lty = name)) +
  scale_color_viridis_c()
```

```{r m1bresid_spatial}
tsummaries

```


```{r m1bresid_garchmod}
acfs <- acf(m1bresids$.resid)
pacfs <- pacf(m1bresids$.resid)

resid_garch_spec <- ugarchspec(variance.model = list(
  model = "sGARCH", garchOrder = c(3, 3)),
  mean.model = list(armaOrder = c(3, 4)))

farmset <- m1bresids %>% 
  filter(farm == "BELL") %>% 
  as_tibble() %>%
  select(".resid") %>%
  unlist()
resid_garch <- ugarchfit(resid_garch_spec,
                         farmset,
                      solver = "hybrid",
                      fit.control = list(stationarity = TRUE, scale = 1))

resid_garch
plot(resid_garch)
```


## Search for better predictors using *lm* modelling scheme


## Resolve issue that autocorrelation remains in residuals, perhaps by using 1 in 4 data points (rather than the 1 in 3 currentl)
```{r m6_remout_autocorr}
g1 <- feasts::ACF(residuals(m6_remout, "innovation"), .resid) %>%  #innovation type is forecast using all prior information, regression is the mean
  autoplot()

g2 <- feasts::PACF(residuals(m6_remout, "innovation"), .resid) %>%  #innovation type is forecast using all prior information, regression is the mean
  autoplot()
g1 / g2
```

PACF and ACF being nearly identical and both non-zero. 

### m8: Search using fable::ARIMA with larger orders possible and given seasonality
```{r m8_increasepq}
m8_sp <- ARIMA(box_cox(gpp / gpp.ydaymed, lambda = bestlambda) ~ 
              pg_1to5m * I(1 / pg_1to5m.ydaymed) * pg_24d +
              pdq() +
              PDQ(period = 16),
              greedy = FALSE,
              stepwise = FALSE,
              ic = "aicc",
              order_constraint = p + q + P + Q <= 20)
m8 <- train %>% filtertrain2() %>%
  tibble::rowid_to_column() %>% #reindex by approximate 8 day intervals (discrepancies at the end of every year)
  as_tsibble(key = NULL, index = "rowid") %>%
  ungroup() %>%
  model(m8_sp)
m8[[1, 1]]

out <- feasts::ACF(residuals(m8, "innovation"), .resid)
out %>%  #innovation type is forecast using all prior information, regression is the mean
  autoplot()

out <- feasts::PACF(residuals(m8, "innovation"), .resid)
out %>%  #innovation type is forecast using all prior information, regression is the mean
  autoplot()
```

### m8b: Like m8, but without thinning the data time points.
The following fits a model without thinning the data
```{r m8b_fitsave}
filtertrain3 <- function(x){
  x <- x %>% filter(sitenum == 1,
                    !is.na(pg_1to14m),
                    !is.na(gpp))
  return(x)
}

m8b_sp <- ARIMA(box_cox(gpp / gpp.ydaymed, lambda = bestlambda) ~ 
              pg_1to5m * I(1 / pg_1to5m.ydaymed) * pg_24d +
              pdq() +
              PDQ(period = 46),
              greedy = FALSE,
              stepwise = FALSE,
              ic = "aicc",
              order_constraint = p + q + P + Q <= 20)
m8b <- train %>% filtertrain3() %>%
  tibble::rowid_to_column() %>% #reindex by approximate 8 day intervals (discrepancies at the end of every year)
  as_tsibble(key = NULL, index = "rowid") %>%
  ungroup() %>%
  model(m8b_sp)

saveRDS(m8b, file = "../private/models/m8b_20200206.rds")
m8b %>%
  forecast(new_data = pggpp %>% filtertrain3() %>%
             tibble::rowid_to_column() %>%
             update_tsibble(key = NULL, index = "rowid") 
           ) %>%
  filter(!is.na(times)) %>%
  update_tsibble(key = "site", index = "times") %>%
  rename(`pred.(gpp/gpp.ydaymed)` = `gpp/gpp.ydaymed`) %>%
  rename(`pred.distribution` = `.distribution`) 


m8b[[1, 1]]

out <- feasts::ACF(residuals(m8b, "innovation"), .resid)
out %>%  #innovation type is forecast using all prior information, regression is the mean
  autoplot()

out <- feasts::PACF(residuals(m8b, "innovation"), .resid)
out %>%  #innovation type is forecast using all prior information, regression is the mean
  autoplot()

```

No new model appears to be able to reduce the autocorrelations, but they are still statistically significant. Furthermore the model is now computationally harder to fit!


```{r m8forecastview}
m8 %>%
  forecast(new_data = train %>% filtertrain2() %>%
             tibble::rowid_to_column() %>%
             left_join(resids %>% select(rowid, .resid.m6, outlier.m6, outlier.m7), by = "rowid") %>%
             update_tsibble(key = NULL, index = "rowid") 
           ) %>%
  filter(!is.na(times)) %>%
  update_tsibble(key = "site", index = "times") %>%
  # filter(farm %in% c("WILS", "GEDD", "MATH", "SMAR")) %>% 
  filter(farm %in% (farmswoutliers %>% filter(any.outliers == TRUE))$farm) %>%
  mutate(interval = hilo(.distribution, 95)) %>%
  ggplot() +
  facet_wrap(~farm, scales = "free_y") +
  geom_ribbon(aes(x = times, ymin = interval$.lower * gpp.ydaymed, ymax = interval$.upper * gpp.ydaymed), fill = "lightgrey") +
  geom_line(aes(x = times, y = `gpp/gpp.ydaymed` * gpp.ydaymed), col = "black") + 
  geom_line(aes(x = times, y = gpp), col = "blue") +
  geom_point(aes(x = times, y = gpp), 
             col = "red", shape = 1, size = 2,
             data = function(x) x %>% filter(outlier.m6 == "m6")) +
  geom_rug(aes(x = times, y = gpp), 
             col = "red", sides = "b",
             data = function(x) x %>% filter(outlier.m6 == "m6")) +
  geom_point(aes(x = times, y = gpp), 
             col = "green", shape = 2, size = 2,
             data = function(x) x %>% filter(outlier.m7 == "m7")) +
  geom_rug(aes(x = times, y = gpp), 
             col = "green", sides = "b",
             data = function(x) x %>% filter(outlier.m7 == "m7")) +
  scale_y_continuous(name = "GPP") +
  ggtitle("gpp and m6 forecast with different outliers")

```

### Investigate the error from the mean for m6
Expecting that an ARIMA of (4, 0, 2) will be most appropriate.

```{r m6addresid}
trainwlinresid <- m6 %>%
  forecast(new_data = train %>% filtertrain2() %>%
             tibble::rowid_to_column() %>%
             left_join(resids %>% select(rowid, .resid.m6, outlier.m6, outlier.m7), by = "rowid") %>%
             update_tsibble(key = NULL, index = "rowid") %>%
             fill_gaps()
           ) %>%
  #filter(!is.na(times)) %>%
  update_tsibble(key = NULL, index = "rowid") %>%
  mutate(lin.resid = box_cox(gpp / gpp.ydaymed, lambda = 0.2626) - box_cox(`gpp/gpp.ydaymed`, lambda = 0.2626))

trainwlinresid %>%
  ggplot() +
  facet_wrap(~farm) +
  geom_hline(yintercept = 0) +
  geom_point(aes(x = times, y = lin.resid))

# g1 <- feasts::ACF(.data = trainwlinresid, "lin.resid") %>%  #innovation type is forecast using all prior information, regression is the mean
#   autoplot()

# g2 <- feasts::PACF(trainwlinresid, lin.resid) %>%  #innovation type is forecast using all prior information, regression is the mean
#   autoplot()
# g1 / g2
```

The above calls to ACF were erroring with "can't slice a scaler", so have temporarily given up on making the method work.

### m9: Try model search using forecast::auto.arima
The following code failed.
```{r m9, eval=FALSE}
m9_mat <- model.matrix( ~ 
              pg_1to5m * I(1 / pg_1to5m.ydaymed) * pg_24d,
             data = train %>% filtertrain1())
m9 <- forecast::auto.arima(
  y = (train %>% filtertrain1())$gpp / (train %>% filtertrain1())$gpp.ydaymed,
  lambda = bestlambda,
  xreg = m9_mat,
  ic = "aicc",
  seasonal = c(period = 16),
  stepwise = FALSE, #better search if not stepwise! Takes a lot longer though
  parallel = TRUE,
  max.order = 20
)
acfs <- acf(residuals(m9), plot = FALSE)
cbind(lag = acfs$lag, autocorrelation = acfs$acf[, , 1]) %>%
  as_tibble() %>%
  filter(lag > 0) %>%
  ggplot() +
  geom_hline(yintercept = 0) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = autocorrelation)) +
  geom_hline(yintercept = c(-1, 1) * 2 / sqrt(acfs$n.used),
             col = "blue",
             lty = "dashed") +
  scale_color_viridis() +
  ggtitle("Autocorrelation for m9 residual")
m9
```

The autocorrelations of this model's innovations are much better than `m6`. The annual correlation (lag = 16) is quite obvious. 

The autocorrelations found for m8 is lower in general, including across years.

Both m8 and m9 autocorrelation are statistically significantly different from zero.

```{r m9view}
residuals(m9) %>%
  tibble::enframe(name = "rowid", value = ".resid") %>%
  ggplot() +
  geom_point(aes(x = rowid, y = .resid))

residuals(m9) %>%
  tibble::enframe(name = "rowid", value = ".resid") %>%
  ggplot() +
  geom_qq(aes(sample = .resid)) +
  stat_qq_line(aes(sample = .resid))

m9 %>%
  fitted(h = 1) %>%
  tibble::enframe(name = "rowid", value = "pred") %>%
  left_join(train %>% filtertrain1() %>% tibble::rowid_to_column(), by = "rowid") %>%
  as_tsibble(key = "site", index = "times") %>%
  ggplot() +
  facet_wrap(~farm, scales = "free_y") +
  geom_line(aes(x = times, y = pred * gpp.ydaymed), col = "black") + 
  geom_line(aes(x = times, y = gpp), col = "blue") +
  scale_y_continuous(name = "GPP") +
  ggtitle("m9 forecast 1-ahead predictions")
```


## With ARIMA parameters of (5, 0, 5), search for more covariates
Neither of the `arima()` and `ARIMA()` calls below were successful.
I think the models must be at the edge of invertiblity/mathematical sensibility. 
This is worrying.


```{r m9_fixed}
m9_mat <- model.matrix( ~ 
              pg_1to5m * I(1 / pg_1to5m.ydaymed) * pg_24d,
             data = train %>% filtertrain1())
relgpp <- ts((train %>% filtertrain1())$gpp / (train %>% filtertrain1())$gpp.ydaymed)
m9_fixed <- arima(x = relgpp,
      order = c(5, 0, 5),
      init = rep(0.1, 19),
      method = "ML",
      SSinit = "Rossignol2011",
      xreg = m9_mat)
  
m9_sp_fixed <- ARIMA(box_cox(gpp / gpp.ydaymed, lambda = bestlambda) ~ 
              pg_1to5m * I(1 / pg_1to5m.ydaymed) * pg_24d +
              pdq(5, 0, 5, p_init = 5, q_init = 5) +
              PDQ(0, 0, 0, P_init = 0, Q_init = 0),
              trace = TRUE,
              greedy = FALSE,
              stepwise = FALSE,
              ic = "aicc",
              order_constraint = p + q + P + Q <= 20)
m9_fixed <- train %>% filtertrain1() %>%
  tibble::rowid_to_column() %>% #reindex by approximate 8 day intervals (discrepancies at the end of every year)
  as_tsibble(key = NULL, index = "rowid") %>%
  ungroup() %>%
  model(m9_sp_fixed)
```
## Further Ideas
Time series of residuals appears similar to an ARCH or GARCH model. ARCH and GARCH models have fat tails even when the innovations are white noise [p 287, Cryer and Chan].
---
title: "Assessment of 7_2_4 Ground Observation Models without Detection Covariates"
author: "Kassel Hingee"
date: "16/06/2020"
output: 
  html_document: 
    collapsed: no
    number_sections: yes
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tibble)
library(dplyr)
library(MCMCpack)
library(mclust)
library(corrplot)
library(coda)
library(runjags)
library(ggplot2)
library(patchwork)
```

```{r varname2type}
devtools::load_all() #load the sustfarmld package
varname2type <- function(varnames){
  types <- case_when(
    grepl("lv.coef", varnames) ~ "LV Load",
    grepl("LV", varnames) ~ "LV",
    grepl("^(mu|tau)", varnames) ~ "Comm Param", #parameters of community distributions
    grepl("^u.b", varnames) ~ "Occu Coef",
    grepl("^v.b", varnames) ~ "Detn Coef",
    TRUE ~ "other"
    )
  return(types)
}
```

## Data Import

```{r importdata, echo = FALSE, include = FALSE}
inputdata <- readRDS("./private/data/clean/7_2_4_input_data.rds")
detcovar <- model.matrix(~ ModelSiteID + MeanWind +  MeanTime + MeanClouds + MeanTemp + ObserverId - 1,
             data = inputdata$insampledata$yXobs) %>%
  as_tibble() %>% rename(ModelSite = ModelSiteID)
occcovar <- model.matrix(~ ModelSiteID + os + ms * NMdetected + gc - 1,
             data = inputdata$insampledata$Xocc) %>%
  as_tibble() %>% rename(ModelSite = ModelSiteID)
```
```{r importmodelfits}
filenames <- list(
  os = "./tmpdata/grnd_os_nolv.rds",
  ms = "./tmpdata/grnd_os_ms_nolv.rds",
  os_gc = "./tmpdata/grnd_os_gc_nolv.rds",
  nm = "./tmpdata/grnd_nm_nolv.rds",
  msnm = "./tmpdata/grnd_msnm_nolv.rds",
  pars = "./tmpdata/grnd_pars_nolv.rds"
)

# test loading models
a <- vapply(filenames, file.exists, FUN.VALUE = FALSE)
stopifnot(all(a))

# load and remove crosscorrelation
fittedmods <- lapply(filenames, function(x) {
  fit <- readRDS(x)
  return(fit)})

lapply(fittedmods, function(x) {
  if (!is.null(x$timetaken)) {return(runjags::timestring(as.numeric(x$timetaken, units="secs")))}
  else return(NULL)})
```

All models took nearly identical amount of time, regardless of the number of covariates.

## MCMC Assessment
### Autocorrelation 
```{r autocorr_fromsummary}
mergedsummaries <- bind_rows(lapply(fittedmods, function(x) as_tibble(x$summaries, rownames = "varname")),
                             .id = "Model") %>%
  mutate(AC_10 = case_when(
    is.finite(AC.400) ~ AC.400,
    TRUE ~ as.numeric(NA)))
mergedsummaries %>%
  mutate(type = varname2type(varname)) %>%
  ggplot() +
  facet_grid(rows = vars(type), cols = vars(Model), scales = "free_y") +
  geom_histogram(aes(x = AC_10), bins = 30) +
  geom_vline(aes(xintercept = 0.1), col = "red") +
  scale_y_continuous(name = "Number of Parameters")
```

There is very little autocorrelation in any of the parameters.

### Convegence (Geweke)
See http://www.ugrad.stat.ubc.ca/R/library/coda/html/geweke.diag.html for a very quick description of this.
The Geweke values are Z-scores.
95% of (independent) Geweke values should be within 2 standard deviations (i.e. just 2 for Z-scores) of the mean.
The below assumes the Geweke value for parameter is also *independent*, even in the situation of converged MCMC.

```{r gewekesumm}
gwk <- bind_rows(lapply(fittedmods, 
       function(x) enframe(geweke.diag(x, frac1=0.1, frac2=0.5)$z, name = "varname")),
       .id = "Model")
gwk %>%
  mutate(type = varname2type(varname)) %>%
  ggplot() +
  facet_grid(rows = vars(type), cols = vars(Model)) +
  geom_abline(slope = 1, intercept = 0, lty = "dashed") +
  geom_qq(aes(sample = value), shape = "+", size = 2) +
  coord_cartesian(ylim = c(-5, 5))
```

Geweke values look a bit dodgy for detection coefficients for: ms, msnm, os_gc.
Conversely the detection coefficients appear to have converged for nm, os and pars.
Occupancy coefficient Geweke values look ok for msnm, nm, os, os_gc and pars.


```{r swstatistics, rows.print = 14}
gwk %>%
  mutate(type = varname2type(varname)) %>%
  group_by(Model, type) %>%
  summarise(swp = shapiro.test(value)$p.value) %>%
  ggplot() +
  facet_wrap(~type) +
  geom_vline(aes(xintercept = 0.01)) +
  geom_point(aes(y = Model, x = swp, col = Model)) + 
  scale_x_continuous(name = "Shapiro-Wilk p-value",
                     trans = "identity")
```

Despite above visual assessment, the Shapiro-Wilk tests suggest the Geweke values are fine (if this analysis method can work).

### Multi Chain Gelman-Rubin Statistic (aka "Rhat" or psrf)
Values less than 1.1 are desired.

```{r gelmanrubin}
psrfs <- lapply(fittedmods, function(x) as_tibble(x$summaries[, "psrf"], rownames = "varname"))
psrfs_df <- bind_rows(psrfs, .id = "Model")

psrfs_df %>%
  mutate(type = varname2type(varname)) %>%
  ggplot() +
  facet_grid(rows = vars(type), cols = vars(Model), scales = "free_y") +
  geom_point(aes(y = varname, x = value) ) +
  geom_vline(xintercept = 1.1, col = "blue", lty = "dashed") +
  scale_y_discrete(name = "Variable Name") +
  scale_x_continuous(name = "Gelman-Rubin Statistic")
```

All coefficient converged according to the Gelman-Rubin statistic that is designed for multiple chains.

### Conclusions
All models have converged well and have little autocorrelation in their samples.

## Compare Covariate Loadings
```{r covariateloadings}
u.b_median <- function(fit) {
  fit$data <- as_list_format(fit$data)
  theta <- get_theta(fit, type = "median")
  u.b <- bugsvar2matrix(theta, "u.b", 1:fit$data$n, 1:fit$data$Vocc)
  colnames(u.b) <- names(fit$XoccProcess$center)
  rownames(u.b) <- fit$species
  u.b <- as_tibble(u.b, rownames = "Species")
  return(u.b)
}
u.b_l <- lapply(fittedmods, u.b_median)
u.b_longer <- lapply(u.b_l,
                     function(x) pivot_longer(x, -Species, names_to = "Covariate", values_to = "CovariateValue"))
df <- bind_rows(u.b_longer, .id = "Model")

df %>%
  ggplot() +
  facet_wrap(vars(Covariate), nrow = 1) +
  geom_point(aes(y = Species, x = CovariateValue,
                 col = Model,
                 shape = Model)) +
  scale_color_viridis_d() +
  scale_shape_manual(values = rep(0:5, 3))
```

All models give virtually the same covariate loading medians (when the covariate is included).
The loadings are not zero, for example midstorey and NMdetected,
this suggests that the covariate effects are independent of each other (it doesn't matter which other covariates are included in the model).


## Model Comparisons
### Log Posterior Density
```{r holdoutlpd}
lpds_l <- readRDS("./tmpdata/7_2_4_lpds.rds")
lpds_df <- as_tibble(do.call(cbind, lapply(lpds_l, function(x) x$lpds)))
melpd <- data.frame(Estimate = apply(lpds_df, 2, mean),
                    SE = apply(lpds_df, 2, sd) / sqrt(nrow(lpds_df)))

lpds_df %>%
  as_tibble() %>%
  rowid_to_column(var = "HoldOutModelSite") %>%
  tidyr::pivot_longer(-HoldOutModelSite, names_to = "model", values_to = "Site_lpd") %>%
  ggplot() +
  facet_grid(rows = vars(model), scales = "free_y") +
  geom_violin(aes(x = Site_lpd, y = model)) +
  stat_summary(aes(x = Site_lpd, y = model),
               fun = mean, geom = "point", shape = 23, size = 2) +
  stat_summary(aes(x = Site_lpd, y = model),
               fun = function(x) mean(x) - 2*sd(x)/sqrt(nrow(lpds_df)), geom = "crossbar") +
  stat_summary(aes(x = Site_lpd, y = model),
               fun = function(x) mean(x) + 2*sd(x)/sqrt(nrow(lpds_df)), geom = "crossbar")
```

For the holdout data the average site lpd is very similar for each model, within 2 standard deviations of each other. 
However, the distributions appear to be a bit different.

Below is the lpd computed for each ModelSite for both the InSample and out of sample data.

```{r distributioninsampleoutsamplelpd}
waics_l <- readRDS("./tmpdata/7_2_4_waics.rds")
insamplelpds_df <- do.call(cbind, lapply(waics_l, function(x) x$waic$pointwise[, "elpd_waic"])) %>%
  as_tibble() %>% mutate(InSample = TRUE)

df <- lpds_df %>% as_tibble() %>% mutate(InSample = FALSE)

df <- bind_rows(insamplelpds_df, df)

df %>%
  as_tibble() %>%
  tidyr::pivot_longer(-InSample, names_to = "model", values_to = "site_lpd") %>%
  ggplot() +
  facet_grid(rows = vars(model, InSample), scales = "free_y") +
  geom_violin(aes(x = site_lpd, y = model, col = InSample)) +
  stat_summary(aes(x = site_lpd, y = model),
               fun = mean, geom = "point", shape = 23, size = 2) +
  stat_summary(aes(x = site_lpd, y = model),
               fun = function(x) mean(x) - 2*sd(x)/sqrt(nrow(lpds_df)), geom = "crossbar") +
  stat_summary(aes(x = site_lpd, y = model),
               fun = function(x) mean(x) + 2*sd(x)/sqrt(nrow(lpds_df)), geom = "crossbar")
```

The differences between lpds values are larger for the InSample data. nm and msnm both have a slight two-peak distribution, no other models created that.

vs WAIC:
```{r waics}
waics_l <- readRDS("./tmpdata/7_2_4_waics.rds")
waics_average_elpd_per_point <- lapply(waics_l, function(x) x$waic$estimates["elpd_waic", ]/nrow(x$waic$pointwise))
waics_average_elpd_per_point <- simplify2array(waics_average_elpd_per_point)
waics_average_elpd_per_point <- t(waics_average_elpd_per_point) %>% as_tibble(rownames = "Model")
waics_average_elpd_per_point$type = "WAIC"

loo_average_elpd_per_point <- lapply(waics_l, function(x) x$loo$estimates["elpd_loo", ]/nrow(x$waic$pointwise))
loo_average_elpd_per_point <- simplify2array(loo_average_elpd_per_point)
loo_average_elpd_per_point <- t(loo_average_elpd_per_point) %>% as_tibble(rownames = "Model")
loo_average_elpd_per_point$type = "LOO-PSIS"

melpd$type <- "Holdout"
melpd <- as_tibble(melpd, rownames = "Model")

df <- bind_rows(waics_average_elpd_per_point, loo_average_elpd_per_point, melpd)

df %>%
  ggplot() +
  geom_errorbar(aes(x = Model, ymax = Estimate +  2*SE, ymin = Estimate - 2*SE, col = type, lty = type)) +
  geom_point(aes(x = Model, y = Estimate, col = type), position = position_jitter(width = 0.1)) +
  coord_flip()
```

The LOO and WAIC estimates are identical. The Holdout estimates appear to be consitent with the WAIC/LOO-PSIS estimates.
The benefit of WAIC is that error bars are narrower.
A downside is that some ModelSites may not suitable for using in WAIC and LOO-PSIS (the code produces warnings). In particular the standard errors calculated could be wrong.

For WAIC/LOO-PSIS, all models but os_gc are statistically compatible estimates of elpd for a site.
For Holdout data, all models are statistically compatible estimates of elpd for a site.

### Quick check of residuals for all models
Note that there are too many data points to apply the shapiro-Wilks normality test directly. A sample of 5000 might be ok though. **would be good to have something better**

```{r all_resid_occ_normality}
resid_occ_l <- lapply(fittedmods, ds_occupancy_residuals.fit, type = "median", seed = 321, conditionalLV = FALSE)
vapply(resid_occ_l, function(x) shapiro.test(sample(unlist(x[, -1]), 5000))$p.value, FUN.VALUE = 3.3)
vapply(resid_occ_l, function(x) goftest::ad.test(unlist(x[, -1]))$p.value, FUN.VALUE = 3.3)
as_tibble(lapply(resid_occ_l, function(x) unlist(x[, -1]))) %>%
  pivot_longer(everything(), names_to = "Model", values_to = "Residual") %>%
  ggplot() +
  geom_qq(aes(sample = Residual)) +
  geom_abline(slope = 1, intercept = 0, lty = "dashed") +
  facet_grid(cols = vars(Model))
```

All occupancy residuals appear roughly normal too, when sampled. But when using all residuals and the Anderson Darling pvalue they clearly aren't normal.


```{r all_resid_det_normality}
resid_det_l <- lapply(fittedmods, ds_detection_residuals.fit, type = "median", seed = 321)
vapply(resid_det_l, function(x) shapiro.test(sample(unlist(x[, -1]), 5000))$p.value, FUN.VALUE = 3.3)
vapply(resid_det_l, function(x) {
  vals <- unlist(x[, -1])
  vals <- vals[!is.na(vals)]
  goftest::ad.test(vals)$p.value},
  FUN.VALUE = 3.3)
as_tibble(lapply(resid_det_l, function(x) unlist(x[, -1]))) %>%
  pivot_longer(everything(), names_to = "Model", values_to = "Residual") %>%
  ggplot() +
  geom_qq(aes(sample = Residual)) +
  geom_abline(slope = 1, intercept = 0, lty = "dashed") +
  facet_grid(cols = vars(Model))
```

All detection residuals are close to a normal distribution.
But when using all residuals and the Anderson Darling pvalue they clearly aren't normal.


### Residuals against occupancy covariates:
```{r residocc_plots_manymodels}
seeds = c(321, 120, 6545, 65498, 63)
df_l <- lapply(seeds, function(x) {
  resid_occ_l <- lapply(fittedmods, ds_occupancy_residuals.fit, type = "median", seed = x, conditionalLV = FALSE)
  resid_occ_df <- bind_rows(resid_occ_l, .id = "Model")
  df <- resid_occ_df %>%
    pivot_longer(-c(ModelSite, Model),
                   names_to = "Species",
                   values_to = "Residual",
                   values_drop_na = TRUE) %>%
    left_join(occcovar %>% 
                pivot_longer(-ModelSite,
                   names_to = "Covariate",
                   values_to = "CovariateValue"),
              by = "ModelSite")
  return(df)
})
names(df_l) <- seeds
df <- bind_rows(df_l, .id = "seed")

plt <- df %>%
  ggplot() +
  ggplot2::geom_point(aes(x = CovariateValue, y = Residual), data = function(x) x[x$seed == seeds[[1]], ])
  
plt <- plt + ggplot2::geom_smooth(aes(x = CovariateValue, y = Residual, col = seed), method = "gam", level = 0.95, formula = y ~ s(x, bs = "cs"))

plt <- plt +
  ggplot2::facet_grid(rows = vars(Model), cols = vars(Covariate), as.table = TRUE, scales = "free_x") +
  ggplot2::geom_hline(yintercept = 0, col = "blue", lty = "dashed") +
  ggplot2::scale_x_continuous(name = "Covariate Value") +
  scale_y_continuous(name = "Occupancy Residual")
plt + coord_cartesian(ylim = c(-0.1, 0.1))
```

Model residuals appear quite informative!! 

+ The parsimonious model (and msnm should too) has correctly incorporated midstory, for many different jitter seeds for the residuals.
+ Many of the models have negative residuals at high overstory.
+ The interaction between midstorey and Noisy Miners appears to not be incompletely modeled by all methods. 
This suggests a ms^2 * nm term, perhaps even an ms^3 * nm term.
+ Ground cover could do with a non-linear term, such as gc^2 

Models with midstory incorporated are the only models with zero mean midstorey residual.
However, the smooths are quite sensitive to the jitter in Dunn-Smyth residuals. See below for a plot with additional residuals.
The zero mean related to midstorey is sensitive to jitter, and may not be real.

### Residuals against detection covariates:
```{r residdet_plots_manymodels}
seeds = c(321, 120, 6545, 65498, 63)
df_l <- lapply(seeds, function(x) {
  resid_det_l <- lapply(fittedmods, ds_detection_residuals.fit, type = "median", seed = x)
  resid_det_df <- bind_rows(resid_occ_l, .id = "Model")
  df <- resid_det_df %>%
    pivot_longer(-c(ModelSite, Model),
                   names_to = "Species",
                   values_to = "Residual",
                   values_drop_na = TRUE) %>%
    left_join(detcovar %>% 
                pivot_longer(-ModelSite,
                   names_to = "Covariate",
                   values_to = "CovariateValue"),
              by = "ModelSite")
  return(df)
})
names(df_l) <- seeds
df_det <- bind_rows(df_l, .id = "seed")

plt <- df_det %>%
  ggplot() +
  ggplot2::geom_point(aes(x = CovariateValue, y = Residual), data = function(x) x[x$seed == seeds[[1]], ])
  
plt <- plt + ggplot2::geom_smooth(aes(x = CovariateValue, y = Residual, col = seed), method = "gam", level = 0.95, formula = y ~ s(x, bs = "cs"))

plt <- plt +
  ggplot2::facet_grid(rows = vars(Model), cols = vars(Covariate), as.table = TRUE, scales = "free_x") +
  ggplot2::geom_hline(yintercept = 0, col = "blue", lty = "dashed") +
  ggplot2::scale_x_continuous(name = "Covariate Value") +
  scale_y_continuous(name = "Detection Residual")
plt + coord_cartesian(ylim = c(-0.1, 0.1))
```

Strongly suggests MeanTime as a detection covariate. MeanTemp could also be valuable.

## Conclusions
MCMC chains were well behaved.
Similarly detection and occupancy residuals were close to Normally distributed.

All models gave similar median covariate loadings, suggesting that the loadings are independent of other covariates present.

Models had similar estimates of elpd for a new ModelSite. Regardless of the estimation method (WAIC, LOO-PSIS, Holdout).

The best models, according to the residuals were the parsimonious and ms*nm models.
+ Many of the models have negative residuals at high overstory.
+ The interaction between midstorey and Noisy Miners appears to not be incompletely modeled by all methods. 
This suggests a ms^2 * nm term, perhaps even an ms^3 * nm term.
+ Ground cover could do with a non-linear term, such as gc^2 

### Further Covariates
Detection residuals strongly suggest MeanTime.

Occupancy residuals suggest:
+ 2nd order overstorey (or something that decreases with higher OS)
+ 2nd order ground cover
+ 2nd order midstorey interacting with noisy miner

### Next Steps
I am very curious to see if the performance of `pars` and `msnm` occupancy models improve with detection models.
I am also curious to see if the addition of 2nd-order occupancy covariates will improve the lpd of the models.

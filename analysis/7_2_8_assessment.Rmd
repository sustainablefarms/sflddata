---
title: "Assessment 7_2_8 Remote Sensing Models"
author: "Kassel Hingee"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document: 
    collapsed: no
    number_sections: yes
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_root(rprojroot::has_file("DESCRIPTION")))
devtools::load_all(rprojroot::find_root(rprojroot::has_file("DESCRIPTION")))
knitr::opts_chunk$set(echo = FALSE)
library(tibble)
library(dplyr)
library(MCMCpack)
library(mclust)
library(corrplot)
library(coda)
library(runjags)
library(ggplot2)
library(patchwork)
```

```{r varname2type}
varname2type <- function(varnames){
  types <- case_when(
    grepl("lv.coef", varnames) ~ "LV Load",
    grepl("LV", varnames) ~ "LV",
    grepl("^(mu|tau)", varnames) ~ "Comm Param", #parameters of community distributions
    grepl("^u.b", varnames) ~ "Occu Coef",
    grepl("^v.b", varnames) ~ "Detn Coef",
    TRUE ~ "other"
    )
  return(types)
}
```

## Data Import

```{r importdata, echo = FALSE, include = FALSE}
inputdata <- readRDS("./private/data/clean/7_2_8_input_data.rds")
# the following whittle out the covariates that we are interested in the residual diagnostics
detcovar <- model.matrix(~ ModelSiteID + MeanWind +  MeanTime + MeanClouds + MeanTemp + ObserverId - 1,
             data = inputdata$insampledata$yXobs) %>%
  as_tibble() %>% rename(ModelSite = ModelSiteID)
occcovar <- model.matrix(~ ModelSiteID + os + ms * NMdetected + gc - 1,
             data = inputdata$insampledata$Xocc) %>%
  as_tibble() %>% rename(ModelSite = ModelSiteID)
```
```{r importmodelfits}
modelspecs <- readRDS("./tmpdata/7_2_8_modelspecs.rds")
filenames <- lapply(modelspecs, function(x) x$filename)

# test loading models
a <- vapply(filenames, file.exists, FUN.VALUE = FALSE)
stopifnot(all(a))

# load fitted models
fittedmods <- lapply(filenames, function(x) {
  fit <- readRDS(x)
  return(fit)})
```

```{r cleanersummaries}
cleanersummary <- function(fit) {
  vals <- fit$summaries %>%
    as_tibble(rownames = "bugsvarname") %>%
    mutate(AC_10 = case_when(
      is.finite(AC.400) ~ AC.400,
      TRUE ~ as.numeric(NA))) %>%
    mutate(var = gsub("\\[.*\\]", "", bugsvarname)) %>%
    mutate(type = varname2type(bugsvarname))
  suppressWarnings(vals <- vals %>%
    mutate(SpeciesIdx = as.integer(gsub("(.*\\[|,.*\\])", "", bugsvarname))) %>%
    mutate(CovarIdx = as.integer(gsub("(.*\\[.*,|\\])", "", bugsvarname))) )
  vals <- vals %>%
    mutate(Species = fit$species[SpeciesIdx]) %>%
    mutate(Covariate = case_when(
      var == "u.b" ~ colnames(fit$data$Xocc)[CovarIdx],
      var == "v.b" ~ colnames(fit$data$Xobs)[CovarIdx],
      var == "LV" ~ as.character(CovarIdx),
      TRUE ~ as.character(NA)
    )) %>% 
    dplyr::select(-SpeciesIdx, -CovarIdx)
  return(vals)
}
cleanersummary_l <- lapply(fittedmods, cleanersummary)
cleanersummaries <- bind_rows(cleanersummary_l, .id = "Model")
```

```{r import_lpd}
lpds_l <- readRDS("./tmpdata/7_2_8_lpds.rds")
waics_l <- readRDS("./tmpdata/7_2_8_waics.rds")
```

```{r mcmctime}
cat("MCMC time:\n")
lapply(fittedmods, function(x) {
  if (!is.null(x$timetaken)) {return(runjags::timestring(as.numeric(x$timetaken, units="secs")))}
  else return(NULL)})
```

*Comment on time taken for the MCMC of each model:*


## MCMC Assessment
### Autocorrelation 
```{r autocorr_fromsummary}
cleanersummaries %>%
  ggplot() +
  facet_grid(rows = vars(type), cols = vars(Model), scales = "free_y") +
  geom_histogram(aes(x = AC_10), bins = 30) +
  geom_vline(aes(xintercept = 0.1), col = "red") +
  scale_y_continuous(name = "Number of Parameters")
```

*Comment on autocorrelation of model parameters. A threshold of 0.1 has been arbitrarily chosen.*

### Convegence (Geweke)
See http://www.ugrad.stat.ubc.ca/R/library/coda/html/geweke.diag.html for a very quick description of this.
The Geweke values are Z-scores (technically t-distributed in this situation?).
95% of (independent) Geweke values should be within 2 standard deviations (i.e. just 2 for Z-scores) of the mean.
The below assumes the Geweke value for parameter is also *independent*, even in the situation of converged MCMC.

```{r gewekesumm}
gwk <- bind_rows(lapply(fittedmods, 
       function(x) enframe(geweke.diag(x, frac1=0.1, frac2=0.5)$z, name = "varname")),
       .id = "Model")
gwk %>%
  mutate(type = varname2type(varname)) %>%
  ggplot() +
  facet_grid(rows = vars(type), cols = vars(Model)) +
  geom_abline(slope = 1, intercept = 0, lty = "dashed") +
  geom_qq(aes(sample = value), shape = "+", size = 2) +
  coord_cartesian(ylim = c(-5, 5)) +
  ggtitle("QQ Plots of Geweke Statistics for Each Parameter")
```


```{r swstatistics, rows.print = 14}
gwk %>%
  mutate(type = varname2type(varname)) %>%
  group_by(Model, type) %>%
  summarise(swp = shapiro.test(value)$p.value) %>%
  ggplot() +
  facet_wrap(~type) +
  geom_vline(aes(xintercept = 0.01)) +
  geom_point(aes(y = Model, x = swp, col = Model)) + 
  scale_x_continuous(name = "Shapiro-Wilk p-value",
                     trans = "identity") +
  ggtitle("Geweke Convergence Statistics Normality Tests",
          subtitle = "0.01 threshold shown")
```

*Comment on convergence using visual assessment and the Shapiro-Wilk test of normalisty*

### Multi Chain Gelman-Rubin Statistic (aka "Rhat" or psrf)
Values less than 1.1 are desired.

```{r gelmanrubin}
psrfs <- lapply(fittedmods, function(x) as_tibble(x$summaries[, "psrf"], rownames = "varname"))
psrfs_df <- bind_rows(psrfs, .id = "Model")

psrfs_df %>%
  mutate(type = varname2type(varname)) %>%
  ggplot() +
  facet_grid(rows = vars(type), cols = vars(Model), scales = "free_y") +
  geom_point(aes(y = varname, x = value) ) +
  geom_vline(xintercept = 1.1, col = "blue", lty = "dashed") +
  scale_y_discrete(name = "Variable Name") +
  scale_x_continuous(name = "Gelman-Rubin Statistic")
```

*Comment on convergence using the Gelman-Rubin statistic*

### Conclusions
*Summarise behaviour of the MCMC chains*

## Compare Covariate Loadings
```{r occupancycovariateloadings}
cleanersummaries %>%
  dplyr::filter(varname == "u.b") %>%
  ggplot() +
  facet_wrap(vars(Covariate), nrow = 1) +
  geom_hline(yintercept = 0) +
  geom_pointrange(aes(x = Species,
                 ymin = Lower95,
                 ymax = Upper95,
                 y = Median,
                 col = Model,
                 group = Model),
             shape = "|",
             size = 1,
             position = position_dodge(width = 1)) +
  coord_flip() +
  scale_color_viridis_d() +
  ggtitle("Occupancy Covariate Loadings per Species and Model")
```
  

```{r detectioncovariateloadings}
cleanersummaries %>%
  dplyr::filter(varname == "v.b") %>%
  ggplot() +
  facet_wrap(vars(Covariate), nrow = 1) +
  geom_hline(yintercept = 0) +
  geom_pointrange(aes(x = Species,
                 ymin = Lower95,
                 ymax = Upper95,
                 y = Median,
                 col = Model,
                 group = Model),
             shape = "|",
             size = 1,
             position = position_dodge(width = 1)) +
  coord_flip() +
  scale_color_viridis_d() +
  ggtitle("Detection Covariate Loadings per Species and Model")
```


## Model Comparisons
### Log Posterior Density
```{r holdoutlpd}
lpds_df <- as_tibble(do.call(cbind, lapply(lpds_l, function(x) x$lpds)))
melpd <- data.frame(Estimate = apply(lpds_df, 2, mean),
                    SE = apply(lpds_df, 2, sd) / sqrt(nrow(lpds_df)))

mean_2se <- function(x, mult = 2){
  n <- length(x)
  xbar <- sum(x)/n
  sd <- sqrt(sum((x - xbar)^2)/(n - 1))
  return(c(ymin = xbar - mult * sd / sqrt(n),
           y = xbar,
           ymax = xbar + mult * sd / sqrt(n)))
}

lpds_df %>%
  as_tibble() %>%
  rowid_to_column(var = "HoldOutModelSite") %>%
  tidyr::pivot_longer(-HoldOutModelSite, names_to = "model", values_to = "Site_lpd") %>%
  ggplot() +
  facet_grid(rows = vars(model), scales = "free_y") +
  geom_violin(aes(x = Site_lpd, y = model)) +
  stat_summary(aes(x = Site_lpd, y = model),
               fun.data=mean_2se, fun.args = list(mult=2), geom="crossbar", width=0.2 ) +
  stat_summary(aes(x = Site_lpd, y = model),
               fun = median, geom = "point", shape = 23, size = 2) +
  ggtitle("Log-Posterior Density of Holdout ModelSites")
```

Below is the lpd computed for each ModelSite for both the InSample and out of sample data.

```{r distributioninsampleoutsamplelpd}
insamplelpds_df <- do.call(cbind, lapply(waics_l, function(x) x$waic$pointwise[, "elpd_waic"])) %>%
  as_tibble() %>% mutate(InSample = TRUE)

df <- lpds_df %>% as_tibble() %>% mutate(InSample = FALSE)

df <- bind_rows(insamplelpds_df, df)


df %>%
  as_tibble() %>%
  tidyr::pivot_longer(-InSample, names_to = "model", values_to = "site_lpd") %>%
  ggplot() +
  facet_grid(rows = vars(model), scales = "free_y", switch = "y") +
  geom_violin(aes(x = site_lpd, y = InSample, col = InSample), position = position_dodge(1)) +
  stat_summary(aes(x = site_lpd, y = InSample, group = InSample),
               fun.data=mean_2se, fun.args = list(mult=2), geom="crossbar", width=0.2 ) +
  theme(strip.text.y.left = element_text(angle = 0)) +
  ggtitle("Log Posterior Density of ModelSites")
```


```{r waics}
waics_average_elpd_per_point <- lapply(waics_l, function(x) x$waic$estimates["elpd_waic", ]/nrow(x$waic$pointwise))
waics_average_elpd_per_point <- simplify2array(waics_average_elpd_per_point)
waics_average_elpd_per_point <- t(waics_average_elpd_per_point) %>% as_tibble(rownames = "Model")
waics_average_elpd_per_point$type = "WAIC"

loo_average_elpd_per_point <- lapply(waics_l, function(x) x$loo$estimates["elpd_loo", ]/nrow(x$waic$pointwise))
loo_average_elpd_per_point <- simplify2array(loo_average_elpd_per_point)
loo_average_elpd_per_point <- t(loo_average_elpd_per_point) %>% as_tibble(rownames = "Model")
loo_average_elpd_per_point$type = "LOO-PSIS"

melpd$type <- "Holdout"
melpd <- as_tibble(melpd, rownames = "Model")

df <- bind_rows(waics_average_elpd_per_point, loo_average_elpd_per_point, melpd)

df %>%
  ggplot() +
  geom_errorbar(aes(x = Model, ymax = Estimate +  2*SE, ymin = Estimate - 2*SE, col = type, lty = type)) +
  geom_point(aes(x = Model, y = Estimate, col = type), position = position_jitter(width = 0.1)) +
  coord_flip() +
  ggtitle("Estimates of Log Posterior Density for a new ModelSite")
```


```{r loo_compare}
loos <- lapply(waics_l, function(x) x$loo)
loo::loo_compare(loos)
```

### Expected Number of Detections for Each Species
```{r numdetections}
obsdetections <- colSums(fittedmods[[1]]$data$y)

Edetections <- lapply(fittedmods,
                      function(x) colSums(Endetect_modelsite(x,
                                            conditionalLV = (!is.null(x$data$nlv) && (x$data$nlv > 0) ))
                                          )
                      )
Edetections <- simplify2array(Edetections)
# Edetections[names(obsdetections), "Observed"] <- obsdetections



Edetections %>% 
  as_tibble(Edetections, rownames = "Species") %>%
  tidyr::pivot_longer(cols = -Species, names_to = "Model", values_to = "E_Ndetections") %>%
  ggplot() +
  geom_col(aes(x = Detections, y = Species), data = obsdetections %>% enframe(name = "Species", value = "Detections"),
             alpha = 0.2,
             inherit.aes = FALSE) +
  geom_point(aes(x = E_Ndetections, y = Species, col = Model, shape = Model), inherit.aes = FALSE) +
  scale_color_viridis_d() +
  scale_shape_manual(values = rep(0:5, 3)) +
  theme(legend.position="bottom") +
  ggtitle("Expected Number of Detections vs Observed")
```


### Quick check of residual distribution for all models
Note that there are too many data points to apply the shapiro-Wilks normality test directly, however the Anderson-Darling test can be applied. I do not know enough about this test yet to know if it can be fully trusted.

```{r all_resid_occ_normality}
resid_occ_l <- lapply(fittedmods, ds_occupancy_residuals.fit, type = "median", seed = 321, conditionalLV = FALSE)
# vapply(resid_occ_l, function(x) shapiro.test(sample(unlist(x[, -1]), 5000))$p.value, FUN.VALUE = 3.3)
vapply(resid_occ_l, function(x) goftest::ad.test(unlist(x[, -1]))$p.value, FUN.VALUE = 3.3)
as_tibble(lapply(resid_occ_l, function(x) unlist(x[, -1]))) %>%
  pivot_longer(everything(), names_to = "Model", values_to = "Residual") %>%
  ggplot() +
  geom_qq(aes(sample = Residual)) +
  geom_abline(slope = 1, intercept = 0, lty = "dashed") +
  facet_grid(cols = vars(Model)) +
  ggtitle("Occupancy Residual Distribution: qq plots")
```


```{r all_resid_det_normality}
resid_det_l <- lapply(fittedmods, ds_detection_residuals.fit, type = "median", seed = 321)
vapply(resid_det_l, function(x) {
  vals <- unlist(x[, -1])
  vals <- vals[!is.na(vals)]
  goftest::ad.test(vals)$p.value},
  FUN.VALUE = 3.3)
as_tibble(lapply(resid_det_l, function(x) unlist(x[, -1]))) %>%
  pivot_longer(everything(), names_to = "Model", values_to = "Residual") %>%
  ggplot() +
  geom_qq(aes(sample = Residual)) +
  geom_abline(slope = 1, intercept = 0, lty = "dashed") +
  facet_grid(cols = vars(Model)) +
  ggtitle("Detection Residual Distribution: qq plots")
```



### Occupancy Residuals
```{r residocc_plots_manymodels}
seeds = c(321, 120, 6545, 65498, 63)
df_l <- lapply(seeds, function(x) {
  resid_occ_l <- lapply(fittedmods, ds_occupancy_residuals.fit, type = "median", seed = x, conditionalLV = FALSE)
  resid_occ_df <- bind_rows(resid_occ_l, .id = "Model")
  df <- resid_occ_df %>%
    pivot_longer(-c(ModelSite, Model),
                   names_to = "Species",
                   values_to = "Residual",
                   values_drop_na = TRUE) %>%
    left_join(occcovar %>% 
                pivot_longer(-ModelSite,
                   names_to = "Covariate",
                   values_to = "CovariateValue"),
              by = "ModelSite")
  return(df)
})
names(df_l) <- seeds
df <- bind_rows(df_l, .id = "seed")

plt <- df %>%
  ggplot() +
  ggplot2::geom_point(aes(x = CovariateValue, y = Residual), data = function(x) x[x$seed == seeds[[1]], ])
  
plt <- plt + ggplot2::geom_smooth(aes(x = CovariateValue, y = Residual, col = seed), method = "gam", level = 0.95, formula = y ~ s(x, bs = "cs"))

plt <- plt +
  ggplot2::facet_grid(rows = vars(Model), cols = vars(Covariate), as.table = TRUE, scales = "free_x") +
  ggplot2::geom_hline(yintercept = 0, col = "blue", lty = "dashed") +
  ggplot2::scale_x_continuous(name = "Covariate Value") +
  scale_y_continuous(name = "Occupancy Residual")
plt + coord_cartesian(ylim = c(-0.1, 0.1)) + ggtitle("Occupancy Residuals vs Covariates") +
  theme(strip.text.y.right = element_text(angle = 0))
```


### Detection Residuals
```{r residdet_plots_manymodels}
seeds = c(321, 120, 6545, 65498, 63)
df_l <- lapply(seeds, function(x) {
  resid_det_l <- lapply(fittedmods, ds_detection_residuals.fit, type = "median", seed = x)
  resid_det_df <- bind_rows(resid_det_l, .id = "Model")
  df <- resid_det_df %>%
    pivot_longer(-c(ModelSite, Model),
                   names_to = "Species",
                   values_to = "Residual",
                   values_drop_na = TRUE) %>%
    left_join(detcovar %>% 
                pivot_longer(-ModelSite,
                   names_to = "Covariate",
                   values_to = "CovariateValue"),
              by = "ModelSite")
  return(df)
})
names(df_l) <- seeds
df_det <- bind_rows(df_l, .id = "seed")

plt <- df_det %>%
  ggplot() +
  ggplot2::geom_point(aes(x = CovariateValue, y = Residual), data = function(x) x[x$seed == seeds[[1]], ])
  
plt <- plt + ggplot2::geom_smooth(aes(x = CovariateValue, y = Residual, col = seed), method = "gam", level = 0.95, formula = y ~ s(x, bs = "cs"))

plt <- plt +
  ggplot2::facet_grid(rows = vars(Model), cols = vars(Covariate), as.table = TRUE, scales = "free_x") +
  ggplot2::geom_hline(yintercept = 0, col = "blue", lty = "dashed") +
  ggplot2::scale_x_continuous(name = "Covariate Value") +
  scale_y_continuous(name = "Detection Residual")
plt + coord_cartesian(ylim = c(-0.1, 0.1)) + ggtitle("Detection Residuals vs Covariates") +
  theme(strip.text.y.right = element_text(angle = 0))
```


## Conclusions

### Next Steps

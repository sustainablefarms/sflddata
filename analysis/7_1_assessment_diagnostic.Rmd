---
title: "Diagnostic and Assesment of 7_1 model"
author: "Kassel Hingee"
date: "25/03/2020"
output: 
  html_document: 
    toc: yes
---

```{r setup, include=FALSE}
library(tibble)
library(dplyr)
library(MCMCpack)
library(mclust)
library(corrplot)
library(coda)
library(runjags)
```

```{r importdata, echo = FALSE, include = FALSE}
# setwd("..")
source("./scripts/7_1_import_site_observations.R")
```
```{r importmodelfit, out.width=14}
fit <- readRDS("./tmpdata/7_1_mcmcchain_20200420.rds")
fit <- add.summary(fit)
print(fit)
```

*Very strange that lv.coef[1,2] did have a stochastic nature!* I'll understand this once I understand the model more!

## Diagnostics of MCMC Chain Convergence
### Gelman-Rubin Statistic or "Rhat"
I think values less than 1.1 are desired.
Using this it appears that u.b[3,1] and many lv.coef components did not converge.
Some lv.coef components have __very__ high Rhat.

```{r gelmanrubin}
sm <- as_tibble(summary(fit), rownames = "varname")
sm %>%
  dplyr::filter(psrf >= 1.1) %>%
  dplyr::select(varname) %>%
  as.list()
```


### Traces
```{r newchaingdiagnostics1}
plot(fit, plot.type = "trace", vars = grep("lv.coef\\[.*,1\\]", sm$varname, value = TRUE),
     layout = c(2, 5))
plot(fit, plot.type = "trace", vars = grep("lv.coef\\[([2-9]|[1-9].).*,2\\]", sm$varname, value = TRUE),
     layout = c(2, 5))
plot(fit, plot.type = "trace", vars = sm$varname[[1]], separate.chains = TRUE, layout = c(5, 1))
plot(fit, plot.type = "trace", vars = grep("u.b\\[.*,1\\]", sm$varname, value = TRUE),
     layout = c(3, 5))
```

#### Observations
+ lv.coef values show dependence between samples --> larger thinning valuable. 
+ u.b samples appear ok except u.b[3,1] which looks like it didn't converge until iteration 40000.
  + Note that u.b[3,1] corresponds to the interpect for the Australian Raven. Perhaps there is not enough data for it, or it is too likely to be present?
+ Chains 1, 3, 5 appear to be identical suggesting the initial conditions of these were identical.
  + Similary for chains 2 and 4.
  + However there should be 4 different sets of initial conditions.

### Further Analysis with help from ggmcmc
* Densities from each chain
* Rhat
* Geweke
* Autocorrelation
* Cross-Correlation __unfinished__

```{r ggmcmc_prep}
library(ggmcmc)
fit.ggs <- ggs(coda::as.mcmc.list(fit), sort = TRUE)  #z is too large to include here (causes R to crash)
```

#### Densities
```{r densities, fig.width = 12, fig.height = 10}
ggs_density(fit.ggs, family = "lv.coef") + facet_wrap(~ Parameter)
ggs_density(fit.ggs, family = "^mu.u.b") + facet_wrap(~ Parameter, scales = "free")
ggs_density(fit.ggs, family = "^mu.v.b") + facet_wrap(~ Parameter, scales = "free")
ggs_density(fit.ggs, family = "^u.b") + facet_wrap(~ Parameter, scales = "free")
ggs_density(fit.ggs, family = "^v.b") + facet_wrap(~ Parameter, scales = "free")
```

There is something funky happening with the chains.
There should be 4 different chains, but so many of them are duplicated that there only appears to be 2 different chains. How is this possible?

#### Geweke
I am not sure how to use this. I think 95% of dots should be within -2 and 2?
I suspect the main information of the plot will be similar to the information from Rhat and the trace plots.

```{r geweke}
ggs_geweke(fit.ggs, family = "^[v].*") 
ggs_geweke(fit.ggs, family = "^[mt].*") 
ggs_geweke(fit.ggs, family = "^l.*\\]$")
```

#### Autocorrelation

The runjags summary function has computed autocorrelation up to 500 iterations (equal to 10 samples). We'd like it if the autocorrelation was close 0. Auto-correlation of most parameters less than 0.1. Some are greater than 0.1 though

```{r autocorr_fromsummary}
hist(sm$AC.500)
sm %>% 
  filter(AC.500 >= 0.1) %>% 
  dplyr::select(varname, AC.500) %>%
  deframe()
```

Lots of autocorrelation: occassional covariate coefficients for species and many of the latent variables.
This is better than first run in March, in that fit many of the u.b and v.b components had autocorrelation.

The species that had high autocorrelation were `r detection_data_specieslist[c(3, 26, 43)]`: "Australian Raven", "Laughing Kookaburra" "Stubble Quail".

The lv.coef can have very large autocorrelation so we don't look them below. Autocorrelation plots of u.b[, 1] components don't show much interesting structure and confirm the above numerical summaries.
The mu and tau components have little autocorrelation.

```{r autocorrelation}
ggs_autocorrelation(fit.ggs, family = "^[u].*\\[.*,1\\]") +
  facet_wrap(~ Parameter) +
  aes(fill = NULL, alpha = 0)
ggs_autocorrelation(fit.ggs, family = "^[mt].*") +
  facet_wrap(~ Parameter) +
  aes(fill = NULL, alpha = 0)
```

#### Cross-Correlation (NOT PERFORMED)
```{r crosscorrelation}
ggs_crosscorrelation(fit.ggs)
# ggs_pairs(fit.ggs, lower = list(continuous = "density"))
```



### Correlation Between Variables (NOT PERFORMED)

### Compare to chains with very different initial conditions (NOT PERFORMED)

### Other Diagnostics of Whether Model has Updated Successfully?  (NOT PERFORMED)
```{r ggmcmc1, eval = FALSE}

ggs_compare_partial(fit.ggs, family = "lv.coef\\[.,1\\]")
ggs_compare_partial(fit.ggs, family = "lv.coef\\[.,2\\]")
ggs_crosscorrelation(fit.ggs)
ggs_pairs(fit.ggs, lower = list(continuous = "density"))

ggs_rocplot(fit.ggs, outcome = "y")

ggs_autocorrelation(fit.ggs, family = "lv.coef\\[.,1\\]") +
  facet_wrap(~ Parameter) +
  aes(fill = NULL, alpha = 0)
```

## Assess Model
The latent variable information is totally untrustworthy. I don't have the latent variables anyway.

The occupancy probability of site should be possible to compute, and the dependence on covariates.

### Caterpilla Plots of Covariates
```{r caterpillar_occupancy, fig.height = 12, out.height=12}
speciesnameWparamname <- function(shortparamname, speciesnames, colidx){
  setNames(speciesnames, paste0(shortparamname,"[",1:length(speciesnames),",",colidx,"]"))
}
ggs_caterpillar(fit.ggs, family = "u.b\\[.*,1\\]") +
  ggtitle("Intercept Coefficient") +
  scale_y_discrete(labels = speciesnameWparamname("u.b", detection_data_specieslist, 1))
ggs_caterpillar(fit.ggs, family = "u.b\\[.*,2\\]") +
  ggtitle("os_cover Coefficient") +
  scale_y_discrete(labels = speciesnameWparamname("u.b", detection_data_specieslist, 2))
ggs_caterpillar(fit.ggs, family = "u.b\\[.*,3\\]") +
  ggtitle("log(ms_cover + 1) Coefficient") +
  scale_y_discrete(labels = speciesnameWparamname("u.b", detection_data_specieslist, 3))
ggs_caterpillar(fit.ggs, family = "u.b\\[.*,4\\]") +
  ggtitle("NMDetected Coefficient") +
  scale_y_discrete(labels = speciesnameWparamname("u.b", detection_data_specieslist, 4))
```

Note in the above: thick line is 0.05 to 0.95 credible interval. Thin line is 0.025 - 0.975 credible interval.
The intercept presumably gives the overall presence of each bird. Magpie is top of the list as I expected.
I'm not sure if the dependence on overstory and midstory makes sense.
I'm guessing large birds (cockatoos) do not like mid story; Sulphur-crested Cockatoo has one of the most negative response to midstorey. Striated Pardalotes, Galah and Starlings all displike midstorey to a similar amount according to this model.


```{r caterpillar_detectionprob, fig.height = 12, out.height=12}
ggs_caterpillar(fit.ggs, family = "v.b\\[.*,1\\]") +
  ggtitle("Intercept Coefficient") +
  scale_y_discrete(labels = speciesnameWparamname("v.b", detection_data_specieslist, 1))
ggs_caterpillar(fit.ggs, family = "v.b\\[.*,2\\]") +
  ggtitle("MeanWind Coefficient") +
  scale_y_discrete(labels = speciesnameWparamname("v.b", detection_data_specieslist, 2))
ggs_caterpillar(fit.ggs, family = "v.b\\[.*,3\\]") +
  ggtitle("MeanTime Coefficient") +
  scale_y_discrete(labels = speciesnameWparamname("v.b", detection_data_specieslist, 3))
```

Not much differences of wind on the different species, though for many detection probability is negatively associated with windiness.
It would seem that the birds differ a little bit in their response to the time of day (Dusky Woodswallow detections correlated to visits later in the morning!). 

The greater impact of windiness is consistent with Wade's findings.
__Knowing a little bit more about the different species' behaviour would allow me to assess the models easier, but perhaps taint my interpretations of the models?__

### Residuals, or similar of detections vs fitted detection probability.
__How to do this?!__

## Impovements
* Look at the fitted probabilities and compare to observations some how.


* Keep burn in and don't do any thinning - to see effect of initial conditions, and of thinning
* Do fewer iterations to make for faster assessment. More chains instead.
* Reduce plotting of per-site parameters of no interest (mainly z?)
* Track final probability of detection 'mu.p' - to compare with actual observations.
* Track the LV values

